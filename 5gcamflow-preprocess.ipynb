{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camflow Dataset Preprocess for flash\n",
    "\n",
    "This notebook goes through a list of files representing a dataset generated by camflow and prepared by the Unicorn parser to be reformated and split into batches to be processed by flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange\n",
    "import os.path as osp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parse_data = True\n",
    "\n",
    "ds_path = '/home/aabouelk/ds/camflow/'\n",
    "benign_date = '10-05-2024'\n",
    "attack_date = '13-03-2024'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_types = {}\n",
    "edge_types = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing. 2024-05-22 19:58:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "351859it [00:00, 400508.14it/s] ?it/s]\n",
      "351907it [00:00, 407819.99it/s]:25,  1.13it/s]\n",
      "350634it [00:00, 404655.45it/s]:24,  1.14it/s]\n",
      "349533it [00:00, 483526.71it/s]:23,  1.15it/s]\n",
      "352332it [00:00, 554923.35it/s]:21,  1.23it/s]\n",
      "356273it [00:00, 547881.92it/s]:18,  1.33it/s]\n",
      "355014it [00:00, 535099.41it/s]:17,  1.39it/s]\n",
      "356007it [00:00, 547253.76it/s]:16,  1.42it/s]\n",
      "354442it [00:00, 544088.90it/s]:15,  1.46it/s]\n",
      "353031it [00:00, 549642.10it/s]:14,  1.48it/s]\n",
      "352729it [00:00, 542914.62it/s]0:13,  1.50it/s]\n",
      "352349it [00:00, 558108.84it/s]0:12,  1.51it/s]\n",
      "352903it [00:00, 547308.01it/s]0:11,  1.53it/s]\n",
      "352660it [00:00, 556024.57it/s]0:11,  1.53it/s]\n",
      "353498it [00:00, 559682.79it/s]0:10,  1.54it/s]\n",
      "353270it [00:00, 534383.61it/s]0:09,  1.55it/s]\n",
      "353404it [00:00, 542859.49it/s]0:09,  1.54it/s]\n",
      "353581it [00:00, 553090.82it/s]0:08,  1.53it/s]\n",
      "352697it [00:00, 553862.04it/s]0:07,  1.54it/s]\n",
      "352366it [00:00, 544415.87it/s]0:07,  1.55it/s]\n",
      "352669it [00:00, 550430.48it/s]0:06,  1.54it/s]\n",
      "352747it [00:00, 555600.34it/s]0:05,  1.54it/s]\n",
      "352504it [00:00, 536760.30it/s]0:05,  1.55it/s]\n",
      "352294it [00:00, 537737.97it/s]0:04,  1.54it/s]\n",
      "352558it [00:00, 550635.27it/s]0:03,  1.53it/s]\n",
      "352428it [00:00, 542497.31it/s]0:03,  1.54it/s]\n",
      "351639it [00:00, 542387.56it/s]0:02,  1.54it/s]\n",
      "348152it [00:00, 562578.55it/s]0:01,  1.53it/s]\n",
      "347877it [00:00, 547774.25it/s]0:01,  1.56it/s]\n",
      "348044it [00:00, 546741.63it/s]0:00,  1.56it/s]\n",
      "100%|██████████| 30/30 [00:20<00:00,  1.49it/s]\n",
      "951538it [00:02, 447586.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. 2024-05-22 19:58:38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def show(str):\n",
    "\tprint (str + ' ' + time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(time.time())))\n",
    "\n",
    "def parse_data():\n",
    "    \n",
    "    show('Start processing.')\n",
    "    file_idx = 0\n",
    "    i = 0 \n",
    "    \n",
    "    for base_idx in trange(30):\n",
    "        file_path = osp.join(ds_path, benign_date, f'base/base-{base_idx}.txt')\n",
    "        f = open(file_path, 'r')\n",
    "\n",
    "        for line in tqdm(f):\n",
    "\n",
    "            # Split the large graph into smaller graph each with 1M edges\n",
    "            if i >= file_idx * 30000:\n",
    "                if file_idx > 0: fw.close()\n",
    "                fw = open('5gcamflow/'+str(file_idx)+'.txt', 'w')\n",
    "                file_idx += 1\n",
    "\n",
    "            tempp = line.strip('\\n').split(' ')\n",
    "            temp = []\n",
    "            temp.append(tempp[0])\n",
    "            temp.append(tempp[2].split(':')[0])\n",
    "            temp.append(tempp[1])\n",
    "            temp.append(tempp[2].split(':')[1])\n",
    "            temp.append(tempp[2].split(':')[2])\n",
    "            temp.append(tempp[2].split(':')[3])\n",
    "            fw.write(temp[0]+'\\t'+temp[1]+'\\t'+temp[2]+'\\t'+temp[3]+'\\t'+temp[4]+'\\t'+temp[5]+'\\n')\n",
    "            node_types[temp[1]] = node_types.get(temp[1], 0) + 1\n",
    "            node_types[temp[1]] = node_types.get(temp[3], 0) + 1\n",
    "            i += 1\n",
    "                \n",
    "        f.close()\n",
    "    fw.close()\n",
    "    \n",
    "    file_idx = 400\n",
    "    i = 0 \n",
    "    \n",
    "    file_path = osp.join(ds_path, attack_date, f'privesc/preprocessed.txt')\n",
    "    f = open(file_path, 'r')\n",
    "\n",
    "    for line in tqdm(f):\n",
    "        # Split the large graph into smaller graph each with 1M edges\n",
    "        if i >= (file_idx-400) * 30000:\n",
    "            if file_idx > 0: fw.close()\n",
    "            fw = open('5gcamflow/'+str(file_idx)+'.txt', 'w')\n",
    "            file_idx += 1\n",
    "\n",
    "        tempp = line.strip('\\n').split('\\t')\n",
    "        temp = []\n",
    "        temp.append(tempp[0])\n",
    "        temp.append(tempp[2].split(':')[0])\n",
    "        temp.append(tempp[1])\n",
    "        temp.append(tempp[2].split(':')[1])\n",
    "        temp.append(tempp[2].split(':')[2])\n",
    "        temp.append(tempp[2].split(':')[3])\n",
    "        fw.write(temp[0]+'\\t'+temp[1]+'\\t'+temp[2]+'\\t'+temp[3]+'\\t'+temp[4]+'\\t'+temp[5]+'\\n')\n",
    "        node_types[temp[1]] = node_types.get(temp[1], 0) + 1\n",
    "        node_types[temp[1]] = node_types.get(temp[3], 0) + 1\n",
    "        i += 1\n",
    "            \n",
    "    f.close()\n",
    "    fw.close()\n",
    "    show('Done.')\n",
    "\n",
    "if Parse_data:\n",
    "    parse_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'address': 2037267,\n",
      " 'argv': 2036347,\n",
      " 'block': 2082676,\n",
      " 'file': 2096312,\n",
      " 'iattr': 2093167,\n",
      " 'link': 2096252,\n",
      " 'path': 2096241,\n",
      " 'pipe': 2096310,\n",
      " 'process_memory': 2096308,\n",
      " 'socket': 2096258,\n",
      " 'task': 2096311,\n",
      " 'xattr': 2036354}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# sorted_edge_types = {k:v for k, v in sorted(edge_types.items(), key=lambda item: item[1])}\n",
    "# pprint(sorted_edge_types)\n",
    "pprint(node_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
