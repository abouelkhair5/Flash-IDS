{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flash Evaluation on CamFow Dataset:\n",
    "\n",
    "This notebook is dedicated to evaluating Flash on the 5G CamFlow datasets, which are graph-level in nature. We employ Flash in graph-level detection mode to analyze this dataset effectively. Upon completion of the notebook execution, the results will be presented.\n",
    "\n",
    "## Dataset Access: \n",
    "- This dataset will be publically available upon publishing\n",
    "\n",
    "## Data Parsing and Execution:\n",
    "- Utilize the parser included in this notebook to process the downloaded files.\n",
    "- To obtain the evaluation results, execute all cells within this notebook.\n",
    "\n",
    "## Model Training and Execution Flexibility:\n",
    "- By default, the notebook operates using pre-trained model weights.\n",
    "- Additionally, this notebook offers the flexibility to set parameters for training Graph Neural Networks (GNNs) and word2vec models from scratch.\n",
    "- You can then utilize these freshly trained models to conduct the evaluation. \n",
    "\n",
    "Follow these guidelines for a thorough and efficient analysis of the Unicorn datasets using Flash.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "id": "F1op-CbyLuN4",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "warnings.filterwarnings('ignore')\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import multiprocessing\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nM7KaeCbA_mQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import gzip\n",
    "from sklearn.manifold import TSNE\n",
    "import json\n",
    "import copy\n",
    "import os\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Train_Gnn = True\n",
    "Train_Word2vec = False\n",
    "Parse_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "def prepare_graph(df):\n",
    "    def process_node(node, action, node_dict, label_dict, dummies, node_type):\n",
    "        node_dict.setdefault(node, []).append(action)\n",
    "        label_dict[node] = dummies.get(getattr(row, node_type), -1)  \n",
    "\n",
    "    nodes = {}\n",
    "    labels = {}\n",
    "    edges = []\n",
    "    # dummies = {\n",
    "    #     \"7998762093665332071\": 0,\n",
    "    #     \"14709879154498484854\": 1,\n",
    "    #     \"10991425273196493354\": 2,\n",
    "    #     \"14871526952859113360\": 3,\n",
    "    #     \"8771628573506871447\": 4,\n",
    "    #     \"7877121489144997480\": 5,\n",
    "    #     \"17841021884467483934\": 6,\n",
    "    #     \"7895447931126725167\": 7,\n",
    "    #     \"15125250455093594050\": 8,\n",
    "    #     \"8664433583651064836\": 9,\n",
    "    #     \"14377490526132269506\": 10,\n",
    "    #     \"15554536683409451879\": 11,\n",
    "    #     \"8204541918505434145\": 12,\n",
    "    #     \"14356114695140920775\": 13\n",
    "    # }\n",
    "    \n",
    "    dummies = {'address': 0,\n",
    "        'argv': 1,\n",
    "        'block': 2,\n",
    "        'file': 3,\n",
    "        'iattr': 4,\n",
    "        'link': 5,\n",
    "        'path': 6,\n",
    "        'pipe': 7,\n",
    "        'process_memory': 8,\n",
    "        'socket': 9,\n",
    "        'task': 10,\n",
    "        'xattr': 11}\n",
    "\n",
    "    for row in df.itertuples():\n",
    "        process_node(row.actorID, row.action, nodes, labels, dummies, 'actor_type')\n",
    "        process_node(row.objectID, row.action, nodes, labels, dummies, 'object')\n",
    "\n",
    "        edges.append((row.actorID, row.objectID))\n",
    "\n",
    "    features = [nodes[node] for node in tqdm(nodes)]\n",
    "    feat_labels = [labels[node] for node in tqdm(nodes)]\n",
    "    edge_index = [[], []]\n",
    "    node_index_map = {node: i for i, node in enumerate(nodes.keys())}\n",
    "    for src, dst in tqdm(edges):\n",
    "        src_index = node_index_map[src]\n",
    "        dst_index = node_index_map[dst]\n",
    "        edge_index[0].append(src_index)\n",
    "        edge_index[1].append(dst_index)\n",
    "\n",
    "    return features, feat_labels, edge_index, list(nodes.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fmXWs1dKIzD8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import SAGEConv, GATConv\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self,in_channel,out_channel):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channel, 32, normalize=True)\n",
    "        self.conv2 = SAGEConv(32, 20, normalize=True)\n",
    "        self.linear = nn.Linear(in_features=20,out_features=out_channel)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.linear(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3PCP6SXwZaif",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from multiprocessing import Pool\n",
    "from itertools import compress\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class EpochSaver(CallbackAny2Vec):\n",
    "    '''Callback to save model after each epoch.'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        model.save('trained_weights/5gcamflow/5gcamflow.model')\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "P8oBL8LFaeOf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EpochLogger(CallbackAny2Vec):\n",
    "    '''Callback to log information about training'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(\"Epoch #{} start\".format(self.epoch))\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(\"Epoch #{} end\".format(self.epoch))\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Se7Ei4tAapVj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = EpochLogger()\n",
    "saver = EpochSaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Train_Word2vec:\n",
    "    comb_data = []\n",
    "    for i in tqdm(range(12)):\n",
    "        f = open(f\"5gcamflow/{i}.txt\")\n",
    "        data = f.read().split('\\n')\n",
    "        data = [line.split('\\t') for line in data]\n",
    "        comb_data = comb_data + data\n",
    "\n",
    "    df = pd.DataFrame (comb_data, columns = ['actorID', 'actor_type','objectID','object','action','timestamp'])\n",
    "    df.sort_values(by='timestamp', ascending=True,inplace=True)\n",
    "    df = df.dropna()\n",
    "    phrases,labels,edges,mapp = prepare_graph(df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Train_Word2vec:\n",
    "        word2vec = Word2Vec(sentences=phrases, vector_size=30, window=5, min_count=1, workers=32,epochs=300,callbacks=[saver,logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "p3TAi69zI1bO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "model = GCN(30,14).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Vn_pMyt5Jd-6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "class PositionalEncoder:\n",
    "\n",
    "    def __init__(self, d_model, max_len=100000, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.device = device\n",
    "        position = torch.arange(max_len, device=device).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2, device=device) * (-math.log(10000.0) / d_model))\n",
    "        self.pe = torch.zeros(max_len, d_model, device=device)\n",
    "        self.pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "    def embed(self, x):\n",
    "        return x + self.pe[:x.size(0)]\n",
    "\n",
    "def infer(document):\n",
    "    word_embeddings = [w2vmodel.wv[word] for word in document if word in  w2vmodel.wv]\n",
    "    \n",
    "    if not word_embeddings:\n",
    "        return np.zeros(30)\n",
    "\n",
    "    output_embedding = torch.tensor(word_embeddings, dtype=torch.float, device=device)\n",
    "    if len(document) < 100000:\n",
    "        output_embedding = encoder.embed(output_embedding)\n",
    "\n",
    "    output_embedding = output_embedding.detach().cpu().numpy()\n",
    "    return np.mean(output_embedding, axis=0)\n",
    "\n",
    "encoder = PositionalEncoder(30)\n",
    "w2vmodel = Word2Vec.load(\"trained_weights/5gcamflow/5gcamflow.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 689309,
     "status": "ok",
     "timestamp": 1673566932746,
     "user": {
      "displayName": "Mati Ur Rehman",
      "userId": "04281203290774044297"
     },
     "user_tz": 300
    },
    "id": "Gclj6HVL17lD",
    "outputId": "f60fadea-a7db-471f-defe-fee744f6ef25",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12742/12742 [00:00<00:00, 4297854.57it/s]\n",
      "100%|██████████| 12742/12742 [00:00<00:00, 5356165.72it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 3694554.00it/s]\n",
      "Inferring Phrases: 100%|██████████| 12742/12742 [00:00<00:00, 418609.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5977 nodes still misclassified out of torch.Size([12742]) \n",
      "\n",
      "Model# 1. 5977 nodes still misclassified out of torch.Size([12742]) \n",
      "\n",
      "Model# 2. 5977 nodes still misclassified out of torch.Size([12742]) \n",
      "\n",
      "Model# 3. 5977 nodes still misclassified out of torch.Size([12742]) \n",
      "\n",
      "Model# 4. 5977 nodes still misclassified out of torch.Size([12742]) \n",
      "\n",
      "Model# 5. 5977 nodes still misclassified out of torch.Size([12742]) \n",
      "\n",
      "Model# 6. 5977 nodes still misclassified out of torch.Size([12742]) \n",
      "\n",
      "Model# 7. 5977 nodes still misclassified out of torch.Size([12742]) \n",
      "\n",
      "Model# 8. 5977 nodes still misclassified out of torch.Size([12742]) \n",
      "\n",
      "Model# 9. 5977 nodes still misclassified out of torch.Size([12742]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/299 [00:01<06:37,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 5977 nodes still misclassified out of torch.Size([12742]) \n",
      "\n",
      "Model# 11. 5977 nodes still misclassified out of torch.Size([12742]) \n",
      "\n",
      "Model# 12. 5977 nodes still misclassified out of torch.Size([12742]) \n",
      "\n",
      "Model# 13. 5977 nodes still misclassified out of torch.Size([12742]) \n",
      "\n",
      "Model# 14. 5977 nodes still misclassified out of torch.Size([12742]) \n",
      "\n",
      "Model# 15. 5977 nodes still misclassified out of torch.Size([12742]) \n",
      "\n",
      "Model# 16. 5977 nodes still misclassified out of torch.Size([12742]) \n",
      "\n",
      "Model# 17. 5977 nodes still misclassified out of torch.Size([12742]) \n",
      "\n",
      "Model# 18. 5977 nodes still misclassified out of torch.Size([12742]) \n",
      "\n",
      "Model# 19. 5977 nodes still misclassified out of torch.Size([12742]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13248/13248 [00:00<00:00, 3480061.34it/s]\n",
      "100%|██████████| 13248/13248 [00:00<00:00, 4084544.21it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2518748.52it/s]\n",
      "Inferring Phrases: 100%|██████████| 13248/13248 [00:00<00:00, 324777.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5075 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 1. 5075 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 2. 5075 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 3. 5075 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 4. 5075 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 5. 5075 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 6. 5075 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 7. 5075 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 8. 5075 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 9. 5075 nodes still misclassified out of torch.Size([13248]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/299 [00:02<04:56,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 5075 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 11. 5075 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 12. 5075 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 13. 5075 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 14. 5075 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 15. 5075 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 16. 5075 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 17. 5075 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 18. 5075 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 19. 5075 nodes still misclassified out of torch.Size([13248]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12918/12918 [00:00<00:00, 3458794.71it/s]\n",
      "100%|██████████| 12918/12918 [00:00<00:00, 3984264.95it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2314354.14it/s]\n",
      "Inferring Phrases: 100%|██████████| 12918/12918 [00:00<00:00, 322230.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5067 nodes still misclassified out of torch.Size([12918]) \n",
      "\n",
      "Model# 1. 5067 nodes still misclassified out of torch.Size([12918]) \n",
      "\n",
      "Model# 2. 5067 nodes still misclassified out of torch.Size([12918]) \n",
      "\n",
      "Model# 3. 5067 nodes still misclassified out of torch.Size([12918]) \n",
      "\n",
      "Model# 4. 5067 nodes still misclassified out of torch.Size([12918]) \n",
      "\n",
      "Model# 5. 5067 nodes still misclassified out of torch.Size([12918]) \n",
      "\n",
      "Model# 6. 5067 nodes still misclassified out of torch.Size([12918]) \n",
      "\n",
      "Model# 7. 5067 nodes still misclassified out of torch.Size([12918]) \n",
      "\n",
      "Model# 8. 5067 nodes still misclassified out of torch.Size([12918]) \n",
      "\n",
      "Model# 9. 5067 nodes still misclassified out of torch.Size([12918]) \n",
      "\n",
      "Model# 10. 5067 nodes still misclassified out of torch.Size([12918]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/299 [00:02<04:04,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 5067 nodes still misclassified out of torch.Size([12918]) \n",
      "\n",
      "Model# 12. 5067 nodes still misclassified out of torch.Size([12918]) \n",
      "\n",
      "Model# 13. 5067 nodes still misclassified out of torch.Size([12918]) \n",
      "\n",
      "Model# 14. 5067 nodes still misclassified out of torch.Size([12918]) \n",
      "\n",
      "Model# 15. 5067 nodes still misclassified out of torch.Size([12918]) \n",
      "\n",
      "Model# 16. 5067 nodes still misclassified out of torch.Size([12918]) \n",
      "\n",
      "Model# 17. 5067 nodes still misclassified out of torch.Size([12918]) \n",
      "\n",
      "Model# 18. 5067 nodes still misclassified out of torch.Size([12918]) \n",
      "\n",
      "Model# 19. 5067 nodes still misclassified out of torch.Size([12918]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13688/13688 [00:00<00:00, 2934854.98it/s]\n",
      "100%|██████████| 13688/13688 [00:00<00:00, 3428174.19it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2288967.47it/s]\n",
      "Inferring Phrases: 100%|██████████| 13688/13688 [00:00<00:00, 325983.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5450 nodes still misclassified out of torch.Size([13688]) \n",
      "\n",
      "Model# 1. 5450 nodes still misclassified out of torch.Size([13688]) \n",
      "\n",
      "Model# 2. 5450 nodes still misclassified out of torch.Size([13688]) \n",
      "\n",
      "Model# 3. 5450 nodes still misclassified out of torch.Size([13688]) \n",
      "\n",
      "Model# 4. 5450 nodes still misclassified out of torch.Size([13688]) \n",
      "\n",
      "Model# 5. 5450 nodes still misclassified out of torch.Size([13688]) \n",
      "\n",
      "Model# 6. 5450 nodes still misclassified out of torch.Size([13688]) \n",
      "\n",
      "Model# 7. 5450 nodes still misclassified out of torch.Size([13688]) \n",
      "\n",
      "Model# 8. 5450 nodes still misclassified out of torch.Size([13688]) \n",
      "\n",
      "Model# 9. 5450 nodes still misclassified out of torch.Size([13688]) \n",
      "\n",
      "Model# 10. 5450 nodes still misclassified out of torch.Size([13688]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 4/299 [00:03<04:03,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 5450 nodes still misclassified out of torch.Size([13688]) \n",
      "\n",
      "Model# 12. 5450 nodes still misclassified out of torch.Size([13688]) \n",
      "\n",
      "Model# 13. 5450 nodes still misclassified out of torch.Size([13688]) \n",
      "\n",
      "Model# 14. 5450 nodes still misclassified out of torch.Size([13688]) \n",
      "\n",
      "Model# 15. 5450 nodes still misclassified out of torch.Size([13688]) \n",
      "\n",
      "Model# 16. 5450 nodes still misclassified out of torch.Size([13688]) \n",
      "\n",
      "Model# 17. 5450 nodes still misclassified out of torch.Size([13688]) \n",
      "\n",
      "Model# 18. 5450 nodes still misclassified out of torch.Size([13688]) \n",
      "\n",
      "Model# 19. 5450 nodes still misclassified out of torch.Size([13688]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13711/13711 [00:00<00:00, 3539177.93it/s]\n",
      "100%|██████████| 13711/13711 [00:00<00:00, 3984763.18it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2502468.48it/s]\n",
      "Inferring Phrases: 100%|██████████| 13711/13711 [00:00<00:00, 323752.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4746 nodes still misclassified out of torch.Size([13711]) \n",
      "\n",
      "Model# 1. 4746 nodes still misclassified out of torch.Size([13711]) \n",
      "\n",
      "Model# 2. 4746 nodes still misclassified out of torch.Size([13711]) \n",
      "\n",
      "Model# 3. 4746 nodes still misclassified out of torch.Size([13711]) \n",
      "\n",
      "Model# 4. 4746 nodes still misclassified out of torch.Size([13711]) \n",
      "\n",
      "Model# 5. 4746 nodes still misclassified out of torch.Size([13711]) \n",
      "\n",
      "Model# 6. 4746 nodes still misclassified out of torch.Size([13711]) \n",
      "\n",
      "Model# 7. 4746 nodes still misclassified out of torch.Size([13711]) \n",
      "\n",
      "Model# 8. 4746 nodes still misclassified out of torch.Size([13711]) \n",
      "\n",
      "Model# 9. 4746 nodes still misclassified out of torch.Size([13711]) \n",
      "\n",
      "Model# 10. 4746 nodes still misclassified out of torch.Size([13711]) \n",
      "\n",
      "Model# 11. 4746 nodes still misclassified out of torch.Size([13711]) \n",
      "\n",
      "Model# 12. 4746 nodes still misclassified out of torch.Size([13711]) \n",
      "\n",
      "Model# 13. 4746 nodes still misclassified out of torch.Size([13711]) \n",
      "\n",
      "Model# 14. 4746 nodes still misclassified out of torch.Size([13711]) \n",
      "\n",
      "Model# 15. 4746 nodes still misclassified out of torch.Size([13711]) \n",
      "\n",
      "Model# 16. 4746 nodes still misclassified out of torch.Size([13711]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/299 [00:04<03:28,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 17. 4746 nodes still misclassified out of torch.Size([13711]) \n",
      "\n",
      "Model# 18. 4746 nodes still misclassified out of torch.Size([13711]) \n",
      "\n",
      "Model# 19. 4746 nodes still misclassified out of torch.Size([13711]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13089/13089 [00:00<00:00, 3531633.65it/s]\n",
      "100%|██████████| 13089/13089 [00:00<00:00, 4006951.69it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2361569.01it/s]\n",
      "Inferring Phrases: 100%|██████████| 13089/13089 [00:00<00:00, 324061.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4866 nodes still misclassified out of torch.Size([13089]) \n",
      "\n",
      "Model# 1. 4866 nodes still misclassified out of torch.Size([13089]) \n",
      "\n",
      "Model# 2. 4866 nodes still misclassified out of torch.Size([13089]) \n",
      "\n",
      "Model# 3. 4866 nodes still misclassified out of torch.Size([13089]) \n",
      "\n",
      "Model# 4. 4866 nodes still misclassified out of torch.Size([13089]) \n",
      "\n",
      "Model# 5. 4866 nodes still misclassified out of torch.Size([13089]) \n",
      "\n",
      "Model# 6. 4866 nodes still misclassified out of torch.Size([13089]) \n",
      "\n",
      "Model# 7. 4866 nodes still misclassified out of torch.Size([13089]) \n",
      "\n",
      "Model# 8. 4866 nodes still misclassified out of torch.Size([13089]) \n",
      "\n",
      "Model# 9. 4866 nodes still misclassified out of torch.Size([13089]) \n",
      "\n",
      "Model# 10. 4866 nodes still misclassified out of torch.Size([13089]) \n",
      "\n",
      "Model# 11. 4866 nodes still misclassified out of torch.Size([13089]) \n",
      "\n",
      "Model# 12. 4866 nodes still misclassified out of torch.Size([13089]) \n",
      "\n",
      "Model# 13. 4866 nodes still misclassified out of torch.Size([13089]) \n",
      "\n",
      "Model# 14. 4866 nodes still misclassified out of torch.Size([13089]) \n",
      "\n",
      "Model# 15. 4866 nodes still misclassified out of torch.Size([13089]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/299 [00:04<03:06,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 16. 4866 nodes still misclassified out of torch.Size([13089]) \n",
      "\n",
      "Model# 17. 4866 nodes still misclassified out of torch.Size([13089]) \n",
      "\n",
      "Model# 18. 4866 nodes still misclassified out of torch.Size([13089]) \n",
      "\n",
      "Model# 19. 4866 nodes still misclassified out of torch.Size([13089]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13135/13135 [00:00<00:00, 3248742.96it/s]\n",
      "100%|██████████| 13135/13135 [00:00<00:00, 3837839.29it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2302454.16it/s]\n",
      "Inferring Phrases: 100%|██████████| 13135/13135 [00:00<00:00, 328590.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4779 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 1. 4779 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 2. 4779 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 3. 4779 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 4. 4779 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 5. 4779 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 6. 4779 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 7. 4779 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 8. 4779 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 9. 4779 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 10. 4779 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 11. 4779 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 12. 4779 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 13. 4779 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 14. 4779 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 15. 4779 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 16. 4779 nodes still misclassified out of torch.Size([13135]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 7/299 [00:05<03:11,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 17. 4779 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 18. 4779 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 19. 4779 nodes still misclassified out of torch.Size([13135]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12961/12961 [00:00<00:00, 3555187.64it/s]\n",
      "100%|██████████| 12961/12961 [00:00<00:00, 3975892.21it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2346682.58it/s]\n",
      "Inferring Phrases: 100%|██████████| 12961/12961 [00:00<00:00, 322611.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4842 nodes still misclassified out of torch.Size([12961]) \n",
      "\n",
      "Model# 1. 4842 nodes still misclassified out of torch.Size([12961]) \n",
      "\n",
      "Model# 2. 4842 nodes still misclassified out of torch.Size([12961]) \n",
      "\n",
      "Model# 3. 4842 nodes still misclassified out of torch.Size([12961]) \n",
      "\n",
      "Model# 4. 4842 nodes still misclassified out of torch.Size([12961]) \n",
      "\n",
      "Model# 5. 4842 nodes still misclassified out of torch.Size([12961]) \n",
      "\n",
      "Model# 6. 4842 nodes still misclassified out of torch.Size([12961]) \n",
      "\n",
      "Model# 7. 4842 nodes still misclassified out of torch.Size([12961]) \n",
      "\n",
      "Model# 8. 4842 nodes still misclassified out of torch.Size([12961]) \n",
      "\n",
      "Model# 9. 4842 nodes still misclassified out of torch.Size([12961]) \n",
      "\n",
      "Model# 10. 4842 nodes still misclassified out of torch.Size([12961]) \n",
      "\n",
      "Model# 11. 4842 nodes still misclassified out of torch.Size([12961]) \n",
      "\n",
      "Model# 12. 4842 nodes still misclassified out of torch.Size([12961]) \n",
      "\n",
      "Model# 13. 4842 nodes still misclassified out of torch.Size([12961]) \n",
      "\n",
      "Model# 14. 4842 nodes still misclassified out of torch.Size([12961]) \n",
      "\n",
      "Model# 15. 4842 nodes still misclassified out of torch.Size([12961]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8/299 [00:05<02:54,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 16. 4842 nodes still misclassified out of torch.Size([12961]) \n",
      "\n",
      "Model# 17. 4842 nodes still misclassified out of torch.Size([12961]) \n",
      "\n",
      "Model# 18. 4842 nodes still misclassified out of torch.Size([12961]) \n",
      "\n",
      "Model# 19. 4842 nodes still misclassified out of torch.Size([12961]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13295/13295 [00:00<00:00, 3361055.49it/s]\n",
      "100%|██████████| 13295/13295 [00:00<00:00, 3996507.68it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2294937.35it/s]\n",
      "Inferring Phrases: 100%|██████████| 13295/13295 [00:00<00:00, 317471.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5010 nodes still misclassified out of torch.Size([13295]) \n",
      "\n",
      "Model# 1. 5010 nodes still misclassified out of torch.Size([13295]) \n",
      "\n",
      "Model# 2. 5010 nodes still misclassified out of torch.Size([13295]) \n",
      "\n",
      "Model# 3. 5010 nodes still misclassified out of torch.Size([13295]) \n",
      "\n",
      "Model# 4. 5010 nodes still misclassified out of torch.Size([13295]) \n",
      "\n",
      "Model# 5. 5010 nodes still misclassified out of torch.Size([13295]) \n",
      "\n",
      "Model# 6. 5010 nodes still misclassified out of torch.Size([13295]) \n",
      "\n",
      "Model# 7. 5010 nodes still misclassified out of torch.Size([13295]) \n",
      "\n",
      "Model# 8. 5010 nodes still misclassified out of torch.Size([13295]) \n",
      "\n",
      "Model# 9. 5010 nodes still misclassified out of torch.Size([13295]) \n",
      "\n",
      "Model# 10. 5010 nodes still misclassified out of torch.Size([13295]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 9/299 [00:06<02:53,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 5010 nodes still misclassified out of torch.Size([13295]) \n",
      "\n",
      "Model# 12. 5010 nodes still misclassified out of torch.Size([13295]) \n",
      "\n",
      "Model# 13. 5010 nodes still misclassified out of torch.Size([13295]) \n",
      "\n",
      "Model# 14. 5010 nodes still misclassified out of torch.Size([13295]) \n",
      "\n",
      "Model# 15. 5010 nodes still misclassified out of torch.Size([13295]) \n",
      "\n",
      "Model# 16. 5010 nodes still misclassified out of torch.Size([13295]) \n",
      "\n",
      "Model# 17. 5010 nodes still misclassified out of torch.Size([13295]) \n",
      "\n",
      "Model# 18. 5010 nodes still misclassified out of torch.Size([13295]) \n",
      "\n",
      "Model# 19. 5010 nodes still misclassified out of torch.Size([13295]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12876/12876 [00:00<00:00, 3118481.25it/s]\n",
      "100%|██████████| 12876/12876 [00:00<00:00, 3725569.70it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2106243.95it/s]\n",
      "Inferring Phrases: 100%|██████████| 12876/12876 [00:00<00:00, 316265.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3561 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 1. 3561 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 2. 3561 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 3. 3561 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 4. 3561 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 5. 3561 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 6. 3561 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 7. 3561 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 8. 3561 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 9. 3561 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 10. 3561 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 11. 3561 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 12. 3561 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 13. 3561 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 14. 3561 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 15. 3561 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 16. 3561 nodes still misclassified out of torch.Size([12876]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 10/299 [00:07<03:08,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 17. 3561 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 18. 3561 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 19. 3561 nodes still misclassified out of torch.Size([12876]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12764/12764 [00:00<00:00, 2024891.12it/s]\n",
      "100%|██████████| 12764/12764 [00:00<00:00, 2817392.71it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1837753.14it/s]\n",
      "Inferring Phrases: 100%|██████████| 12764/12764 [00:00<00:00, 408594.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5043 nodes still misclassified out of torch.Size([12764]) \n",
      "\n",
      "Model# 1. 5043 nodes still misclassified out of torch.Size([12764]) \n",
      "\n",
      "Model# 2. 5043 nodes still misclassified out of torch.Size([12764]) \n",
      "\n",
      "Model# 3. 5043 nodes still misclassified out of torch.Size([12764]) \n",
      "\n",
      "Model# 4. 5043 nodes still misclassified out of torch.Size([12764]) \n",
      "\n",
      "Model# 5. 5043 nodes still misclassified out of torch.Size([12764]) \n",
      "\n",
      "Model# 6. 5043 nodes still misclassified out of torch.Size([12764]) \n",
      "\n",
      "Model# 7. 5043 nodes still misclassified out of torch.Size([12764]) \n",
      "\n",
      "Model# 8. 5043 nodes still misclassified out of torch.Size([12764]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 11/299 [00:07<03:10,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 9. 5043 nodes still misclassified out of torch.Size([12764]) \n",
      "\n",
      "Model# 10. 5043 nodes still misclassified out of torch.Size([12764]) \n",
      "\n",
      "Model# 11. 5043 nodes still misclassified out of torch.Size([12764]) \n",
      "\n",
      "Model# 12. 5043 nodes still misclassified out of torch.Size([12764]) \n",
      "\n",
      "Model# 13. 5043 nodes still misclassified out of torch.Size([12764]) \n",
      "\n",
      "Model# 14. 5043 nodes still misclassified out of torch.Size([12764]) \n",
      "\n",
      "Model# 15. 5043 nodes still misclassified out of torch.Size([12764]) \n",
      "\n",
      "Model# 16. 5043 nodes still misclassified out of torch.Size([12764]) \n",
      "\n",
      "Model# 17. 5043 nodes still misclassified out of torch.Size([12764]) \n",
      "\n",
      "Model# 18. 5043 nodes still misclassified out of torch.Size([12764]) \n",
      "\n",
      "Model# 19. 5043 nodes still misclassified out of torch.Size([12764]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13895/13895 [00:00<00:00, 3196920.14it/s]\n",
      "100%|██████████| 13895/13895 [00:00<00:00, 3831428.18it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2048733.60it/s]\n",
      "Inferring Phrases: 100%|██████████| 13895/13895 [00:00<00:00, 339390.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5667 nodes still misclassified out of torch.Size([13895]) \n",
      "\n",
      "Model# 1. 5667 nodes still misclassified out of torch.Size([13895]) \n",
      "\n",
      "Model# 2. 5667 nodes still misclassified out of torch.Size([13895]) \n",
      "\n",
      "Model# 3. 5667 nodes still misclassified out of torch.Size([13895]) \n",
      "\n",
      "Model# 4. 5667 nodes still misclassified out of torch.Size([13895]) \n",
      "\n",
      "Model# 5. 5667 nodes still misclassified out of torch.Size([13895]) \n",
      "\n",
      "Model# 6. 5667 nodes still misclassified out of torch.Size([13895]) \n",
      "\n",
      "Model# 7. 5667 nodes still misclassified out of torch.Size([13895]) \n",
      "\n",
      "Model# 8. 5667 nodes still misclassified out of torch.Size([13895]) \n",
      "\n",
      "Model# 9. 5667 nodes still misclassified out of torch.Size([13895]) \n",
      "\n",
      "Model# 10. 5667 nodes still misclassified out of torch.Size([13895]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 12/299 [00:08<03:07,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 5667 nodes still misclassified out of torch.Size([13895]) \n",
      "\n",
      "Model# 12. 5667 nodes still misclassified out of torch.Size([13895]) \n",
      "\n",
      "Model# 13. 5667 nodes still misclassified out of torch.Size([13895]) \n",
      "\n",
      "Model# 14. 5667 nodes still misclassified out of torch.Size([13895]) \n",
      "\n",
      "Model# 15. 5667 nodes still misclassified out of torch.Size([13895]) \n",
      "\n",
      "Model# 16. 5667 nodes still misclassified out of torch.Size([13895]) \n",
      "\n",
      "Model# 17. 5667 nodes still misclassified out of torch.Size([13895]) \n",
      "\n",
      "Model# 18. 5667 nodes still misclassified out of torch.Size([13895]) \n",
      "\n",
      "Model# 19. 5667 nodes still misclassified out of torch.Size([13895]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14637/14637 [00:00<00:00, 3170420.76it/s]\n",
      "100%|██████████| 14637/14637 [00:00<00:00, 3786359.17it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2102794.50it/s]\n",
      "Inferring Phrases: 100%|██████████| 14637/14637 [00:00<00:00, 335923.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5664 nodes still misclassified out of torch.Size([14637]) \n",
      "\n",
      "Model# 1. 5664 nodes still misclassified out of torch.Size([14637]) \n",
      "\n",
      "Model# 2. 5664 nodes still misclassified out of torch.Size([14637]) \n",
      "\n",
      "Model# 3. 5664 nodes still misclassified out of torch.Size([14637]) \n",
      "\n",
      "Model# 4. 5664 nodes still misclassified out of torch.Size([14637]) \n",
      "\n",
      "Model# 5. 5664 nodes still misclassified out of torch.Size([14637]) \n",
      "\n",
      "Model# 6. 5664 nodes still misclassified out of torch.Size([14637]) \n",
      "\n",
      "Model# 7. 5664 nodes still misclassified out of torch.Size([14637]) \n",
      "\n",
      "Model# 8. 5664 nodes still misclassified out of torch.Size([14637]) \n",
      "\n",
      "Model# 9. 5664 nodes still misclassified out of torch.Size([14637]) \n",
      "\n",
      "Model# 10. 5664 nodes still misclassified out of torch.Size([14637]) \n",
      "\n",
      "Model# 11. 5664 nodes still misclassified out of torch.Size([14637]) \n",
      "\n",
      "Model# 12. 5664 nodes still misclassified out of torch.Size([14637]) \n",
      "\n",
      "Model# 13. 5664 nodes still misclassified out of torch.Size([14637]) \n",
      "\n",
      "Model# 14. 5664 nodes still misclassified out of torch.Size([14637]) \n",
      "\n",
      "Model# 15. 5664 nodes still misclassified out of torch.Size([14637]) \n",
      "\n",
      "Model# 16. 5664 nodes still misclassified out of torch.Size([14637]) \n",
      "\n",
      "Model# 17. 5664 nodes still misclassified out of torch.Size([14637]) \n",
      "\n",
      "Model# 18. 5664 nodes still misclassified out of torch.Size([14637]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 13/299 [00:09<03:39,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 5664 nodes still misclassified out of torch.Size([14637]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14778/14778 [00:00<00:00, 3131583.11it/s]\n",
      "100%|██████████| 14778/14778 [00:00<00:00, 3733266.55it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2147254.61it/s]\n",
      "Inferring Phrases: 100%|██████████| 14778/14778 [00:00<00:00, 350626.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6172 nodes still misclassified out of torch.Size([14778]) \n",
      "\n",
      "Model# 1. 6172 nodes still misclassified out of torch.Size([14778]) \n",
      "\n",
      "Model# 2. 6172 nodes still misclassified out of torch.Size([14778]) \n",
      "\n",
      "Model# 3. 6172 nodes still misclassified out of torch.Size([14778]) \n",
      "\n",
      "Model# 4. 6172 nodes still misclassified out of torch.Size([14778]) \n",
      "\n",
      "Model# 5. 6172 nodes still misclassified out of torch.Size([14778]) \n",
      "\n",
      "Model# 6. 6172 nodes still misclassified out of torch.Size([14778]) \n",
      "\n",
      "Model# 7. 6172 nodes still misclassified out of torch.Size([14778]) \n",
      "\n",
      "Model# 8. 6172 nodes still misclassified out of torch.Size([14778]) \n",
      "\n",
      "Model# 9. 6172 nodes still misclassified out of torch.Size([14778]) \n",
      "\n",
      "Model# 10. 6172 nodes still misclassified out of torch.Size([14778]) \n",
      "\n",
      "Model# 11. 6172 nodes still misclassified out of torch.Size([14778]) \n",
      "\n",
      "Model# 12. 6172 nodes still misclassified out of torch.Size([14778]) \n",
      "\n",
      "Model# 13. 6172 nodes still misclassified out of torch.Size([14778]) \n",
      "\n",
      "Model# 14. 6172 nodes still misclassified out of torch.Size([14778]) \n",
      "\n",
      "Model# 15. 6172 nodes still misclassified out of torch.Size([14778]) \n",
      "\n",
      "Model# 16. 6172 nodes still misclassified out of torch.Size([14778]) \n",
      "\n",
      "Model# 17. 6172 nodes still misclassified out of torch.Size([14778]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 14/299 [00:10<03:31,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 18. 6172 nodes still misclassified out of torch.Size([14778]) \n",
      "\n",
      "Model# 19. 6172 nodes still misclassified out of torch.Size([14778]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13616/13616 [00:00<00:00, 3003715.52it/s]\n",
      "100%|██████████| 13616/13616 [00:00<00:00, 3676192.04it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2191572.24it/s]\n",
      "Inferring Phrases: 100%|██████████| 13616/13616 [00:00<00:00, 326669.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4710 nodes still misclassified out of torch.Size([13616]) \n",
      "\n",
      "Model# 1. 4710 nodes still misclassified out of torch.Size([13616]) \n",
      "\n",
      "Model# 2. 4710 nodes still misclassified out of torch.Size([13616]) \n",
      "\n",
      "Model# 3. 4710 nodes still misclassified out of torch.Size([13616]) \n",
      "\n",
      "Model# 4. 4710 nodes still misclassified out of torch.Size([13616]) \n",
      "\n",
      "Model# 5. 4710 nodes still misclassified out of torch.Size([13616]) \n",
      "\n",
      "Model# 6. 4710 nodes still misclassified out of torch.Size([13616]) \n",
      "\n",
      "Model# 7. 4710 nodes still misclassified out of torch.Size([13616]) \n",
      "\n",
      "Model# 8. 4710 nodes still misclassified out of torch.Size([13616]) \n",
      "\n",
      "Model# 9. 4710 nodes still misclassified out of torch.Size([13616]) \n",
      "\n",
      "Model# 10. 4710 nodes still misclassified out of torch.Size([13616]) \n",
      "\n",
      "Model# 11. 4710 nodes still misclassified out of torch.Size([13616]) \n",
      "\n",
      "Model# 12. 4710 nodes still misclassified out of torch.Size([13616]) \n",
      "\n",
      "Model# 13. 4710 nodes still misclassified out of torch.Size([13616]) \n",
      "\n",
      "Model# 14. 4710 nodes still misclassified out of torch.Size([13616]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 15/299 [00:10<03:26,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4710 nodes still misclassified out of torch.Size([13616]) \n",
      "\n",
      "Model# 16. 4710 nodes still misclassified out of torch.Size([13616]) \n",
      "\n",
      "Model# 17. 4710 nodes still misclassified out of torch.Size([13616]) \n",
      "\n",
      "Model# 18. 4710 nodes still misclassified out of torch.Size([13616]) \n",
      "\n",
      "Model# 19. 4710 nodes still misclassified out of torch.Size([13616]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14021/14021 [00:00<00:00, 3304581.73it/s]\n",
      "100%|██████████| 14021/14021 [00:00<00:00, 3808336.77it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2077759.58it/s]\n",
      "Inferring Phrases: 100%|██████████| 14021/14021 [00:00<00:00, 322421.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4990 nodes still misclassified out of torch.Size([14021]) \n",
      "\n",
      "Model# 1. 4990 nodes still misclassified out of torch.Size([14021]) \n",
      "\n",
      "Model# 2. 4990 nodes still misclassified out of torch.Size([14021]) \n",
      "\n",
      "Model# 3. 4990 nodes still misclassified out of torch.Size([14021]) \n",
      "\n",
      "Model# 4. 4990 nodes still misclassified out of torch.Size([14021]) \n",
      "\n",
      "Model# 5. 4990 nodes still misclassified out of torch.Size([14021]) \n",
      "\n",
      "Model# 6. 4990 nodes still misclassified out of torch.Size([14021]) \n",
      "\n",
      "Model# 7. 4990 nodes still misclassified out of torch.Size([14021]) \n",
      "\n",
      "Model# 8. 4990 nodes still misclassified out of torch.Size([14021]) \n",
      "\n",
      "Model# 9. 4990 nodes still misclassified out of torch.Size([14021]) \n",
      "\n",
      "Model# 10. 4990 nodes still misclassified out of torch.Size([14021]) \n",
      "\n",
      "Model# 11. 4990 nodes still misclassified out of torch.Size([14021]) \n",
      "\n",
      "Model# 12. 4990 nodes still misclassified out of torch.Size([14021]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 16/299 [00:11<03:10,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 13. 4990 nodes still misclassified out of torch.Size([14021]) \n",
      "\n",
      "Model# 14. 4990 nodes still misclassified out of torch.Size([14021]) \n",
      "\n",
      "Model# 15. 4990 nodes still misclassified out of torch.Size([14021]) \n",
      "\n",
      "Model# 16. 4990 nodes still misclassified out of torch.Size([14021]) \n",
      "\n",
      "Model# 17. 4990 nodes still misclassified out of torch.Size([14021]) \n",
      "\n",
      "Model# 18. 4990 nodes still misclassified out of torch.Size([14021]) \n",
      "\n",
      "Model# 19. 4990 nodes still misclassified out of torch.Size([14021]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14845/14845 [00:00<00:00, 3892744.16it/s]\n",
      "100%|██████████| 14845/14845 [00:00<00:00, 2949803.05it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1937531.68it/s]\n",
      "Inferring Phrases: 100%|██████████| 14845/14845 [00:00<00:00, 290579.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6171 nodes still misclassified out of torch.Size([14845]) \n",
      "\n",
      "Model# 1. 6171 nodes still misclassified out of torch.Size([14845]) \n",
      "\n",
      "Model# 2. 6171 nodes still misclassified out of torch.Size([14845]) \n",
      "\n",
      "Model# 3. 6171 nodes still misclassified out of torch.Size([14845]) \n",
      "\n",
      "Model# 4. 6171 nodes still misclassified out of torch.Size([14845]) \n",
      "\n",
      "Model# 5. 6171 nodes still misclassified out of torch.Size([14845]) \n",
      "\n",
      "Model# 6. 6171 nodes still misclassified out of torch.Size([14845]) \n",
      "\n",
      "Model# 7. 6171 nodes still misclassified out of torch.Size([14845]) \n",
      "\n",
      "Model# 8. 6171 nodes still misclassified out of torch.Size([14845]) \n",
      "\n",
      "Model# 9. 6171 nodes still misclassified out of torch.Size([14845]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 17/299 [00:12<03:08,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 6171 nodes still misclassified out of torch.Size([14845]) \n",
      "\n",
      "Model# 11. 6171 nodes still misclassified out of torch.Size([14845]) \n",
      "\n",
      "Model# 12. 6171 nodes still misclassified out of torch.Size([14845]) \n",
      "\n",
      "Model# 13. 6171 nodes still misclassified out of torch.Size([14845]) \n",
      "\n",
      "Model# 14. 6171 nodes still misclassified out of torch.Size([14845]) \n",
      "\n",
      "Model# 15. 6171 nodes still misclassified out of torch.Size([14845]) \n",
      "\n",
      "Model# 16. 6171 nodes still misclassified out of torch.Size([14845]) \n",
      "\n",
      "Model# 17. 6171 nodes still misclassified out of torch.Size([14845]) \n",
      "\n",
      "Model# 18. 6171 nodes still misclassified out of torch.Size([14845]) \n",
      "\n",
      "Model# 19. 6171 nodes still misclassified out of torch.Size([14845]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13999/13999 [00:00<00:00, 3420286.70it/s]\n",
      "100%|██████████| 13999/13999 [00:00<00:00, 3940146.40it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2343928.62it/s]\n",
      "Inferring Phrases: 100%|██████████| 13999/13999 [00:00<00:00, 336373.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5014 nodes still misclassified out of torch.Size([13999]) \n",
      "\n",
      "Model# 1. 5014 nodes still misclassified out of torch.Size([13999]) \n",
      "\n",
      "Model# 2. 5014 nodes still misclassified out of torch.Size([13999]) \n",
      "\n",
      "Model# 3. 5014 nodes still misclassified out of torch.Size([13999]) \n",
      "\n",
      "Model# 4. 5014 nodes still misclassified out of torch.Size([13999]) \n",
      "\n",
      "Model# 5. 5014 nodes still misclassified out of torch.Size([13999]) \n",
      "\n",
      "Model# 6. 5014 nodes still misclassified out of torch.Size([13999]) \n",
      "\n",
      "Model# 7. 5014 nodes still misclassified out of torch.Size([13999]) \n",
      "\n",
      "Model# 8. 5014 nodes still misclassified out of torch.Size([13999]) \n",
      "\n",
      "Model# 9. 5014 nodes still misclassified out of torch.Size([13999]) \n",
      "\n",
      "Model# 10. 5014 nodes still misclassified out of torch.Size([13999]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 18/299 [00:12<03:18,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 5014 nodes still misclassified out of torch.Size([13999]) \n",
      "\n",
      "Model# 12. 5014 nodes still misclassified out of torch.Size([13999]) \n",
      "\n",
      "Model# 13. 5014 nodes still misclassified out of torch.Size([13999]) \n",
      "\n",
      "Model# 14. 5014 nodes still misclassified out of torch.Size([13999]) \n",
      "\n",
      "Model# 15. 5014 nodes still misclassified out of torch.Size([13999]) \n",
      "\n",
      "Model# 16. 5014 nodes still misclassified out of torch.Size([13999]) \n",
      "\n",
      "Model# 17. 5014 nodes still misclassified out of torch.Size([13999]) \n",
      "\n",
      "Model# 18. 5014 nodes still misclassified out of torch.Size([13999]) \n",
      "\n",
      "Model# 19. 5014 nodes still misclassified out of torch.Size([13999]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15845/15845 [00:00<00:00, 2423202.32it/s]\n",
      "100%|██████████| 15845/15845 [00:00<00:00, 2904284.70it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1896302.01it/s]\n",
      "Inferring Phrases: 100%|██████████| 15845/15845 [00:00<00:00, 332506.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 7514 nodes still misclassified out of torch.Size([15845]) \n",
      "\n",
      "Model# 1. 7514 nodes still misclassified out of torch.Size([15845]) \n",
      "\n",
      "Model# 2. 7514 nodes still misclassified out of torch.Size([15845]) \n",
      "\n",
      "Model# 3. 7514 nodes still misclassified out of torch.Size([15845]) \n",
      "\n",
      "Model# 4. 7514 nodes still misclassified out of torch.Size([15845]) \n",
      "\n",
      "Model# 5. 7514 nodes still misclassified out of torch.Size([15845]) \n",
      "\n",
      "Model# 6. 7514 nodes still misclassified out of torch.Size([15845]) \n",
      "\n",
      "Model# 7. 7514 nodes still misclassified out of torch.Size([15845]) \n",
      "\n",
      "Model# 8. 7514 nodes still misclassified out of torch.Size([15845]) \n",
      "\n",
      "Model# 9. 7514 nodes still misclassified out of torch.Size([15845]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 19/299 [00:13<03:12,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 7514 nodes still misclassified out of torch.Size([15845]) \n",
      "\n",
      "Model# 11. 7514 nodes still misclassified out of torch.Size([15845]) \n",
      "\n",
      "Model# 12. 7514 nodes still misclassified out of torch.Size([15845]) \n",
      "\n",
      "Model# 13. 7514 nodes still misclassified out of torch.Size([15845]) \n",
      "\n",
      "Model# 14. 7514 nodes still misclassified out of torch.Size([15845]) \n",
      "\n",
      "Model# 15. 7514 nodes still misclassified out of torch.Size([15845]) \n",
      "\n",
      "Model# 16. 7514 nodes still misclassified out of torch.Size([15845]) \n",
      "\n",
      "Model# 17. 7514 nodes still misclassified out of torch.Size([15845]) \n",
      "\n",
      "Model# 18. 7514 nodes still misclassified out of torch.Size([15845]) \n",
      "\n",
      "Model# 19. 7514 nodes still misclassified out of torch.Size([15845]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16078/16078 [00:00<00:00, 3071136.70it/s]\n",
      "100%|██████████| 16078/16078 [00:00<00:00, 4156047.07it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2521676.19it/s]\n",
      "Inferring Phrases: 100%|██████████| 16078/16078 [00:00<00:00, 493693.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 7696 nodes still misclassified out of torch.Size([16078]) \n",
      "\n",
      "Model# 1. 7696 nodes still misclassified out of torch.Size([16078]) \n",
      "\n",
      "Model# 2. 7696 nodes still misclassified out of torch.Size([16078]) \n",
      "\n",
      "Model# 3. 7696 nodes still misclassified out of torch.Size([16078]) \n",
      "\n",
      "Model# 4. 7696 nodes still misclassified out of torch.Size([16078]) \n",
      "\n",
      "Model# 5. 7696 nodes still misclassified out of torch.Size([16078]) \n",
      "\n",
      "Model# 6. 7696 nodes still misclassified out of torch.Size([16078]) \n",
      "\n",
      "Model# 7. 7696 nodes still misclassified out of torch.Size([16078]) \n",
      "\n",
      "Model# 8. 7696 nodes still misclassified out of torch.Size([16078]) \n",
      "\n",
      "Model# 9. 7696 nodes still misclassified out of torch.Size([16078]) \n",
      "\n",
      "Model# 10. 7696 nodes still misclassified out of torch.Size([16078]) \n",
      "\n",
      "Model# 11. 7696 nodes still misclassified out of torch.Size([16078]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/299 [00:14<03:13,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 12. 7696 nodes still misclassified out of torch.Size([16078]) \n",
      "\n",
      "Model# 13. 7696 nodes still misclassified out of torch.Size([16078]) \n",
      "\n",
      "Model# 14. 7696 nodes still misclassified out of torch.Size([16078]) \n",
      "\n",
      "Model# 15. 7696 nodes still misclassified out of torch.Size([16078]) \n",
      "\n",
      "Model# 16. 7696 nodes still misclassified out of torch.Size([16078]) \n",
      "\n",
      "Model# 17. 7696 nodes still misclassified out of torch.Size([16078]) \n",
      "\n",
      "Model# 18. 7696 nodes still misclassified out of torch.Size([16078]) \n",
      "\n",
      "Model# 19. 7696 nodes still misclassified out of torch.Size([16078]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16300/16300 [00:00<00:00, 4174328.68it/s]\n",
      "100%|██████████| 16300/16300 [00:00<00:00, 4762270.49it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2827874.87it/s]\n",
      "Inferring Phrases: 100%|██████████| 16300/16300 [00:00<00:00, 441497.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 7955 nodes still misclassified out of torch.Size([16300]) \n",
      "\n",
      "Model# 1. 7955 nodes still misclassified out of torch.Size([16300]) \n",
      "\n",
      "Model# 2. 7955 nodes still misclassified out of torch.Size([16300]) \n",
      "\n",
      "Model# 3. 7955 nodes still misclassified out of torch.Size([16300]) \n",
      "\n",
      "Model# 4. 7955 nodes still misclassified out of torch.Size([16300]) \n",
      "\n",
      "Model# 5. 7955 nodes still misclassified out of torch.Size([16300]) \n",
      "\n",
      "Model# 6. 7955 nodes still misclassified out of torch.Size([16300]) \n",
      "\n",
      "Model# 7. 7955 nodes still misclassified out of torch.Size([16300]) \n",
      "\n",
      "Model# 8. 7955 nodes still misclassified out of torch.Size([16300]) \n",
      "\n",
      "Model# 9. 7955 nodes still misclassified out of torch.Size([16300]) \n",
      "\n",
      "Model# 10. 7955 nodes still misclassified out of torch.Size([16300]) \n",
      "\n",
      "Model# 11. 7955 nodes still misclassified out of torch.Size([16300]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 21/299 [00:14<03:01,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 12. 7955 nodes still misclassified out of torch.Size([16300]) \n",
      "\n",
      "Model# 13. 7955 nodes still misclassified out of torch.Size([16300]) \n",
      "\n",
      "Model# 14. 7955 nodes still misclassified out of torch.Size([16300]) \n",
      "\n",
      "Model# 15. 7955 nodes still misclassified out of torch.Size([16300]) \n",
      "\n",
      "Model# 16. 7955 nodes still misclassified out of torch.Size([16300]) \n",
      "\n",
      "Model# 17. 7955 nodes still misclassified out of torch.Size([16300]) \n",
      "\n",
      "Model# 18. 7955 nodes still misclassified out of torch.Size([16300]) \n",
      "\n",
      "Model# 19. 7955 nodes still misclassified out of torch.Size([16300]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14945/14945 [00:00<00:00, 3851780.34it/s]\n",
      "100%|██████████| 14945/14945 [00:00<00:00, 4695069.53it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2562606.82it/s]\n",
      "Inferring Phrases: 100%|██████████| 14945/14945 [00:00<00:00, 378210.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6369 nodes still misclassified out of torch.Size([14945]) \n",
      "\n",
      "Model# 1. 6369 nodes still misclassified out of torch.Size([14945]) \n",
      "\n",
      "Model# 2. 6369 nodes still misclassified out of torch.Size([14945]) \n",
      "\n",
      "Model# 3. 6369 nodes still misclassified out of torch.Size([14945]) \n",
      "\n",
      "Model# 4. 6369 nodes still misclassified out of torch.Size([14945]) \n",
      "\n",
      "Model# 5. 6369 nodes still misclassified out of torch.Size([14945]) \n",
      "\n",
      "Model# 6. 6369 nodes still misclassified out of torch.Size([14945]) \n",
      "\n",
      "Model# 7. 6369 nodes still misclassified out of torch.Size([14945]) \n",
      "\n",
      "Model# 8. 6369 nodes still misclassified out of torch.Size([14945]) \n",
      "\n",
      "Model# 9. 6369 nodes still misclassified out of torch.Size([14945]) \n",
      "\n",
      "Model# 10. 6369 nodes still misclassified out of torch.Size([14945]) \n",
      "\n",
      "Model# 11. 6369 nodes still misclassified out of torch.Size([14945]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 22/299 [00:15<02:50,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 12. 6369 nodes still misclassified out of torch.Size([14945]) \n",
      "\n",
      "Model# 13. 6369 nodes still misclassified out of torch.Size([14945]) \n",
      "\n",
      "Model# 14. 6369 nodes still misclassified out of torch.Size([14945]) \n",
      "\n",
      "Model# 15. 6369 nodes still misclassified out of torch.Size([14945]) \n",
      "\n",
      "Model# 16. 6369 nodes still misclassified out of torch.Size([14945]) \n",
      "\n",
      "Model# 17. 6369 nodes still misclassified out of torch.Size([14945]) \n",
      "\n",
      "Model# 18. 6369 nodes still misclassified out of torch.Size([14945]) \n",
      "\n",
      "Model# 19. 6369 nodes still misclassified out of torch.Size([14945]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15958/15958 [00:00<00:00, 4088492.04it/s]\n",
      "100%|██████████| 15958/15958 [00:00<00:00, 5004688.44it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2570091.71it/s]\n",
      "Inferring Phrases: 100%|██████████| 15958/15958 [00:00<00:00, 457471.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 7650 nodes still misclassified out of torch.Size([15958]) \n",
      "\n",
      "Model# 1. 7650 nodes still misclassified out of torch.Size([15958]) \n",
      "\n",
      "Model# 2. 7650 nodes still misclassified out of torch.Size([15958]) \n",
      "\n",
      "Model# 3. 7650 nodes still misclassified out of torch.Size([15958]) \n",
      "\n",
      "Model# 4. 7650 nodes still misclassified out of torch.Size([15958]) \n",
      "\n",
      "Model# 5. 7650 nodes still misclassified out of torch.Size([15958]) \n",
      "\n",
      "Model# 6. 7650 nodes still misclassified out of torch.Size([15958]) \n",
      "\n",
      "Model# 7. 7650 nodes still misclassified out of torch.Size([15958]) \n",
      "\n",
      "Model# 8. 7650 nodes still misclassified out of torch.Size([15958]) \n",
      "\n",
      "Model# 9. 7650 nodes still misclassified out of torch.Size([15958]) \n",
      "\n",
      "Model# 10. 7650 nodes still misclassified out of torch.Size([15958]) \n",
      "\n",
      "Model# 11. 7650 nodes still misclassified out of torch.Size([15958]) \n",
      "\n",
      "Model# 12. 7650 nodes still misclassified out of torch.Size([15958]) \n",
      "\n",
      "Model# 13. 7650 nodes still misclassified out of torch.Size([15958]) \n",
      "\n",
      "Model# 14. 7650 nodes still misclassified out of torch.Size([15958]) \n",
      "\n",
      "Model# 15. 7650 nodes still misclassified out of torch.Size([15958]) \n",
      "\n",
      "Model# 16. 7650 nodes still misclassified out of torch.Size([15958]) \n",
      "\n",
      "Model# 17. 7650 nodes still misclassified out of torch.Size([15958]) \n",
      "\n",
      "Model# 18. 7650 nodes still misclassified out of torch.Size([15958]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 23/299 [00:16<03:08,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 7650 nodes still misclassified out of torch.Size([15958]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15107/15107 [00:00<00:00, 2380648.88it/s]\n",
      "100%|██████████| 15107/15107 [00:00<00:00, 3478826.76it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2690783.74it/s]\n",
      "Inferring Phrases: 100%|██████████| 15107/15107 [00:00<00:00, 430305.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6046 nodes still misclassified out of torch.Size([15107]) \n",
      "\n",
      "Model# 1. 6046 nodes still misclassified out of torch.Size([15107]) \n",
      "\n",
      "Model# 2. 6046 nodes still misclassified out of torch.Size([15107]) \n",
      "\n",
      "Model# 3. 6046 nodes still misclassified out of torch.Size([15107]) \n",
      "\n",
      "Model# 4. 6046 nodes still misclassified out of torch.Size([15107]) \n",
      "\n",
      "Model# 5. 6046 nodes still misclassified out of torch.Size([15107]) \n",
      "\n",
      "Model# 6. 6046 nodes still misclassified out of torch.Size([15107]) \n",
      "\n",
      "Model# 7. 6046 nodes still misclassified out of torch.Size([15107]) \n",
      "\n",
      "Model# 8. 6046 nodes still misclassified out of torch.Size([15107]) \n",
      "\n",
      "Model# 9. 6046 nodes still misclassified out of torch.Size([15107]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 24/299 [00:16<03:02,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 6046 nodes still misclassified out of torch.Size([15107]) \n",
      "\n",
      "Model# 11. 6046 nodes still misclassified out of torch.Size([15107]) \n",
      "\n",
      "Model# 12. 6046 nodes still misclassified out of torch.Size([15107]) \n",
      "\n",
      "Model# 13. 6046 nodes still misclassified out of torch.Size([15107]) \n",
      "\n",
      "Model# 14. 6046 nodes still misclassified out of torch.Size([15107]) \n",
      "\n",
      "Model# 15. 6046 nodes still misclassified out of torch.Size([15107]) \n",
      "\n",
      "Model# 16. 6046 nodes still misclassified out of torch.Size([15107]) \n",
      "\n",
      "Model# 17. 6046 nodes still misclassified out of torch.Size([15107]) \n",
      "\n",
      "Model# 18. 6046 nodes still misclassified out of torch.Size([15107]) \n",
      "\n",
      "Model# 19. 6046 nodes still misclassified out of torch.Size([15107]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14318/14318 [00:00<00:00, 3817075.23it/s]\n",
      "100%|██████████| 14318/14318 [00:00<00:00, 4554724.66it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2637595.27it/s]\n",
      "Inferring Phrases: 100%|██████████| 14318/14318 [00:00<00:00, 417244.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5416 nodes still misclassified out of torch.Size([14318]) \n",
      "\n",
      "Model# 1. 5416 nodes still misclassified out of torch.Size([14318]) \n",
      "\n",
      "Model# 2. 5416 nodes still misclassified out of torch.Size([14318]) \n",
      "\n",
      "Model# 3. 5416 nodes still misclassified out of torch.Size([14318]) \n",
      "\n",
      "Model# 4. 5416 nodes still misclassified out of torch.Size([14318]) \n",
      "\n",
      "Model# 5. 5416 nodes still misclassified out of torch.Size([14318]) \n",
      "\n",
      "Model# 6. 5416 nodes still misclassified out of torch.Size([14318]) \n",
      "\n",
      "Model# 7. 5416 nodes still misclassified out of torch.Size([14318]) \n",
      "\n",
      "Model# 8. 5416 nodes still misclassified out of torch.Size([14318]) \n",
      "\n",
      "Model# 9. 5416 nodes still misclassified out of torch.Size([14318]) \n",
      "\n",
      "Model# 10. 5416 nodes still misclassified out of torch.Size([14318]) \n",
      "\n",
      "Model# 11. 5416 nodes still misclassified out of torch.Size([14318]) \n",
      "\n",
      "Model# 12. 5416 nodes still misclassified out of torch.Size([14318]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 25/299 [00:17<02:52,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 13. 5416 nodes still misclassified out of torch.Size([14318]) \n",
      "\n",
      "Model# 14. 5416 nodes still misclassified out of torch.Size([14318]) \n",
      "\n",
      "Model# 15. 5416 nodes still misclassified out of torch.Size([14318]) \n",
      "\n",
      "Model# 16. 5416 nodes still misclassified out of torch.Size([14318]) \n",
      "\n",
      "Model# 17. 5416 nodes still misclassified out of torch.Size([14318]) \n",
      "\n",
      "Model# 18. 5416 nodes still misclassified out of torch.Size([14318]) \n",
      "\n",
      "Model# 19. 5416 nodes still misclassified out of torch.Size([14318]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14211/14211 [00:00<00:00, 3675706.35it/s]\n",
      "100%|██████████| 14211/14211 [00:00<00:00, 4418149.44it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2475245.80it/s]\n",
      "Inferring Phrases: 100%|██████████| 14211/14211 [00:00<00:00, 420718.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5687 nodes still misclassified out of torch.Size([14211]) \n",
      "\n",
      "Model# 1. 5687 nodes still misclassified out of torch.Size([14211]) \n",
      "\n",
      "Model# 2. 5687 nodes still misclassified out of torch.Size([14211]) \n",
      "\n",
      "Model# 3. 5687 nodes still misclassified out of torch.Size([14211]) \n",
      "\n",
      "Model# 4. 5687 nodes still misclassified out of torch.Size([14211]) \n",
      "\n",
      "Model# 5. 5687 nodes still misclassified out of torch.Size([14211]) \n",
      "\n",
      "Model# 6. 5687 nodes still misclassified out of torch.Size([14211]) \n",
      "\n",
      "Model# 7. 5687 nodes still misclassified out of torch.Size([14211]) \n",
      "\n",
      "Model# 8. 5687 nodes still misclassified out of torch.Size([14211]) \n",
      "\n",
      "Model# 9. 5687 nodes still misclassified out of torch.Size([14211]) \n",
      "\n",
      "Model# 10. 5687 nodes still misclassified out of torch.Size([14211]) \n",
      "\n",
      "Model# 11. 5687 nodes still misclassified out of torch.Size([14211]) \n",
      "\n",
      "Model# 12. 5687 nodes still misclassified out of torch.Size([14211]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 26/299 [00:17<02:56,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 13. 5687 nodes still misclassified out of torch.Size([14211]) \n",
      "\n",
      "Model# 14. 5687 nodes still misclassified out of torch.Size([14211]) \n",
      "\n",
      "Model# 15. 5687 nodes still misclassified out of torch.Size([14211]) \n",
      "\n",
      "Model# 16. 5687 nodes still misclassified out of torch.Size([14211]) \n",
      "\n",
      "Model# 17. 5687 nodes still misclassified out of torch.Size([14211]) \n",
      "\n",
      "Model# 18. 5687 nodes still misclassified out of torch.Size([14211]) \n",
      "\n",
      "Model# 19. 5687 nodes still misclassified out of torch.Size([14211]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13525/13525 [00:00<00:00, 2646634.39it/s]\n",
      "100%|██████████| 13525/13525 [00:00<00:00, 2955812.92it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1981873.05it/s]\n",
      "Inferring Phrases: 100%|██████████| 13525/13525 [00:00<00:00, 264559.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4637 nodes still misclassified out of torch.Size([13525]) \n",
      "\n",
      "Model# 1. 4637 nodes still misclassified out of torch.Size([13525]) \n",
      "\n",
      "Model# 2. 4637 nodes still misclassified out of torch.Size([13525]) \n",
      "\n",
      "Model# 3. 4637 nodes still misclassified out of torch.Size([13525]) \n",
      "\n",
      "Model# 4. 4637 nodes still misclassified out of torch.Size([13525]) \n",
      "\n",
      "Model# 5. 4637 nodes still misclassified out of torch.Size([13525]) \n",
      "\n",
      "Model# 6. 4637 nodes still misclassified out of torch.Size([13525]) \n",
      "\n",
      "Model# 7. 4637 nodes still misclassified out of torch.Size([13525]) \n",
      "\n",
      "Model# 8. 4637 nodes still misclassified out of torch.Size([13525]) \n",
      "\n",
      "Model# 9. 4637 nodes still misclassified out of torch.Size([13525]) \n",
      "\n",
      "Model# 10. 4637 nodes still misclassified out of torch.Size([13525]) \n",
      "\n",
      "Model# 11. 4637 nodes still misclassified out of torch.Size([13525]) \n",
      "\n",
      "Model# 12. 4637 nodes still misclassified out of torch.Size([13525]) \n",
      "\n",
      "Model# 13. 4637 nodes still misclassified out of torch.Size([13525]) \n",
      "\n",
      "Model# 14. 4637 nodes still misclassified out of torch.Size([13525]) \n",
      "\n",
      "Model# 15. 4637 nodes still misclassified out of torch.Size([13525]) \n",
      "\n",
      "Model# 16. 4637 nodes still misclassified out of torch.Size([13525]) \n",
      "\n",
      "Model# 17. 4637 nodes still misclassified out of torch.Size([13525]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 27/299 [00:18<02:41,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 18. 4637 nodes still misclassified out of torch.Size([13525]) \n",
      "\n",
      "Model# 19. 4637 nodes still misclassified out of torch.Size([13525]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14039/14039 [00:00<00:00, 4028448.65it/s]\n",
      "100%|██████████| 14039/14039 [00:00<00:00, 4637983.13it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2643913.26it/s]\n",
      "Inferring Phrases: 100%|██████████| 14039/14039 [00:00<00:00, 403626.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5493 nodes still misclassified out of torch.Size([14039]) \n",
      "\n",
      "Model# 1. 5493 nodes still misclassified out of torch.Size([14039]) \n",
      "\n",
      "Model# 2. 5493 nodes still misclassified out of torch.Size([14039]) \n",
      "\n",
      "Model# 3. 5493 nodes still misclassified out of torch.Size([14039]) \n",
      "\n",
      "Model# 4. 5493 nodes still misclassified out of torch.Size([14039]) \n",
      "\n",
      "Model# 5. 5493 nodes still misclassified out of torch.Size([14039]) \n",
      "\n",
      "Model# 6. 5493 nodes still misclassified out of torch.Size([14039]) \n",
      "\n",
      "Model# 7. 5493 nodes still misclassified out of torch.Size([14039]) \n",
      "\n",
      "Model# 8. 5493 nodes still misclassified out of torch.Size([14039]) \n",
      "\n",
      "Model# 9. 5493 nodes still misclassified out of torch.Size([14039]) \n",
      "\n",
      "Model# 10. 5493 nodes still misclassified out of torch.Size([14039]) \n",
      "\n",
      "Model# 11. 5493 nodes still misclassified out of torch.Size([14039]) \n",
      "\n",
      "Model# 12. 5493 nodes still misclassified out of torch.Size([14039]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 28/299 [00:18<02:35,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 13. 5493 nodes still misclassified out of torch.Size([14039]) \n",
      "\n",
      "Model# 14. 5493 nodes still misclassified out of torch.Size([14039]) \n",
      "\n",
      "Model# 15. 5493 nodes still misclassified out of torch.Size([14039]) \n",
      "\n",
      "Model# 16. 5493 nodes still misclassified out of torch.Size([14039]) \n",
      "\n",
      "Model# 17. 5493 nodes still misclassified out of torch.Size([14039]) \n",
      "\n",
      "Model# 18. 5493 nodes still misclassified out of torch.Size([14039]) \n",
      "\n",
      "Model# 19. 5493 nodes still misclassified out of torch.Size([14039]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13338/13338 [00:00<00:00, 4211354.02it/s]\n",
      "100%|██████████| 13338/13338 [00:00<00:00, 5194876.66it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 3070350.89it/s]\n",
      "Inferring Phrases: 100%|██████████| 13338/13338 [00:00<00:00, 428907.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4870 nodes still misclassified out of torch.Size([13338]) \n",
      "\n",
      "Model# 1. 4870 nodes still misclassified out of torch.Size([13338]) \n",
      "\n",
      "Model# 2. 4870 nodes still misclassified out of torch.Size([13338]) \n",
      "\n",
      "Model# 3. 4870 nodes still misclassified out of torch.Size([13338]) \n",
      "\n",
      "Model# 4. 4870 nodes still misclassified out of torch.Size([13338]) \n",
      "\n",
      "Model# 5. 4870 nodes still misclassified out of torch.Size([13338]) \n",
      "\n",
      "Model# 6. 4870 nodes still misclassified out of torch.Size([13338]) \n",
      "\n",
      "Model# 7. 4870 nodes still misclassified out of torch.Size([13338]) \n",
      "\n",
      "Model# 8. 4870 nodes still misclassified out of torch.Size([13338]) \n",
      "\n",
      "Model# 9. 4870 nodes still misclassified out of torch.Size([13338]) \n",
      "\n",
      "Model# 10. 4870 nodes still misclassified out of torch.Size([13338]) \n",
      "\n",
      "Model# 11. 4870 nodes still misclassified out of torch.Size([13338]) \n",
      "\n",
      "Model# 12. 4870 nodes still misclassified out of torch.Size([13338]) \n",
      "\n",
      "Model# 13. 4870 nodes still misclassified out of torch.Size([13338]) \n",
      "\n",
      "Model# 14. 4870 nodes still misclassified out of torch.Size([13338]) \n",
      "\n",
      "Model# 15. 4870 nodes still misclassified out of torch.Size([13338]) \n",
      "\n",
      "Model# 16. 4870 nodes still misclassified out of torch.Size([13338]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 29/299 [00:19<02:37,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 17. 4870 nodes still misclassified out of torch.Size([13338]) \n",
      "\n",
      "Model# 18. 4870 nodes still misclassified out of torch.Size([13338]) \n",
      "\n",
      "Model# 19. 4870 nodes still misclassified out of torch.Size([13338]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13416/13416 [00:00<00:00, 3973644.69it/s]\n",
      "100%|██████████| 13416/13416 [00:00<00:00, 4592408.59it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2791116.63it/s]\n",
      "Inferring Phrases: 100%|██████████| 13416/13416 [00:00<00:00, 397333.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4647 nodes still misclassified out of torch.Size([13416]) \n",
      "\n",
      "Model# 1. 4647 nodes still misclassified out of torch.Size([13416]) \n",
      "\n",
      "Model# 2. 4647 nodes still misclassified out of torch.Size([13416]) \n",
      "\n",
      "Model# 3. 4647 nodes still misclassified out of torch.Size([13416]) \n",
      "\n",
      "Model# 4. 4647 nodes still misclassified out of torch.Size([13416]) \n",
      "\n",
      "Model# 5. 4647 nodes still misclassified out of torch.Size([13416]) \n",
      "\n",
      "Model# 6. 4647 nodes still misclassified out of torch.Size([13416]) \n",
      "\n",
      "Model# 7. 4647 nodes still misclassified out of torch.Size([13416]) \n",
      "\n",
      "Model# 8. 4647 nodes still misclassified out of torch.Size([13416]) \n",
      "\n",
      "Model# 9. 4647 nodes still misclassified out of torch.Size([13416]) \n",
      "\n",
      "Model# 10. 4647 nodes still misclassified out of torch.Size([13416]) \n",
      "\n",
      "Model# 11. 4647 nodes still misclassified out of torch.Size([13416]) \n",
      "\n",
      "Model# 12. 4647 nodes still misclassified out of torch.Size([13416]) \n",
      "\n",
      "Model# 13. 4647 nodes still misclassified out of torch.Size([13416]) \n",
      "\n",
      "Model# 14. 4647 nodes still misclassified out of torch.Size([13416]) \n",
      "\n",
      "Model# 15. 4647 nodes still misclassified out of torch.Size([13416]) \n",
      "\n",
      "Model# 16. 4647 nodes still misclassified out of torch.Size([13416]) \n",
      "\n",
      "Model# 17. 4647 nodes still misclassified out of torch.Size([13416]) \n",
      "\n",
      "Model# 18. 4647 nodes still misclassified out of torch.Size([13416]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 30/299 [00:19<02:23,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4647 nodes still misclassified out of torch.Size([13416]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13052/13052 [00:00<00:00, 4473650.06it/s]\n",
      "100%|██████████| 13052/13052 [00:00<00:00, 5270439.57it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2875502.64it/s]\n",
      "Inferring Phrases: 100%|██████████| 13052/13052 [00:00<00:00, 426974.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3570 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 1. 3570 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 2. 3570 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 3. 3570 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 4. 3570 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 5. 3570 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 6. 3570 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 7. 3570 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 8. 3570 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 9. 3570 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 10. 3570 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 11. 3570 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 12. 3570 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 13. 3570 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 14. 3570 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 15. 3570 nodes still misclassified out of torch.Size([13052]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 31/299 [00:20<02:31,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 16. 3570 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 17. 3570 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 18. 3570 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 19. 3570 nodes still misclassified out of torch.Size([13052]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13045/13045 [00:00<00:00, 2642711.34it/s]\n",
      "100%|██████████| 13045/13045 [00:00<00:00, 2951488.60it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1965650.01it/s]\n",
      "Inferring Phrases: 100%|██████████| 13045/13045 [00:00<00:00, 370033.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5106 nodes still misclassified out of torch.Size([13045]) \n",
      "\n",
      "Model# 1. 5106 nodes still misclassified out of torch.Size([13045]) \n",
      "\n",
      "Model# 2. 5106 nodes still misclassified out of torch.Size([13045]) \n",
      "\n",
      "Model# 3. 5106 nodes still misclassified out of torch.Size([13045]) \n",
      "\n",
      "Model# 4. 5106 nodes still misclassified out of torch.Size([13045]) \n",
      "\n",
      "Model# 5. 5106 nodes still misclassified out of torch.Size([13045]) \n",
      "\n",
      "Model# 6. 5106 nodes still misclassified out of torch.Size([13045]) \n",
      "\n",
      "Model# 7. 5106 nodes still misclassified out of torch.Size([13045]) \n",
      "\n",
      "Model# 8. 5106 nodes still misclassified out of torch.Size([13045]) \n",
      "\n",
      "Model# 9. 5106 nodes still misclassified out of torch.Size([13045]) \n",
      "\n",
      "Model# 10. 5106 nodes still misclassified out of torch.Size([13045]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 32/299 [00:21<02:36,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 5106 nodes still misclassified out of torch.Size([13045]) \n",
      "\n",
      "Model# 12. 5106 nodes still misclassified out of torch.Size([13045]) \n",
      "\n",
      "Model# 13. 5106 nodes still misclassified out of torch.Size([13045]) \n",
      "\n",
      "Model# 14. 5106 nodes still misclassified out of torch.Size([13045]) \n",
      "\n",
      "Model# 15. 5106 nodes still misclassified out of torch.Size([13045]) \n",
      "\n",
      "Model# 16. 5106 nodes still misclassified out of torch.Size([13045]) \n",
      "\n",
      "Model# 17. 5106 nodes still misclassified out of torch.Size([13045]) \n",
      "\n",
      "Model# 18. 5106 nodes still misclassified out of torch.Size([13045]) \n",
      "\n",
      "Model# 19. 5106 nodes still misclassified out of torch.Size([13045]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13438/13438 [00:00<00:00, 2543344.49it/s]\n",
      "100%|██████████| 13438/13438 [00:00<00:00, 2969133.29it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1932621.49it/s]\n",
      "Inferring Phrases: 100%|██████████| 13438/13438 [00:00<00:00, 387071.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4954 nodes still misclassified out of torch.Size([13438]) \n",
      "\n",
      "Model# 1. 4954 nodes still misclassified out of torch.Size([13438]) \n",
      "\n",
      "Model# 2. 4954 nodes still misclassified out of torch.Size([13438]) \n",
      "\n",
      "Model# 3. 4954 nodes still misclassified out of torch.Size([13438]) \n",
      "\n",
      "Model# 4. 4954 nodes still misclassified out of torch.Size([13438]) \n",
      "\n",
      "Model# 5. 4954 nodes still misclassified out of torch.Size([13438]) \n",
      "\n",
      "Model# 6. 4954 nodes still misclassified out of torch.Size([13438]) \n",
      "\n",
      "Model# 7. 4954 nodes still misclassified out of torch.Size([13438]) \n",
      "\n",
      "Model# 8. 4954 nodes still misclassified out of torch.Size([13438]) \n",
      "\n",
      "Model# 9. 4954 nodes still misclassified out of torch.Size([13438]) \n",
      "\n",
      "Model# 10. 4954 nodes still misclassified out of torch.Size([13438]) \n",
      "\n",
      "Model# 11. 4954 nodes still misclassified out of torch.Size([13438]) \n",
      "\n",
      "Model# 12. 4954 nodes still misclassified out of torch.Size([13438]) \n",
      "\n",
      "Model# 13. 4954 nodes still misclassified out of torch.Size([13438]) \n",
      "\n",
      "Model# 14. 4954 nodes still misclassified out of torch.Size([13438]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 33/299 [00:21<02:31,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4954 nodes still misclassified out of torch.Size([13438]) \n",
      "\n",
      "Model# 16. 4954 nodes still misclassified out of torch.Size([13438]) \n",
      "\n",
      "Model# 17. 4954 nodes still misclassified out of torch.Size([13438]) \n",
      "\n",
      "Model# 18. 4954 nodes still misclassified out of torch.Size([13438]) \n",
      "\n",
      "Model# 19. 4954 nodes still misclassified out of torch.Size([13438]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13131/13131 [00:00<00:00, 4453416.82it/s]\n",
      "100%|██████████| 13131/13131 [00:00<00:00, 5302340.02it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2844753.12it/s]\n",
      "Inferring Phrases: 100%|██████████| 13131/13131 [00:00<00:00, 418553.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4805 nodes still misclassified out of torch.Size([13131]) \n",
      "\n",
      "Model# 1. 4805 nodes still misclassified out of torch.Size([13131]) \n",
      "\n",
      "Model# 2. 4805 nodes still misclassified out of torch.Size([13131]) \n",
      "\n",
      "Model# 3. 4805 nodes still misclassified out of torch.Size([13131]) \n",
      "\n",
      "Model# 4. 4805 nodes still misclassified out of torch.Size([13131]) \n",
      "\n",
      "Model# 5. 4805 nodes still misclassified out of torch.Size([13131]) \n",
      "\n",
      "Model# 6. 4805 nodes still misclassified out of torch.Size([13131]) \n",
      "\n",
      "Model# 7. 4805 nodes still misclassified out of torch.Size([13131]) \n",
      "\n",
      "Model# 8. 4805 nodes still misclassified out of torch.Size([13131]) \n",
      "\n",
      "Model# 9. 4805 nodes still misclassified out of torch.Size([13131]) \n",
      "\n",
      "Model# 10. 4805 nodes still misclassified out of torch.Size([13131]) \n",
      "\n",
      "Model# 11. 4805 nodes still misclassified out of torch.Size([13131]) \n",
      "\n",
      "Model# 12. 4805 nodes still misclassified out of torch.Size([13131]) \n",
      "\n",
      "Model# 13. 4805 nodes still misclassified out of torch.Size([13131]) \n",
      "\n",
      "Model# 14. 4805 nodes still misclassified out of torch.Size([13131]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 34/299 [00:22<02:35,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4805 nodes still misclassified out of torch.Size([13131]) \n",
      "\n",
      "Model# 16. 4805 nodes still misclassified out of torch.Size([13131]) \n",
      "\n",
      "Model# 17. 4805 nodes still misclassified out of torch.Size([13131]) \n",
      "\n",
      "Model# 18. 4805 nodes still misclassified out of torch.Size([13131]) \n",
      "\n",
      "Model# 19. 4805 nodes still misclassified out of torch.Size([13131]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12781/12781 [00:00<00:00, 4105015.65it/s]\n",
      "100%|██████████| 12781/12781 [00:00<00:00, 4690881.99it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2831820.68it/s]\n",
      "Inferring Phrases: 100%|██████████| 12781/12781 [00:00<00:00, 387560.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4317 nodes still misclassified out of torch.Size([12781]) \n",
      "\n",
      "Model# 1. 4317 nodes still misclassified out of torch.Size([12781]) \n",
      "\n",
      "Model# 2. 4317 nodes still misclassified out of torch.Size([12781]) \n",
      "\n",
      "Model# 3. 4317 nodes still misclassified out of torch.Size([12781]) \n",
      "\n",
      "Model# 4. 4317 nodes still misclassified out of torch.Size([12781]) \n",
      "\n",
      "Model# 5. 4317 nodes still misclassified out of torch.Size([12781]) \n",
      "\n",
      "Model# 6. 4317 nodes still misclassified out of torch.Size([12781]) \n",
      "\n",
      "Model# 7. 4317 nodes still misclassified out of torch.Size([12781]) \n",
      "\n",
      "Model# 8. 4317 nodes still misclassified out of torch.Size([12781]) \n",
      "\n",
      "Model# 9. 4317 nodes still misclassified out of torch.Size([12781]) \n",
      "\n",
      "Model# 10. 4317 nodes still misclassified out of torch.Size([12781]) \n",
      "\n",
      "Model# 11. 4317 nodes still misclassified out of torch.Size([12781]) \n",
      "\n",
      "Model# 12. 4317 nodes still misclassified out of torch.Size([12781]) \n",
      "\n",
      "Model# 13. 4317 nodes still misclassified out of torch.Size([12781]) \n",
      "\n",
      "Model# 14. 4317 nodes still misclassified out of torch.Size([12781]) \n",
      "\n",
      "Model# 15. 4317 nodes still misclassified out of torch.Size([12781]) \n",
      "\n",
      "Model# 16. 4317 nodes still misclassified out of torch.Size([12781]) \n",
      "\n",
      "Model# 17. 4317 nodes still misclassified out of torch.Size([12781]) \n",
      "\n",
      "Model# 18. 4317 nodes still misclassified out of torch.Size([12781]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 35/299 [00:22<02:20,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4317 nodes still misclassified out of torch.Size([12781]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14867/14867 [00:00<00:00, 4213861.17it/s]\n",
      "100%|██████████| 14867/14867 [00:00<00:00, 5115818.98it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2840130.01it/s]\n",
      "Inferring Phrases: 100%|██████████| 14867/14867 [00:00<00:00, 470901.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6158 nodes still misclassified out of torch.Size([14867]) \n",
      "\n",
      "Model# 1. 6158 nodes still misclassified out of torch.Size([14867]) \n",
      "\n",
      "Model# 2. 6158 nodes still misclassified out of torch.Size([14867]) \n",
      "\n",
      "Model# 3. 6158 nodes still misclassified out of torch.Size([14867]) \n",
      "\n",
      "Model# 4. 6158 nodes still misclassified out of torch.Size([14867]) \n",
      "\n",
      "Model# 5. 6158 nodes still misclassified out of torch.Size([14867]) \n",
      "\n",
      "Model# 6. 6158 nodes still misclassified out of torch.Size([14867]) \n",
      "\n",
      "Model# 7. 6158 nodes still misclassified out of torch.Size([14867]) \n",
      "\n",
      "Model# 8. 6158 nodes still misclassified out of torch.Size([14867]) \n",
      "\n",
      "Model# 9. 6158 nodes still misclassified out of torch.Size([14867]) \n",
      "\n",
      "Model# 10. 6158 nodes still misclassified out of torch.Size([14867]) \n",
      "\n",
      "Model# 11. 6158 nodes still misclassified out of torch.Size([14867]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 36/299 [00:23<02:30,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 12. 6158 nodes still misclassified out of torch.Size([14867]) \n",
      "\n",
      "Model# 13. 6158 nodes still misclassified out of torch.Size([14867]) \n",
      "\n",
      "Model# 14. 6158 nodes still misclassified out of torch.Size([14867]) \n",
      "\n",
      "Model# 15. 6158 nodes still misclassified out of torch.Size([14867]) \n",
      "\n",
      "Model# 16. 6158 nodes still misclassified out of torch.Size([14867]) \n",
      "\n",
      "Model# 17. 6158 nodes still misclassified out of torch.Size([14867]) \n",
      "\n",
      "Model# 18. 6158 nodes still misclassified out of torch.Size([14867]) \n",
      "\n",
      "Model# 19. 6158 nodes still misclassified out of torch.Size([14867]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14439/14439 [00:00<00:00, 4026163.77it/s]\n",
      "100%|██████████| 14439/14439 [00:00<00:00, 4614565.33it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2785987.38it/s]\n",
      "Inferring Phrases: 100%|██████████| 14439/14439 [00:00<00:00, 418187.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5566 nodes still misclassified out of torch.Size([14439]) \n",
      "\n",
      "Model# 1. 5566 nodes still misclassified out of torch.Size([14439]) \n",
      "\n",
      "Model# 2. 5566 nodes still misclassified out of torch.Size([14439]) \n",
      "\n",
      "Model# 3. 5566 nodes still misclassified out of torch.Size([14439]) \n",
      "\n",
      "Model# 4. 5566 nodes still misclassified out of torch.Size([14439]) \n",
      "\n",
      "Model# 5. 5566 nodes still misclassified out of torch.Size([14439]) \n",
      "\n",
      "Model# 6. 5566 nodes still misclassified out of torch.Size([14439]) \n",
      "\n",
      "Model# 7. 5566 nodes still misclassified out of torch.Size([14439]) \n",
      "\n",
      "Model# 8. 5566 nodes still misclassified out of torch.Size([14439]) \n",
      "\n",
      "Model# 9. 5566 nodes still misclassified out of torch.Size([14439]) \n",
      "\n",
      "Model# 10. 5566 nodes still misclassified out of torch.Size([14439]) \n",
      "\n",
      "Model# 11. 5566 nodes still misclassified out of torch.Size([14439]) \n",
      "\n",
      "Model# 12. 5566 nodes still misclassified out of torch.Size([14439]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 37/299 [00:23<02:25,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 13. 5566 nodes still misclassified out of torch.Size([14439]) \n",
      "\n",
      "Model# 14. 5566 nodes still misclassified out of torch.Size([14439]) \n",
      "\n",
      "Model# 15. 5566 nodes still misclassified out of torch.Size([14439]) \n",
      "\n",
      "Model# 16. 5566 nodes still misclassified out of torch.Size([14439]) \n",
      "\n",
      "Model# 17. 5566 nodes still misclassified out of torch.Size([14439]) \n",
      "\n",
      "Model# 18. 5566 nodes still misclassified out of torch.Size([14439]) \n",
      "\n",
      "Model# 19. 5566 nodes still misclassified out of torch.Size([14439]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14198/14198 [00:00<00:00, 4062123.34it/s]\n",
      "100%|██████████| 14198/14198 [00:00<00:00, 4694208.43it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2810191.17it/s]\n",
      "Inferring Phrases: 100%|██████████| 14198/14198 [00:00<00:00, 419079.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5586 nodes still misclassified out of torch.Size([14198]) \n",
      "\n",
      "Model# 1. 5586 nodes still misclassified out of torch.Size([14198]) \n",
      "\n",
      "Model# 2. 5586 nodes still misclassified out of torch.Size([14198]) \n",
      "\n",
      "Model# 3. 5586 nodes still misclassified out of torch.Size([14198]) \n",
      "\n",
      "Model# 4. 5586 nodes still misclassified out of torch.Size([14198]) \n",
      "\n",
      "Model# 5. 5586 nodes still misclassified out of torch.Size([14198]) \n",
      "\n",
      "Model# 6. 5586 nodes still misclassified out of torch.Size([14198]) \n",
      "\n",
      "Model# 7. 5586 nodes still misclassified out of torch.Size([14198]) \n",
      "\n",
      "Model# 8. 5586 nodes still misclassified out of torch.Size([14198]) \n",
      "\n",
      "Model# 9. 5586 nodes still misclassified out of torch.Size([14198]) \n",
      "\n",
      "Model# 10. 5586 nodes still misclassified out of torch.Size([14198]) \n",
      "\n",
      "Model# 11. 5586 nodes still misclassified out of torch.Size([14198]) \n",
      "\n",
      "Model# 12. 5586 nodes still misclassified out of torch.Size([14198]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 38/299 [00:24<02:21,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 13. 5586 nodes still misclassified out of torch.Size([14198]) \n",
      "\n",
      "Model# 14. 5586 nodes still misclassified out of torch.Size([14198]) \n",
      "\n",
      "Model# 15. 5586 nodes still misclassified out of torch.Size([14198]) \n",
      "\n",
      "Model# 16. 5586 nodes still misclassified out of torch.Size([14198]) \n",
      "\n",
      "Model# 17. 5586 nodes still misclassified out of torch.Size([14198]) \n",
      "\n",
      "Model# 18. 5586 nodes still misclassified out of torch.Size([14198]) \n",
      "\n",
      "Model# 19. 5586 nodes still misclassified out of torch.Size([14198]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13481/13481 [00:00<00:00, 4425405.98it/s]\n",
      "100%|██████████| 13481/13481 [00:00<00:00, 5257406.99it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 3150532.56it/s]\n",
      "Inferring Phrases: 100%|██████████| 13481/13481 [00:00<00:00, 450516.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3858 nodes still misclassified out of torch.Size([13481]) \n",
      "\n",
      "Model# 1. 3858 nodes still misclassified out of torch.Size([13481]) \n",
      "\n",
      "Model# 2. 3858 nodes still misclassified out of torch.Size([13481]) \n",
      "\n",
      "Model# 3. 3858 nodes still misclassified out of torch.Size([13481]) \n",
      "\n",
      "Model# 4. 3858 nodes still misclassified out of torch.Size([13481]) \n",
      "\n",
      "Model# 5. 3858 nodes still misclassified out of torch.Size([13481]) \n",
      "\n",
      "Model# 6. 3858 nodes still misclassified out of torch.Size([13481]) \n",
      "\n",
      "Model# 7. 3858 nodes still misclassified out of torch.Size([13481]) \n",
      "\n",
      "Model# 8. 3858 nodes still misclassified out of torch.Size([13481]) \n",
      "\n",
      "Model# 9. 3858 nodes still misclassified out of torch.Size([13481]) \n",
      "\n",
      "Model# 10. 3858 nodes still misclassified out of torch.Size([13481]) \n",
      "\n",
      "Model# 11. 3858 nodes still misclassified out of torch.Size([13481]) \n",
      "\n",
      "Model# 12. 3858 nodes still misclassified out of torch.Size([13481]) \n",
      "\n",
      "Model# 13. 3858 nodes still misclassified out of torch.Size([13481]) \n",
      "\n",
      "Model# 14. 3858 nodes still misclassified out of torch.Size([13481]) \n",
      "\n",
      "Model# 15. 3858 nodes still misclassified out of torch.Size([13481]) \n",
      "\n",
      "Model# 16. 3858 nodes still misclassified out of torch.Size([13481]) \n",
      "\n",
      "Model# 17. 3858 nodes still misclassified out of torch.Size([13481]) \n",
      "\n",
      "Model# 18. 3858 nodes still misclassified out of torch.Size([13481]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 39/299 [00:25<02:21,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 3858 nodes still misclassified out of torch.Size([13481]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13369/13369 [00:00<00:00, 4138276.77it/s]\n",
      "100%|██████████| 13369/13369 [00:00<00:00, 4778732.76it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2776704.03it/s]\n",
      "Inferring Phrases: 100%|██████████| 13369/13369 [00:00<00:00, 396112.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5005 nodes still misclassified out of torch.Size([13369]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 1. 5005 nodes still misclassified out of torch.Size([13369]) \n",
      "\n",
      "Model# 2. 5005 nodes still misclassified out of torch.Size([13369]) \n",
      "\n",
      "Model# 3. 5005 nodes still misclassified out of torch.Size([13369]) \n",
      "\n",
      "Model# 4. 5005 nodes still misclassified out of torch.Size([13369]) \n",
      "\n",
      "Model# 5. 5005 nodes still misclassified out of torch.Size([13369]) \n",
      "\n",
      "Model# 6. 5005 nodes still misclassified out of torch.Size([13369]) \n",
      "\n",
      "Model# 7. 5005 nodes still misclassified out of torch.Size([13369]) \n",
      "\n",
      "Model# 8. 5005 nodes still misclassified out of torch.Size([13369]) \n",
      "\n",
      "Model# 9. 5005 nodes still misclassified out of torch.Size([13369]) \n",
      "\n",
      "Model# 10. 5005 nodes still misclassified out of torch.Size([13369]) \n",
      "\n",
      "Model# 11. 5005 nodes still misclassified out of torch.Size([13369]) \n",
      "\n",
      "Model# 12. 5005 nodes still misclassified out of torch.Size([13369]) \n",
      "\n",
      "Model# 13. 5005 nodes still misclassified out of torch.Size([13369]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 40/299 [00:25<02:17,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 14. 5005 nodes still misclassified out of torch.Size([13369]) \n",
      "\n",
      "Model# 15. 5005 nodes still misclassified out of torch.Size([13369]) \n",
      "\n",
      "Model# 16. 5005 nodes still misclassified out of torch.Size([13369]) \n",
      "\n",
      "Model# 17. 5005 nodes still misclassified out of torch.Size([13369]) \n",
      "\n",
      "Model# 18. 5005 nodes still misclassified out of torch.Size([13369]) \n",
      "\n",
      "Model# 19. 5005 nodes still misclassified out of torch.Size([13369]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13258/13258 [00:00<00:00, 3507953.72it/s]\n",
      "100%|██████████| 13258/13258 [00:00<00:00, 4392770.55it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2714349.94it/s]\n",
      "Inferring Phrases: 100%|██████████| 13258/13258 [00:00<00:00, 393905.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4639 nodes still misclassified out of torch.Size([13258]) \n",
      "\n",
      "Model# 1. 4639 nodes still misclassified out of torch.Size([13258]) \n",
      "\n",
      "Model# 2. 4639 nodes still misclassified out of torch.Size([13258]) \n",
      "\n",
      "Model# 3. 4639 nodes still misclassified out of torch.Size([13258]) \n",
      "\n",
      "Model# 4. 4639 nodes still misclassified out of torch.Size([13258]) \n",
      "\n",
      "Model# 5. 4639 nodes still misclassified out of torch.Size([13258]) \n",
      "\n",
      "Model# 6. 4639 nodes still misclassified out of torch.Size([13258]) \n",
      "\n",
      "Model# 7. 4639 nodes still misclassified out of torch.Size([13258]) \n",
      "\n",
      "Model# 8. 4639 nodes still misclassified out of torch.Size([13258]) \n",
      "\n",
      "Model# 9. 4639 nodes still misclassified out of torch.Size([13258]) \n",
      "\n",
      "Model# 10. 4639 nodes still misclassified out of torch.Size([13258]) \n",
      "\n",
      "Model# 11. 4639 nodes still misclassified out of torch.Size([13258]) \n",
      "\n",
      "Model# 12. 4639 nodes still misclassified out of torch.Size([13258]) \n",
      "\n",
      "Model# 13. 4639 nodes still misclassified out of torch.Size([13258]) \n",
      "\n",
      "Model# 14. 4639 nodes still misclassified out of torch.Size([13258]) \n",
      "\n",
      "Model# 15. 4639 nodes still misclassified out of torch.Size([13258]) \n",
      "\n",
      "Model# 16. 4639 nodes still misclassified out of torch.Size([13258]) \n",
      "\n",
      "Model# 17. 4639 nodes still misclassified out of torch.Size([13258]) \n",
      "\n",
      "Model# 18. 4639 nodes still misclassified out of torch.Size([13258]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 41/299 [00:25<02:07,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4639 nodes still misclassified out of torch.Size([13258]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12653/12653 [00:00<00:00, 4272989.41it/s]\n",
      "100%|██████████| 12653/12653 [00:00<00:00, 5191795.00it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 3003440.03it/s]\n",
      "Inferring Phrases: 100%|██████████| 12653/12653 [00:00<00:00, 426176.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4381 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 1. 4381 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 2. 4381 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 3. 4381 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 4. 4381 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 5. 4381 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 6. 4381 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 7. 4381 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 8. 4381 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 9. 4381 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 10. 4381 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 11. 4381 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 12. 4381 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 13. 4381 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 14. 4381 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 15. 4381 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 16. 4381 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 17. 4381 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 18. 4381 nodes still misclassified out of torch.Size([12653]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 42/299 [00:26<02:09,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4381 nodes still misclassified out of torch.Size([12653]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12847/12847 [00:00<00:00, 4176747.81it/s]\n",
      "100%|██████████| 12847/12847 [00:00<00:00, 4776970.17it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2856571.55it/s]\n",
      "Inferring Phrases: 100%|██████████| 12847/12847 [00:00<00:00, 388441.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4926 nodes still misclassified out of torch.Size([12847]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 1. 4926 nodes still misclassified out of torch.Size([12847]) \n",
      "\n",
      "Model# 2. 4926 nodes still misclassified out of torch.Size([12847]) \n",
      "\n",
      "Model# 3. 4926 nodes still misclassified out of torch.Size([12847]) \n",
      "\n",
      "Model# 4. 4926 nodes still misclassified out of torch.Size([12847]) \n",
      "\n",
      "Model# 5. 4926 nodes still misclassified out of torch.Size([12847]) \n",
      "\n",
      "Model# 6. 4926 nodes still misclassified out of torch.Size([12847]) \n",
      "\n",
      "Model# 7. 4926 nodes still misclassified out of torch.Size([12847]) \n",
      "\n",
      "Model# 8. 4926 nodes still misclassified out of torch.Size([12847]) \n",
      "\n",
      "Model# 9. 4926 nodes still misclassified out of torch.Size([12847]) \n",
      "\n",
      "Model# 10. 4926 nodes still misclassified out of torch.Size([12847]) \n",
      "\n",
      "Model# 11. 4926 nodes still misclassified out of torch.Size([12847]) \n",
      "\n",
      "Model# 12. 4926 nodes still misclassified out of torch.Size([12847]) \n",
      "\n",
      "Model# 13. 4926 nodes still misclassified out of torch.Size([12847]) \n",
      "\n",
      "Model# 14. 4926 nodes still misclassified out of torch.Size([12847]) \n",
      "\n",
      "Model# 15. 4926 nodes still misclassified out of torch.Size([12847]) \n",
      "\n",
      "Model# 16. 4926 nodes still misclassified out of torch.Size([12847]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 43/299 [00:26<02:04,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 17. 4926 nodes still misclassified out of torch.Size([12847]) \n",
      "\n",
      "Model# 18. 4926 nodes still misclassified out of torch.Size([12847]) \n",
      "\n",
      "Model# 19. 4926 nodes still misclassified out of torch.Size([12847]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13135/13135 [00:00<00:00, 3803920.67it/s]\n",
      "100%|██████████| 13135/13135 [00:00<00:00, 4530607.16it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2667906.03it/s]\n",
      "Inferring Phrases: 100%|██████████| 13135/13135 [00:00<00:00, 427750.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3726 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 1. 3726 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 2. 3726 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 3. 3726 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 4. 3726 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 5. 3726 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 6. 3726 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 7. 3726 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 8. 3726 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 9. 3726 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 10. 3726 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 11. 3726 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 12. 3726 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 13. 3726 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 14. 3726 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 15. 3726 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 16. 3726 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 17. 3726 nodes still misclassified out of torch.Size([13135]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 44/299 [00:27<02:10,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 18. 3726 nodes still misclassified out of torch.Size([13135]) \n",
      "\n",
      "Model# 19. 3726 nodes still misclassified out of torch.Size([13135]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13213/13213 [00:00<00:00, 3530568.82it/s]\n",
      "100%|██████████| 13213/13213 [00:00<00:00, 4360637.25it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1714737.06it/s]\n",
      "Inferring Phrases: 100%|██████████| 13213/13213 [00:00<00:00, 248097.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4154 nodes still misclassified out of torch.Size([13213]) \n",
      "\n",
      "Model# 1. 4154 nodes still misclassified out of torch.Size([13213]) \n",
      "\n",
      "Model# 2. 4154 nodes still misclassified out of torch.Size([13213]) \n",
      "\n",
      "Model# 3. 4154 nodes still misclassified out of torch.Size([13213]) \n",
      "\n",
      "Model# 4. 4154 nodes still misclassified out of torch.Size([13213]) \n",
      "\n",
      "Model# 5. 4154 nodes still misclassified out of torch.Size([13213]) \n",
      "\n",
      "Model# 6. 4154 nodes still misclassified out of torch.Size([13213]) \n",
      "\n",
      "Model# 7. 4154 nodes still misclassified out of torch.Size([13213]) \n",
      "\n",
      "Model# 8. 4154 nodes still misclassified out of torch.Size([13213]) \n",
      "\n",
      "Model# 9. 4154 nodes still misclassified out of torch.Size([13213]) \n",
      "\n",
      "Model# 10. 4154 nodes still misclassified out of torch.Size([13213]) \n",
      "\n",
      "Model# 11. 4154 nodes still misclassified out of torch.Size([13213]) \n",
      "\n",
      "Model# 12. 4154 nodes still misclassified out of torch.Size([13213]) \n",
      "\n",
      "Model# 13. 4154 nodes still misclassified out of torch.Size([13213]) \n",
      "\n",
      "Model# 14. 4154 nodes still misclassified out of torch.Size([13213]) \n",
      "\n",
      "Model# 15. 4154 nodes still misclassified out of torch.Size([13213]) \n",
      "\n",
      "Model# 16. 4154 nodes still misclassified out of torch.Size([13213]) \n",
      "\n",
      "Model# 17. 4154 nodes still misclassified out of torch.Size([13213]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 45/299 [00:27<02:06,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 18. 4154 nodes still misclassified out of torch.Size([13213]) \n",
      "\n",
      "Model# 19. 4154 nodes still misclassified out of torch.Size([13213]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13032/13032 [00:00<00:00, 3978757.44it/s]\n",
      "100%|██████████| 13032/13032 [00:00<00:00, 4741102.41it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2727233.95it/s]\n",
      "Inferring Phrases: 100%|██████████| 13032/13032 [00:00<00:00, 389262.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4596 nodes still misclassified out of torch.Size([13032]) \n",
      "\n",
      "Model# 1. 4596 nodes still misclassified out of torch.Size([13032]) \n",
      "\n",
      "Model# 2. 4596 nodes still misclassified out of torch.Size([13032]) \n",
      "\n",
      "Model# 3. 4596 nodes still misclassified out of torch.Size([13032]) \n",
      "\n",
      "Model# 4. 4596 nodes still misclassified out of torch.Size([13032]) \n",
      "\n",
      "Model# 5. 4596 nodes still misclassified out of torch.Size([13032]) \n",
      "\n",
      "Model# 6. 4596 nodes still misclassified out of torch.Size([13032]) \n",
      "\n",
      "Model# 7. 4596 nodes still misclassified out of torch.Size([13032]) \n",
      "\n",
      "Model# 8. 4596 nodes still misclassified out of torch.Size([13032]) \n",
      "\n",
      "Model# 9. 4596 nodes still misclassified out of torch.Size([13032]) \n",
      "\n",
      "Model# 10. 4596 nodes still misclassified out of torch.Size([13032]) \n",
      "\n",
      "Model# 11. 4596 nodes still misclassified out of torch.Size([13032]) \n",
      "\n",
      "Model# 12. 4596 nodes still misclassified out of torch.Size([13032]) \n",
      "\n",
      "Model# 13. 4596 nodes still misclassified out of torch.Size([13032]) \n",
      "\n",
      "Model# 14. 4596 nodes still misclassified out of torch.Size([13032]) \n",
      "\n",
      "Model# 15. 4596 nodes still misclassified out of torch.Size([13032]) \n",
      "\n",
      "Model# 16. 4596 nodes still misclassified out of torch.Size([13032]) \n",
      "\n",
      "Model# 17. 4596 nodes still misclassified out of torch.Size([13032]) \n",
      "\n",
      "Model# 18. 4596 nodes still misclassified out of torch.Size([13032]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 46/299 [00:28<02:01,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4596 nodes still misclassified out of torch.Size([13032]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13361/13361 [00:00<00:00, 4307132.10it/s]\n",
      "100%|██████████| 13361/13361 [00:00<00:00, 5000454.69it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2866789.39it/s]\n",
      "Inferring Phrases: 100%|██████████| 13361/13361 [00:00<00:00, 443109.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4825 nodes still misclassified out of torch.Size([13361]) \n",
      "\n",
      "Model# 1. 4825 nodes still misclassified out of torch.Size([13361]) \n",
      "\n",
      "Model# 2. 4825 nodes still misclassified out of torch.Size([13361]) \n",
      "\n",
      "Model# 3. 4825 nodes still misclassified out of torch.Size([13361]) \n",
      "\n",
      "Model# 4. 4825 nodes still misclassified out of torch.Size([13361]) \n",
      "\n",
      "Model# 5. 4825 nodes still misclassified out of torch.Size([13361]) \n",
      "\n",
      "Model# 6. 4825 nodes still misclassified out of torch.Size([13361]) \n",
      "\n",
      "Model# 7. 4825 nodes still misclassified out of torch.Size([13361]) \n",
      "\n",
      "Model# 8. 4825 nodes still misclassified out of torch.Size([13361]) \n",
      "\n",
      "Model# 9. 4825 nodes still misclassified out of torch.Size([13361]) \n",
      "\n",
      "Model# 10. 4825 nodes still misclassified out of torch.Size([13361]) \n",
      "\n",
      "Model# 11. 4825 nodes still misclassified out of torch.Size([13361]) \n",
      "\n",
      "Model# 12. 4825 nodes still misclassified out of torch.Size([13361]) \n",
      "\n",
      "Model# 13. 4825 nodes still misclassified out of torch.Size([13361]) \n",
      "\n",
      "Model# 14. 4825 nodes still misclassified out of torch.Size([13361]) \n",
      "\n",
      "Model# 15. 4825 nodes still misclassified out of torch.Size([13361]) \n",
      "\n",
      "Model# 16. 4825 nodes still misclassified out of torch.Size([13361]) \n",
      "\n",
      "Model# 17. 4825 nodes still misclassified out of torch.Size([13361]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 47/299 [00:28<02:06,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 18. 4825 nodes still misclassified out of torch.Size([13361]) \n",
      "\n",
      "Model# 19. 4825 nodes still misclassified out of torch.Size([13361]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13989/13989 [00:00<00:00, 3994697.62it/s]\n",
      "100%|██████████| 13989/13989 [00:00<00:00, 4723783.81it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2742809.31it/s]\n",
      "Inferring Phrases: 100%|██████████| 13989/13989 [00:00<00:00, 407816.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4588 nodes still misclassified out of torch.Size([13989]) \n",
      "\n",
      "Model# 1. 4588 nodes still misclassified out of torch.Size([13989]) \n",
      "\n",
      "Model# 2. 4588 nodes still misclassified out of torch.Size([13989]) \n",
      "\n",
      "Model# 3. 4588 nodes still misclassified out of torch.Size([13989]) \n",
      "\n",
      "Model# 4. 4588 nodes still misclassified out of torch.Size([13989]) \n",
      "\n",
      "Model# 5. 4588 nodes still misclassified out of torch.Size([13989]) \n",
      "\n",
      "Model# 6. 4588 nodes still misclassified out of torch.Size([13989]) \n",
      "\n",
      "Model# 7. 4588 nodes still misclassified out of torch.Size([13989]) \n",
      "\n",
      "Model# 8. 4588 nodes still misclassified out of torch.Size([13989]) \n",
      "\n",
      "Model# 9. 4588 nodes still misclassified out of torch.Size([13989]) \n",
      "\n",
      "Model# 10. 4588 nodes still misclassified out of torch.Size([13989]) \n",
      "\n",
      "Model# 11. 4588 nodes still misclassified out of torch.Size([13989]) \n",
      "\n",
      "Model# 12. 4588 nodes still misclassified out of torch.Size([13989]) \n",
      "\n",
      "Model# 13. 4588 nodes still misclassified out of torch.Size([13989]) \n",
      "\n",
      "Model# 14. 4588 nodes still misclassified out of torch.Size([13989]) \n",
      "\n",
      "Model# 15. 4588 nodes still misclassified out of torch.Size([13989]) \n",
      "\n",
      "Model# 16. 4588 nodes still misclassified out of torch.Size([13989]) \n",
      "\n",
      "Model# 17. 4588 nodes still misclassified out of torch.Size([13989]) \n",
      "\n",
      "Model# 18. 4588 nodes still misclassified out of torch.Size([13989]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 48/299 [00:29<01:59,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4588 nodes still misclassified out of torch.Size([13989]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14175/14175 [00:00<00:00, 4033258.21it/s]\n",
      "100%|██████████| 14175/14175 [00:00<00:00, 3165997.08it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2491369.74it/s]\n",
      "Inferring Phrases: 100%|██████████| 14175/14175 [00:00<00:00, 405015.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5718 nodes still misclassified out of torch.Size([14175]) \n",
      "\n",
      "Model# 1. 5718 nodes still misclassified out of torch.Size([14175]) \n",
      "\n",
      "Model# 2. 5718 nodes still misclassified out of torch.Size([14175]) \n",
      "\n",
      "Model# 3. 5718 nodes still misclassified out of torch.Size([14175]) \n",
      "\n",
      "Model# 4. 5718 nodes still misclassified out of torch.Size([14175]) \n",
      "\n",
      "Model# 5. 5718 nodes still misclassified out of torch.Size([14175]) \n",
      "\n",
      "Model# 6. 5718 nodes still misclassified out of torch.Size([14175]) \n",
      "\n",
      "Model# 7. 5718 nodes still misclassified out of torch.Size([14175]) \n",
      "\n",
      "Model# 8. 5718 nodes still misclassified out of torch.Size([14175]) \n",
      "\n",
      "Model# 9. 5718 nodes still misclassified out of torch.Size([14175]) \n",
      "\n",
      "Model# 10. 5718 nodes still misclassified out of torch.Size([14175]) \n",
      "\n",
      "Model# 11. 5718 nodes still misclassified out of torch.Size([14175]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 49/299 [00:29<02:03,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 12. 5718 nodes still misclassified out of torch.Size([14175]) \n",
      "\n",
      "Model# 13. 5718 nodes still misclassified out of torch.Size([14175]) \n",
      "\n",
      "Model# 14. 5718 nodes still misclassified out of torch.Size([14175]) \n",
      "\n",
      "Model# 15. 5718 nodes still misclassified out of torch.Size([14175]) \n",
      "\n",
      "Model# 16. 5718 nodes still misclassified out of torch.Size([14175]) \n",
      "\n",
      "Model# 17. 5718 nodes still misclassified out of torch.Size([14175]) \n",
      "\n",
      "Model# 18. 5718 nodes still misclassified out of torch.Size([14175]) \n",
      "\n",
      "Model# 19. 5718 nodes still misclassified out of torch.Size([14175]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13928/13928 [00:00<00:00, 4392020.61it/s]\n",
      "100%|██████████| 13928/13928 [00:00<00:00, 5173420.66it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2765292.84it/s]\n",
      "Inferring Phrases: 100%|██████████| 13928/13928 [00:00<00:00, 452735.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5153 nodes still misclassified out of torch.Size([13928]) \n",
      "\n",
      "Model# 1. 5153 nodes still misclassified out of torch.Size([13928]) \n",
      "\n",
      "Model# 2. 5153 nodes still misclassified out of torch.Size([13928]) \n",
      "\n",
      "Model# 3. 5153 nodes still misclassified out of torch.Size([13928]) \n",
      "\n",
      "Model# 4. 5153 nodes still misclassified out of torch.Size([13928]) \n",
      "\n",
      "Model# 5. 5153 nodes still misclassified out of torch.Size([13928]) \n",
      "\n",
      "Model# 6. 5153 nodes still misclassified out of torch.Size([13928]) \n",
      "\n",
      "Model# 7. 5153 nodes still misclassified out of torch.Size([13928]) \n",
      "\n",
      "Model# 8. 5153 nodes still misclassified out of torch.Size([13928]) \n",
      "\n",
      "Model# 9. 5153 nodes still misclassified out of torch.Size([13928]) \n",
      "\n",
      "Model# 10. 5153 nodes still misclassified out of torch.Size([13928]) \n",
      "\n",
      "Model# 11. 5153 nodes still misclassified out of torch.Size([13928]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 50/299 [00:30<02:16,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 12. 5153 nodes still misclassified out of torch.Size([13928]) \n",
      "\n",
      "Model# 13. 5153 nodes still misclassified out of torch.Size([13928]) \n",
      "\n",
      "Model# 14. 5153 nodes still misclassified out of torch.Size([13928]) \n",
      "\n",
      "Model# 15. 5153 nodes still misclassified out of torch.Size([13928]) \n",
      "\n",
      "Model# 16. 5153 nodes still misclassified out of torch.Size([13928]) \n",
      "\n",
      "Model# 17. 5153 nodes still misclassified out of torch.Size([13928]) \n",
      "\n",
      "Model# 18. 5153 nodes still misclassified out of torch.Size([13928]) \n",
      "\n",
      "Model# 19. 5153 nodes still misclassified out of torch.Size([13928]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13679/13679 [00:00<00:00, 2618974.96it/s]\n",
      "100%|██████████| 13679/13679 [00:00<00:00, 3005914.20it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1844298.65it/s]\n",
      "Inferring Phrases: 100%|██████████| 13679/13679 [00:00<00:00, 273913.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4200 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 1. 4200 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 2. 4200 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 3. 4200 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 4. 4200 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 5. 4200 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 6. 4200 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 7. 4200 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 8. 4200 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 9. 4200 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 10. 4200 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 11. 4200 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 12. 4200 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 13. 4200 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 14. 4200 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 15. 4200 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 16. 4200 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 17. 4200 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 18. 4200 nodes still misclassified out of torch.Size([13679]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 51/299 [00:31<02:08,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4200 nodes still misclassified out of torch.Size([13679]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13529/13529 [00:00<00:00, 3922085.90it/s]\n",
      "100%|██████████| 13529/13529 [00:00<00:00, 4697412.15it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2674142.90it/s]\n",
      "Inferring Phrases: 100%|██████████| 13529/13529 [00:00<00:00, 250772.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5086 nodes still misclassified out of torch.Size([13529]) \n",
      "\n",
      "Model# 1. 5086 nodes still misclassified out of torch.Size([13529]) \n",
      "\n",
      "Model# 2. 5086 nodes still misclassified out of torch.Size([13529]) \n",
      "\n",
      "Model# 3. 5086 nodes still misclassified out of torch.Size([13529]) \n",
      "\n",
      "Model# 4. 5086 nodes still misclassified out of torch.Size([13529]) \n",
      "\n",
      "Model# 5. 5086 nodes still misclassified out of torch.Size([13529]) \n",
      "\n",
      "Model# 6. 5086 nodes still misclassified out of torch.Size([13529]) \n",
      "\n",
      "Model# 7. 5086 nodes still misclassified out of torch.Size([13529]) \n",
      "\n",
      "Model# 8. 5086 nodes still misclassified out of torch.Size([13529]) \n",
      "\n",
      "Model# 9. 5086 nodes still misclassified out of torch.Size([13529]) \n",
      "\n",
      "Model# 10. 5086 nodes still misclassified out of torch.Size([13529]) \n",
      "\n",
      "Model# 11. 5086 nodes still misclassified out of torch.Size([13529]) \n",
      "\n",
      "Model# 12. 5086 nodes still misclassified out of torch.Size([13529]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 52/299 [00:31<02:11,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 13. 5086 nodes still misclassified out of torch.Size([13529]) \n",
      "\n",
      "Model# 14. 5086 nodes still misclassified out of torch.Size([13529]) \n",
      "\n",
      "Model# 15. 5086 nodes still misclassified out of torch.Size([13529]) \n",
      "\n",
      "Model# 16. 5086 nodes still misclassified out of torch.Size([13529]) \n",
      "\n",
      "Model# 17. 5086 nodes still misclassified out of torch.Size([13529]) \n",
      "\n",
      "Model# 18. 5086 nodes still misclassified out of torch.Size([13529]) \n",
      "\n",
      "Model# 19. 5086 nodes still misclassified out of torch.Size([13529]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13480/13480 [00:00<00:00, 4249471.47it/s]\n",
      "100%|██████████| 13480/13480 [00:00<00:00, 4828697.41it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2407521.67it/s]\n",
      "Inferring Phrases: 100%|██████████| 13480/13480 [00:00<00:00, 413349.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5393 nodes still misclassified out of torch.Size([13480]) \n",
      "\n",
      "Model# 1. 5393 nodes still misclassified out of torch.Size([13480]) \n",
      "\n",
      "Model# 2. 5393 nodes still misclassified out of torch.Size([13480]) \n",
      "\n",
      "Model# 3. 5393 nodes still misclassified out of torch.Size([13480]) \n",
      "\n",
      "Model# 4. 5393 nodes still misclassified out of torch.Size([13480]) \n",
      "\n",
      "Model# 5. 5393 nodes still misclassified out of torch.Size([13480]) \n",
      "\n",
      "Model# 6. 5393 nodes still misclassified out of torch.Size([13480]) \n",
      "\n",
      "Model# 7. 5393 nodes still misclassified out of torch.Size([13480]) \n",
      "\n",
      "Model# 8. 5393 nodes still misclassified out of torch.Size([13480]) \n",
      "\n",
      "Model# 9. 5393 nodes still misclassified out of torch.Size([13480]) \n",
      "\n",
      "Model# 10. 5393 nodes still misclassified out of torch.Size([13480]) \n",
      "\n",
      "Model# 11. 5393 nodes still misclassified out of torch.Size([13480]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 53/299 [00:32<02:25,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 12. 5393 nodes still misclassified out of torch.Size([13480]) \n",
      "\n",
      "Model# 13. 5393 nodes still misclassified out of torch.Size([13480]) \n",
      "\n",
      "Model# 14. 5393 nodes still misclassified out of torch.Size([13480]) \n",
      "\n",
      "Model# 15. 5393 nodes still misclassified out of torch.Size([13480]) \n",
      "\n",
      "Model# 16. 5393 nodes still misclassified out of torch.Size([13480]) \n",
      "\n",
      "Model# 17. 5393 nodes still misclassified out of torch.Size([13480]) \n",
      "\n",
      "Model# 18. 5393 nodes still misclassified out of torch.Size([13480]) \n",
      "\n",
      "Model# 19. 5393 nodes still misclassified out of torch.Size([13480]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13037/13037 [00:00<00:00, 3972765.28it/s]\n",
      "100%|██████████| 13037/13037 [00:00<00:00, 4766902.73it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2728180.04it/s]\n",
      "Inferring Phrases: 100%|██████████| 13037/13037 [00:00<00:00, 387779.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4383 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 1. 4383 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 2. 4383 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 3. 4383 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 4. 4383 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 5. 4383 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 6. 4383 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 7. 4383 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 8. 4383 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 9. 4383 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 10. 4383 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 11. 4383 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 12. 4383 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 13. 4383 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 14. 4383 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 15. 4383 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 16. 4383 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 17. 4383 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 18. 4383 nodes still misclassified out of torch.Size([13037]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 54/299 [00:32<02:11,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4383 nodes still misclassified out of torch.Size([13037]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13356/13356 [00:00<00:00, 4264225.03it/s]\n",
      "100%|██████████| 13356/13356 [00:00<00:00, 5072817.55it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2877672.78it/s]\n",
      "Inferring Phrases: 100%|██████████| 13356/13356 [00:00<00:00, 449956.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4561 nodes still misclassified out of torch.Size([13356]) \n",
      "\n",
      "Model# 1. 4561 nodes still misclassified out of torch.Size([13356]) \n",
      "\n",
      "Model# 2. 4561 nodes still misclassified out of torch.Size([13356]) \n",
      "\n",
      "Model# 3. 4561 nodes still misclassified out of torch.Size([13356]) \n",
      "\n",
      "Model# 4. 4561 nodes still misclassified out of torch.Size([13356]) \n",
      "\n",
      "Model# 5. 4561 nodes still misclassified out of torch.Size([13356]) \n",
      "\n",
      "Model# 6. 4561 nodes still misclassified out of torch.Size([13356]) \n",
      "\n",
      "Model# 7. 4561 nodes still misclassified out of torch.Size([13356]) \n",
      "\n",
      "Model# 8. 4561 nodes still misclassified out of torch.Size([13356]) \n",
      "\n",
      "Model# 9. 4561 nodes still misclassified out of torch.Size([13356]) \n",
      "\n",
      "Model# 10. 4561 nodes still misclassified out of torch.Size([13356]) \n",
      "\n",
      "Model# 11. 4561 nodes still misclassified out of torch.Size([13356]) \n",
      "\n",
      "Model# 12. 4561 nodes still misclassified out of torch.Size([13356]) \n",
      "\n",
      "Model# 13. 4561 nodes still misclassified out of torch.Size([13356]) \n",
      "\n",
      "Model# 14. 4561 nodes still misclassified out of torch.Size([13356]) \n",
      "\n",
      "Model# 15. 4561 nodes still misclassified out of torch.Size([13356]) \n",
      "\n",
      "Model# 16. 4561 nodes still misclassified out of torch.Size([13356]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 55/299 [00:33<02:18,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 17. 4561 nodes still misclassified out of torch.Size([13356]) \n",
      "\n",
      "Model# 18. 4561 nodes still misclassified out of torch.Size([13356]) \n",
      "\n",
      "Model# 19. 4561 nodes still misclassified out of torch.Size([13356]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13389/13389 [00:00<00:00, 4092518.31it/s]\n",
      "100%|██████████| 13389/13389 [00:00<00:00, 4738232.89it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2867312.00it/s]\n",
      "Inferring Phrases: 100%|██████████| 13389/13389 [00:00<00:00, 403801.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3991 nodes still misclassified out of torch.Size([13389]) \n",
      "\n",
      "Model# 1. 3991 nodes still misclassified out of torch.Size([13389]) \n",
      "\n",
      "Model# 2. 3991 nodes still misclassified out of torch.Size([13389]) \n",
      "\n",
      "Model# 3. 3991 nodes still misclassified out of torch.Size([13389]) \n",
      "\n",
      "Model# 4. 3991 nodes still misclassified out of torch.Size([13389]) \n",
      "\n",
      "Model# 5. 3991 nodes still misclassified out of torch.Size([13389]) \n",
      "\n",
      "Model# 6. 3991 nodes still misclassified out of torch.Size([13389]) \n",
      "\n",
      "Model# 7. 3991 nodes still misclassified out of torch.Size([13389]) \n",
      "\n",
      "Model# 8. 3991 nodes still misclassified out of torch.Size([13389]) \n",
      "\n",
      "Model# 9. 3991 nodes still misclassified out of torch.Size([13389]) \n",
      "\n",
      "Model# 10. 3991 nodes still misclassified out of torch.Size([13389]) \n",
      "\n",
      "Model# 11. 3991 nodes still misclassified out of torch.Size([13389]) \n",
      "\n",
      "Model# 12. 3991 nodes still misclassified out of torch.Size([13389]) \n",
      "\n",
      "Model# 13. 3991 nodes still misclassified out of torch.Size([13389]) \n",
      "\n",
      "Model# 14. 3991 nodes still misclassified out of torch.Size([13389]) \n",
      "\n",
      "Model# 15. 3991 nodes still misclassified out of torch.Size([13389]) \n",
      "\n",
      "Model# 16. 3991 nodes still misclassified out of torch.Size([13389]) \n",
      "\n",
      "Model# 17. 3991 nodes still misclassified out of torch.Size([13389]) \n",
      "\n",
      "Model# 18. 3991 nodes still misclassified out of torch.Size([13389]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 56/299 [00:33<02:05,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 3991 nodes still misclassified out of torch.Size([13389]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13052/13052 [00:00<00:00, 4151680.25it/s]\n",
      "100%|██████████| 13052/13052 [00:00<00:00, 4803795.70it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2832585.66it/s]\n",
      "Inferring Phrases: 100%|██████████| 13052/13052 [00:00<00:00, 394162.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4695 nodes still misclassified out of torch.Size([13052]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 1. 4695 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 2. 4695 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 3. 4695 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 4. 4695 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 5. 4695 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 6. 4695 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 7. 4695 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 8. 4695 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 9. 4695 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 10. 4695 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 11. 4695 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 12. 4695 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 13. 4695 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 14. 4695 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 15. 4695 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 16. 4695 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 17. 4695 nodes still misclassified out of torch.Size([13052]) \n",
      "\n",
      "Model# 18. 4695 nodes still misclassified out of torch.Size([13052]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 57/299 [00:34<01:56,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4695 nodes still misclassified out of torch.Size([13052]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13162/13162 [00:00<00:00, 4499586.70it/s]\n",
      "100%|██████████| 13162/13162 [00:00<00:00, 5344184.83it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2734048.63it/s]\n",
      "Inferring Phrases: 100%|██████████| 13162/13162 [00:00<00:00, 443909.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4797 nodes still misclassified out of torch.Size([13162]) \n",
      "\n",
      "Model# 1. 4797 nodes still misclassified out of torch.Size([13162]) \n",
      "\n",
      "Model# 2. 4797 nodes still misclassified out of torch.Size([13162]) \n",
      "\n",
      "Model# 3. 4797 nodes still misclassified out of torch.Size([13162]) \n",
      "\n",
      "Model# 4. 4797 nodes still misclassified out of torch.Size([13162]) \n",
      "\n",
      "Model# 5. 4797 nodes still misclassified out of torch.Size([13162]) \n",
      "\n",
      "Model# 6. 4797 nodes still misclassified out of torch.Size([13162]) \n",
      "\n",
      "Model# 7. 4797 nodes still misclassified out of torch.Size([13162]) \n",
      "\n",
      "Model# 8. 4797 nodes still misclassified out of torch.Size([13162]) \n",
      "\n",
      "Model# 9. 4797 nodes still misclassified out of torch.Size([13162]) \n",
      "\n",
      "Model# 10. 4797 nodes still misclassified out of torch.Size([13162]) \n",
      "\n",
      "Model# 11. 4797 nodes still misclassified out of torch.Size([13162]) \n",
      "\n",
      "Model# 12. 4797 nodes still misclassified out of torch.Size([13162]) \n",
      "\n",
      "Model# 13. 4797 nodes still misclassified out of torch.Size([13162]) \n",
      "\n",
      "Model# 14. 4797 nodes still misclassified out of torch.Size([13162]) \n",
      "\n",
      "Model# 15. 4797 nodes still misclassified out of torch.Size([13162]) \n",
      "\n",
      "Model# 16. 4797 nodes still misclassified out of torch.Size([13162]) \n",
      "\n",
      "Model# 17. 4797 nodes still misclassified out of torch.Size([13162]) \n",
      "\n",
      "Model# 18. 4797 nodes still misclassified out of torch.Size([13162]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 58/299 [00:34<02:01,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4797 nodes still misclassified out of torch.Size([13162]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13428/13428 [00:00<00:00, 4100255.83it/s]\n",
      "100%|██████████| 13428/13428 [00:00<00:00, 4700869.22it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2842182.87it/s]\n",
      "Inferring Phrases: 100%|██████████| 13428/13428 [00:00<00:00, 394458.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4600 nodes still misclassified out of torch.Size([13428]) \n",
      "\n",
      "Model# 1. 4600 nodes still misclassified out of torch.Size([13428]) \n",
      "\n",
      "Model# 2. 4600 nodes still misclassified out of torch.Size([13428]) \n",
      "\n",
      "Model# 3. 4600 nodes still misclassified out of torch.Size([13428]) \n",
      "\n",
      "Model# 4. 4600 nodes still misclassified out of torch.Size([13428]) \n",
      "\n",
      "Model# 5. 4600 nodes still misclassified out of torch.Size([13428]) \n",
      "\n",
      "Model# 6. 4600 nodes still misclassified out of torch.Size([13428]) \n",
      "\n",
      "Model# 7. 4600 nodes still misclassified out of torch.Size([13428]) \n",
      "\n",
      "Model# 8. 4600 nodes still misclassified out of torch.Size([13428]) \n",
      "\n",
      "Model# 9. 4600 nodes still misclassified out of torch.Size([13428]) \n",
      "\n",
      "Model# 10. 4600 nodes still misclassified out of torch.Size([13428]) \n",
      "\n",
      "Model# 11. 4600 nodes still misclassified out of torch.Size([13428]) \n",
      "\n",
      "Model# 12. 4600 nodes still misclassified out of torch.Size([13428]) \n",
      "\n",
      "Model# 13. 4600 nodes still misclassified out of torch.Size([13428]) \n",
      "\n",
      "Model# 14. 4600 nodes still misclassified out of torch.Size([13428]) \n",
      "\n",
      "Model# 15. 4600 nodes still misclassified out of torch.Size([13428]) \n",
      "\n",
      "Model# 16. 4600 nodes still misclassified out of torch.Size([13428]) \n",
      "\n",
      "Model# 17. 4600 nodes still misclassified out of torch.Size([13428]) \n",
      "\n",
      "Model# 18. 4600 nodes still misclassified out of torch.Size([13428]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 59/299 [00:35<01:53,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4600 nodes still misclassified out of torch.Size([13428]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13094/13094 [00:00<00:00, 3987238.03it/s]\n",
      "100%|██████████| 13094/13094 [00:00<00:00, 4591223.59it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2743526.95it/s]\n",
      "Inferring Phrases: 100%|██████████| 13094/13094 [00:00<00:00, 390679.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4680 nodes still misclassified out of torch.Size([13094]) \n",
      "\n",
      "Model# 1. 4680 nodes still misclassified out of torch.Size([13094]) \n",
      "\n",
      "Model# 2. 4680 nodes still misclassified out of torch.Size([13094]) \n",
      "\n",
      "Model# 3. 4680 nodes still misclassified out of torch.Size([13094]) \n",
      "\n",
      "Model# 4. 4680 nodes still misclassified out of torch.Size([13094]) \n",
      "\n",
      "Model# 5. 4680 nodes still misclassified out of torch.Size([13094]) \n",
      "\n",
      "Model# 6. 4680 nodes still misclassified out of torch.Size([13094]) \n",
      "\n",
      "Model# 7. 4680 nodes still misclassified out of torch.Size([13094]) \n",
      "\n",
      "Model# 8. 4680 nodes still misclassified out of torch.Size([13094]) \n",
      "\n",
      "Model# 9. 4680 nodes still misclassified out of torch.Size([13094]) \n",
      "\n",
      "Model# 10. 4680 nodes still misclassified out of torch.Size([13094]) \n",
      "\n",
      "Model# 11. 4680 nodes still misclassified out of torch.Size([13094]) \n",
      "\n",
      "Model# 12. 4680 nodes still misclassified out of torch.Size([13094]) \n",
      "\n",
      "Model# 13. 4680 nodes still misclassified out of torch.Size([13094]) \n",
      "\n",
      "Model# 14. 4680 nodes still misclassified out of torch.Size([13094]) \n",
      "\n",
      "Model# 15. 4680 nodes still misclassified out of torch.Size([13094]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 60/299 [00:35<01:52,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 16. 4680 nodes still misclassified out of torch.Size([13094]) \n",
      "\n",
      "Model# 17. 4680 nodes still misclassified out of torch.Size([13094]) \n",
      "\n",
      "Model# 18. 4680 nodes still misclassified out of torch.Size([13094]) \n",
      "\n",
      "Model# 19. 4680 nodes still misclassified out of torch.Size([13094]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12128/12128 [00:00<00:00, 4412223.00it/s]\n",
      "100%|██████████| 12128/12128 [00:00<00:00, 5182204.45it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2928233.46it/s]\n",
      "Inferring Phrases: 100%|██████████| 12128/12128 [00:00<00:00, 391995.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4490 nodes still misclassified out of torch.Size([12128]) \n",
      "\n",
      "Model# 1. 4490 nodes still misclassified out of torch.Size([12128]) \n",
      "\n",
      "Model# 2. 4490 nodes still misclassified out of torch.Size([12128]) \n",
      "\n",
      "Model# 3. 4490 nodes still misclassified out of torch.Size([12128]) \n",
      "\n",
      "Model# 4. 4490 nodes still misclassified out of torch.Size([12128]) \n",
      "\n",
      "Model# 5. 4490 nodes still misclassified out of torch.Size([12128]) \n",
      "\n",
      "Model# 6. 4490 nodes still misclassified out of torch.Size([12128]) \n",
      "\n",
      "Model# 7. 4490 nodes still misclassified out of torch.Size([12128]) \n",
      "\n",
      "Model# 8. 4490 nodes still misclassified out of torch.Size([12128]) \n",
      "\n",
      "Model# 9. 4490 nodes still misclassified out of torch.Size([12128]) \n",
      "\n",
      "Model# 10. 4490 nodes still misclassified out of torch.Size([12128]) \n",
      "\n",
      "Model# 11. 4490 nodes still misclassified out of torch.Size([12128]) \n",
      "\n",
      "Model# 12. 4490 nodes still misclassified out of torch.Size([12128]) \n",
      "\n",
      "Model# 13. 4490 nodes still misclassified out of torch.Size([12128]) \n",
      "\n",
      "Model# 14. 4490 nodes still misclassified out of torch.Size([12128]) \n",
      "\n",
      "Model# 15. 4490 nodes still misclassified out of torch.Size([12128]) \n",
      "\n",
      "Model# 16. 4490 nodes still misclassified out of torch.Size([12128]) \n",
      "\n",
      "Model# 17. 4490 nodes still misclassified out of torch.Size([12128]) \n",
      "\n",
      "Model# 18. 4490 nodes still misclassified out of torch.Size([12128]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 61/299 [00:36<01:57,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4490 nodes still misclassified out of torch.Size([12128]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11369/11369 [00:00<00:00, 4056920.38it/s]\n",
      "100%|██████████| 11369/11369 [00:00<00:00, 4714289.88it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2899956.67it/s]\n",
      "Inferring Phrases: 100%|██████████| 11369/11369 [00:00<00:00, 358569.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3440 nodes still misclassified out of torch.Size([11369]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|██        | 62/299 [00:36<01:49,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 1. 3440 nodes still misclassified out of torch.Size([11369]) \n",
      "\n",
      "Model# 2. 3440 nodes still misclassified out of torch.Size([11369]) \n",
      "\n",
      "Model# 3. 3440 nodes still misclassified out of torch.Size([11369]) \n",
      "\n",
      "Model# 4. 3440 nodes still misclassified out of torch.Size([11369]) \n",
      "\n",
      "Model# 5. 3440 nodes still misclassified out of torch.Size([11369]) \n",
      "\n",
      "Model# 6. 3440 nodes still misclassified out of torch.Size([11369]) \n",
      "\n",
      "Model# 7. 3440 nodes still misclassified out of torch.Size([11369]) \n",
      "\n",
      "Model# 8. 3440 nodes still misclassified out of torch.Size([11369]) \n",
      "\n",
      "Model# 9. 3440 nodes still misclassified out of torch.Size([11369]) \n",
      "\n",
      "Model# 10. 3440 nodes still misclassified out of torch.Size([11369]) \n",
      "\n",
      "Model# 11. 3440 nodes still misclassified out of torch.Size([11369]) \n",
      "\n",
      "Model# 12. 3440 nodes still misclassified out of torch.Size([11369]) \n",
      "\n",
      "Model# 13. 3440 nodes still misclassified out of torch.Size([11369]) \n",
      "\n",
      "Model# 14. 3440 nodes still misclassified out of torch.Size([11369]) \n",
      "\n",
      "Model# 15. 3440 nodes still misclassified out of torch.Size([11369]) \n",
      "\n",
      "Model# 16. 3440 nodes still misclassified out of torch.Size([11369]) \n",
      "\n",
      "Model# 17. 3440 nodes still misclassified out of torch.Size([11369]) \n",
      "\n",
      "Model# 18. 3440 nodes still misclassified out of torch.Size([11369]) \n",
      "\n",
      "Model# 19. 3440 nodes still misclassified out of torch.Size([11369]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11382/11382 [00:00<00:00, 3854939.29it/s]\n",
      "100%|██████████| 11382/11382 [00:00<00:00, 4839777.79it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2792417.39it/s]\n",
      "Inferring Phrases: 100%|██████████| 11382/11382 [00:00<00:00, 397009.25it/s]\n",
      " 21%|██        | 63/299 [00:37<01:55,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3627 nodes still misclassified out of torch.Size([11382]) \n",
      "\n",
      "Model# 1. 3627 nodes still misclassified out of torch.Size([11382]) \n",
      "\n",
      "Model# 2. 3627 nodes still misclassified out of torch.Size([11382]) \n",
      "\n",
      "Model# 3. 3627 nodes still misclassified out of torch.Size([11382]) \n",
      "\n",
      "Model# 4. 3627 nodes still misclassified out of torch.Size([11382]) \n",
      "\n",
      "Model# 5. 3627 nodes still misclassified out of torch.Size([11382]) \n",
      "\n",
      "Model# 6. 3627 nodes still misclassified out of torch.Size([11382]) \n",
      "\n",
      "Model# 7. 3627 nodes still misclassified out of torch.Size([11382]) \n",
      "\n",
      "Model# 8. 3627 nodes still misclassified out of torch.Size([11382]) \n",
      "\n",
      "Model# 9. 3627 nodes still misclassified out of torch.Size([11382]) \n",
      "\n",
      "Model# 10. 3627 nodes still misclassified out of torch.Size([11382]) \n",
      "\n",
      "Model# 11. 3627 nodes still misclassified out of torch.Size([11382]) \n",
      "\n",
      "Model# 12. 3627 nodes still misclassified out of torch.Size([11382]) \n",
      "\n",
      "Model# 13. 3627 nodes still misclassified out of torch.Size([11382]) \n",
      "\n",
      "Model# 14. 3627 nodes still misclassified out of torch.Size([11382]) \n",
      "\n",
      "Model# 15. 3627 nodes still misclassified out of torch.Size([11382]) \n",
      "\n",
      "Model# 16. 3627 nodes still misclassified out of torch.Size([11382]) \n",
      "\n",
      "Model# 17. 3627 nodes still misclassified out of torch.Size([11382]) \n",
      "\n",
      "Model# 18. 3627 nodes still misclassified out of torch.Size([11382]) \n",
      "\n",
      "Model# 19. 3627 nodes still misclassified out of torch.Size([11382]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11850/11850 [00:00<00:00, 4105608.99it/s]\n",
      "100%|██████████| 11850/11850 [00:00<00:00, 4743057.77it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2341529.64it/s]\n",
      "Inferring Phrases: 100%|██████████| 11850/11850 [00:00<00:00, 357065.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4060 nodes still misclassified out of torch.Size([11850]) \n",
      "\n",
      "Model# 1. 4060 nodes still misclassified out of torch.Size([11850]) \n",
      "\n",
      "Model# 2. 4060 nodes still misclassified out of torch.Size([11850]) \n",
      "\n",
      "Model# 3. 4060 nodes still misclassified out of torch.Size([11850]) \n",
      "\n",
      "Model# 4. 4060 nodes still misclassified out of torch.Size([11850]) \n",
      "\n",
      "Model# 5. 4060 nodes still misclassified out of torch.Size([11850]) \n",
      "\n",
      "Model# 6. 4060 nodes still misclassified out of torch.Size([11850]) \n",
      "\n",
      "Model# 7. 4060 nodes still misclassified out of torch.Size([11850]) \n",
      "\n",
      "Model# 8. 4060 nodes still misclassified out of torch.Size([11850]) \n",
      "\n",
      "Model# 9. 4060 nodes still misclassified out of torch.Size([11850]) \n",
      "\n",
      "Model# 10. 4060 nodes still misclassified out of torch.Size([11850]) \n",
      "\n",
      "Model# 11. 4060 nodes still misclassified out of torch.Size([11850]) \n",
      "\n",
      "Model# 12. 4060 nodes still misclassified out of torch.Size([11850]) \n",
      "\n",
      "Model# 13. 4060 nodes still misclassified out of torch.Size([11850]) \n",
      "\n",
      "Model# 14. 4060 nodes still misclassified out of torch.Size([11850]) \n",
      "\n",
      "Model# 15. 4060 nodes still misclassified out of torch.Size([11850]) \n",
      "\n",
      "Model# 16. 4060 nodes still misclassified out of torch.Size([11850]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 64/299 [00:37<01:50,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 17. 4060 nodes still misclassified out of torch.Size([11850]) \n",
      "\n",
      "Model# 18. 4060 nodes still misclassified out of torch.Size([11850]) \n",
      "\n",
      "Model# 19. 4060 nodes still misclassified out of torch.Size([11850]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11790/11790 [00:00<00:00, 2605281.29it/s]\n",
      "100%|██████████| 11790/11790 [00:00<00:00, 2930594.06it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1945650.67it/s]\n",
      "Inferring Phrases: 100%|██████████| 11790/11790 [00:00<00:00, 359341.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3874 nodes still misclassified out of torch.Size([11790]) \n",
      "\n",
      "Model# 1. 3874 nodes still misclassified out of torch.Size([11790]) \n",
      "\n",
      "Model# 2. 3874 nodes still misclassified out of torch.Size([11790]) \n",
      "\n",
      "Model# 3. 3874 nodes still misclassified out of torch.Size([11790]) \n",
      "\n",
      "Model# 4. 3874 nodes still misclassified out of torch.Size([11790]) \n",
      "\n",
      "Model# 5. 3874 nodes still misclassified out of torch.Size([11790]) \n",
      "\n",
      "Model# 6. 3874 nodes still misclassified out of torch.Size([11790]) \n",
      "\n",
      "Model# 7. 3874 nodes still misclassified out of torch.Size([11790]) \n",
      "\n",
      "Model# 8. 3874 nodes still misclassified out of torch.Size([11790]) \n",
      "\n",
      "Model# 9. 3874 nodes still misclassified out of torch.Size([11790]) \n",
      "\n",
      "Model# 10. 3874 nodes still misclassified out of torch.Size([11790]) \n",
      "\n",
      "Model# 11. 3874 nodes still misclassified out of torch.Size([11790]) \n",
      "\n",
      "Model# 12. 3874 nodes still misclassified out of torch.Size([11790]) \n",
      "\n",
      "Model# 13. 3874 nodes still misclassified out of torch.Size([11790]) \n",
      "\n",
      "Model# 14. 3874 nodes still misclassified out of torch.Size([11790]) \n",
      "\n",
      "Model# 15. 3874 nodes still misclassified out of torch.Size([11790]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 65/299 [00:38<01:53,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 16. 3874 nodes still misclassified out of torch.Size([11790]) \n",
      "\n",
      "Model# 17. 3874 nodes still misclassified out of torch.Size([11790]) \n",
      "\n",
      "Model# 18. 3874 nodes still misclassified out of torch.Size([11790]) \n",
      "\n",
      "Model# 19. 3874 nodes still misclassified out of torch.Size([11790]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11333/11333 [00:00<00:00, 4140596.45it/s]\n",
      "100%|██████████| 11333/11333 [00:00<00:00, 5003583.92it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2905917.18it/s]\n",
      "Inferring Phrases: 100%|██████████| 11333/11333 [00:00<00:00, 392156.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3431 nodes still misclassified out of torch.Size([11333]) \n",
      "\n",
      "Model# 1. 3431 nodes still misclassified out of torch.Size([11333]) \n",
      "\n",
      "Model# 2. 3431 nodes still misclassified out of torch.Size([11333]) \n",
      "\n",
      "Model# 3. 3431 nodes still misclassified out of torch.Size([11333]) \n",
      "\n",
      "Model# 4. 3431 nodes still misclassified out of torch.Size([11333]) \n",
      "\n",
      "Model# 5. 3431 nodes still misclassified out of torch.Size([11333]) \n",
      "\n",
      "Model# 6. 3431 nodes still misclassified out of torch.Size([11333]) \n",
      "\n",
      "Model# 7. 3431 nodes still misclassified out of torch.Size([11333]) \n",
      "\n",
      "Model# 8. 3431 nodes still misclassified out of torch.Size([11333]) \n",
      "\n",
      "Model# 9. 3431 nodes still misclassified out of torch.Size([11333]) \n",
      "\n",
      "Model# 10. 3431 nodes still misclassified out of torch.Size([11333]) \n",
      "\n",
      "Model# 11. 3431 nodes still misclassified out of torch.Size([11333]) \n",
      "\n",
      "Model# 12. 3431 nodes still misclassified out of torch.Size([11333]) \n",
      "\n",
      "Model# 13. 3431 nodes still misclassified out of torch.Size([11333]) \n",
      "\n",
      "Model# 14. 3431 nodes still misclassified out of torch.Size([11333]) \n",
      "\n",
      "Model# 15. 3431 nodes still misclassified out of torch.Size([11333]) \n",
      "\n",
      "Model# 16. 3431 nodes still misclassified out of torch.Size([11333]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 66/299 [00:38<02:02,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 17. 3431 nodes still misclassified out of torch.Size([11333]) \n",
      "\n",
      "Model# 18. 3431 nodes still misclassified out of torch.Size([11333]) \n",
      "\n",
      "Model# 19. 3431 nodes still misclassified out of torch.Size([11333]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11603/11603 [00:00<00:00, 4047110.96it/s]\n",
      "100%|██████████| 11603/11603 [00:00<00:00, 3895814.07it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2708973.71it/s]\n",
      "Inferring Phrases: 100%|██████████| 11603/11603 [00:00<00:00, 347379.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3730 nodes still misclassified out of torch.Size([11603]) \n",
      "\n",
      "Model# 1. 3730 nodes still misclassified out of torch.Size([11603]) \n",
      "\n",
      "Model# 2. 3730 nodes still misclassified out of torch.Size([11603]) \n",
      "\n",
      "Model# 3. 3730 nodes still misclassified out of torch.Size([11603]) \n",
      "\n",
      "Model# 4. 3730 nodes still misclassified out of torch.Size([11603]) \n",
      "\n",
      "Model# 5. 3730 nodes still misclassified out of torch.Size([11603]) \n",
      "\n",
      "Model# 6. 3730 nodes still misclassified out of torch.Size([11603]) \n",
      "\n",
      "Model# 7. 3730 nodes still misclassified out of torch.Size([11603]) \n",
      "\n",
      "Model# 8. 3730 nodes still misclassified out of torch.Size([11603]) \n",
      "\n",
      "Model# 9. 3730 nodes still misclassified out of torch.Size([11603]) \n",
      "\n",
      "Model# 10. 3730 nodes still misclassified out of torch.Size([11603]) \n",
      "\n",
      "Model# 11. 3730 nodes still misclassified out of torch.Size([11603]) \n",
      "\n",
      "Model# 12. 3730 nodes still misclassified out of torch.Size([11603]) \n",
      "\n",
      "Model# 13. 3730 nodes still misclassified out of torch.Size([11603]) \n",
      "\n",
      "Model# 14. 3730 nodes still misclassified out of torch.Size([11603]) \n",
      "\n",
      "Model# 15. 3730 nodes still misclassified out of torch.Size([11603]) \n",
      "\n",
      "Model# 16. 3730 nodes still misclassified out of torch.Size([11603]) \n",
      "\n",
      "Model# 17. 3730 nodes still misclassified out of torch.Size([11603]) \n",
      "\n",
      "Model# 18. 3730 nodes still misclassified out of torch.Size([11603]) \n",
      "\n",
      "Model# 19. 3730 nodes still misclassified out of torch.Size([11603]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11905/11905 [00:00<00:00, 4004265.37it/s]\n",
      "100%|██████████| 11905/11905 [00:00<00:00, 4640199.71it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2584237.74it/s]\n",
      "Inferring Phrases: 100%|██████████| 11905/11905 [00:00<00:00, 363700.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4041 nodes still misclassified out of torch.Size([11905]) \n",
      "\n",
      "Model# 1. 4041 nodes still misclassified out of torch.Size([11905]) \n",
      "\n",
      "Model# 2. 4041 nodes still misclassified out of torch.Size([11905]) \n",
      "\n",
      "Model# 3. 4041 nodes still misclassified out of torch.Size([11905]) \n",
      "\n",
      "Model# 4. 4041 nodes still misclassified out of torch.Size([11905]) \n",
      "\n",
      "Model# 5. 4041 nodes still misclassified out of torch.Size([11905]) \n",
      "\n",
      "Model# 6. 4041 nodes still misclassified out of torch.Size([11905]) \n",
      "\n",
      "Model# 7. 4041 nodes still misclassified out of torch.Size([11905]) \n",
      "\n",
      "Model# 8. 4041 nodes still misclassified out of torch.Size([11905]) \n",
      "\n",
      "Model# 9. 4041 nodes still misclassified out of torch.Size([11905]) \n",
      "\n",
      "Model# 10. 4041 nodes still misclassified out of torch.Size([11905]) \n",
      "\n",
      "Model# 11. 4041 nodes still misclassified out of torch.Size([11905]) \n",
      "\n",
      "Model# 12. 4041 nodes still misclassified out of torch.Size([11905]) \n",
      "\n",
      "Model# 13. 4041 nodes still misclassified out of torch.Size([11905]) \n",
      "\n",
      "Model# 14. 4041 nodes still misclassified out of torch.Size([11905]) \n",
      "\n",
      "Model# 15. 4041 nodes still misclassified out of torch.Size([11905]) \n",
      "\n",
      "Model# 16. 4041 nodes still misclassified out of torch.Size([11905]) \n",
      "\n",
      "Model# 17. 4041 nodes still misclassified out of torch.Size([11905]) \n",
      "\n",
      "Model# 18. 4041 nodes still misclassified out of torch.Size([11905]) \n",
      "\n",
      "Model# 19. 4041 nodes still misclassified out of torch.Size([11905]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11673/11673 [00:00<00:00, 4472468.31it/s]\n",
      "100%|██████████| 11673/11673 [00:00<00:00, 5047954.49it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2692453.46it/s]\n",
      "Inferring Phrases: 100%|██████████| 11673/11673 [00:00<00:00, 363942.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3919 nodes still misclassified out of torch.Size([11673]) \n",
      "\n",
      "Model# 1. 3919 nodes still misclassified out of torch.Size([11673]) \n",
      "\n",
      "Model# 2. 3919 nodes still misclassified out of torch.Size([11673]) \n",
      "\n",
      "Model# 3. 3919 nodes still misclassified out of torch.Size([11673]) \n",
      "\n",
      "Model# 4. 3919 nodes still misclassified out of torch.Size([11673]) \n",
      "\n",
      "Model# 5. 3919 nodes still misclassified out of torch.Size([11673]) \n",
      "\n",
      "Model# 6. 3919 nodes still misclassified out of torch.Size([11673]) \n",
      "\n",
      "Model# 7. 3919 nodes still misclassified out of torch.Size([11673]) \n",
      "\n",
      "Model# 8. 3919 nodes still misclassified out of torch.Size([11673]) \n",
      "\n",
      "Model# 9. 3919 nodes still misclassified out of torch.Size([11673]) \n",
      "\n",
      "Model# 10. 3919 nodes still misclassified out of torch.Size([11673]) \n",
      "\n",
      "Model# 11. 3919 nodes still misclassified out of torch.Size([11673]) \n",
      "\n",
      "Model# 12. 3919 nodes still misclassified out of torch.Size([11673]) \n",
      "\n",
      "Model# 13. 3919 nodes still misclassified out of torch.Size([11673]) \n",
      "\n",
      "Model# 14. 3919 nodes still misclassified out of torch.Size([11673]) \n",
      "\n",
      "Model# 15. 3919 nodes still misclassified out of torch.Size([11673]) \n",
      "\n",
      "Model# 16. 3919 nodes still misclassified out of torch.Size([11673]) \n",
      "\n",
      "Model# 17. 3919 nodes still misclassified out of torch.Size([11673]) \n",
      "\n",
      "Model# 18. 3919 nodes still misclassified out of torch.Size([11673]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 69/299 [00:40<01:52,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 3919 nodes still misclassified out of torch.Size([11673]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11521/11521 [00:00<00:00, 4101389.95it/s]\n",
      "100%|██████████| 11521/11521 [00:00<00:00, 4586860.60it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2822293.20it/s]\n",
      "Inferring Phrases: 100%|██████████| 11521/11521 [00:00<00:00, 354885.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3678 nodes still misclassified out of torch.Size([11521]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 1. 3678 nodes still misclassified out of torch.Size([11521]) \n",
      "\n",
      "Model# 2. 3678 nodes still misclassified out of torch.Size([11521]) \n",
      "\n",
      "Model# 3. 3678 nodes still misclassified out of torch.Size([11521]) \n",
      "\n",
      "Model# 4. 3678 nodes still misclassified out of torch.Size([11521]) \n",
      "\n",
      "Model# 5. 3678 nodes still misclassified out of torch.Size([11521]) \n",
      "\n",
      "Model# 6. 3678 nodes still misclassified out of torch.Size([11521]) \n",
      "\n",
      "Model# 7. 3678 nodes still misclassified out of torch.Size([11521]) \n",
      "\n",
      "Model# 8. 3678 nodes still misclassified out of torch.Size([11521]) \n",
      "\n",
      "Model# 9. 3678 nodes still misclassified out of torch.Size([11521]) \n",
      "\n",
      "Model# 10. 3678 nodes still misclassified out of torch.Size([11521]) \n",
      "\n",
      "Model# 11. 3678 nodes still misclassified out of torch.Size([11521]) \n",
      "\n",
      "Model# 12. 3678 nodes still misclassified out of torch.Size([11521]) \n",
      "\n",
      "Model# 13. 3678 nodes still misclassified out of torch.Size([11521]) \n",
      "\n",
      "Model# 14. 3678 nodes still misclassified out of torch.Size([11521]) \n",
      "\n",
      "Model# 15. 3678 nodes still misclassified out of torch.Size([11521]) \n",
      "\n",
      "Model# 16. 3678 nodes still misclassified out of torch.Size([11521]) \n",
      "\n",
      "Model# 17. 3678 nodes still misclassified out of torch.Size([11521]) \n",
      "\n",
      "Model# 18. 3678 nodes still misclassified out of torch.Size([11521]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 70/299 [00:40<01:45,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 3678 nodes still misclassified out of torch.Size([11521]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13152/13152 [00:00<00:00, 3882838.47it/s]\n",
      "100%|██████████| 13152/13152 [00:00<00:00, 4554825.05it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1929805.68it/s]\n",
      "Inferring Phrases: 100%|██████████| 13152/13152 [00:00<00:00, 320587.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4987 nodes still misclassified out of torch.Size([13152]) \n",
      "\n",
      "Model# 1. 4987 nodes still misclassified out of torch.Size([13152]) \n",
      "\n",
      "Model# 2. 4987 nodes still misclassified out of torch.Size([13152]) \n",
      "\n",
      "Model# 3. 4987 nodes still misclassified out of torch.Size([13152]) \n",
      "\n",
      "Model# 4. 4987 nodes still misclassified out of torch.Size([13152]) \n",
      "\n",
      "Model# 5. 4987 nodes still misclassified out of torch.Size([13152]) \n",
      "\n",
      "Model# 6. 4987 nodes still misclassified out of torch.Size([13152]) \n",
      "\n",
      "Model# 7. 4987 nodes still misclassified out of torch.Size([13152]) \n",
      "\n",
      "Model# 8. 4987 nodes still misclassified out of torch.Size([13152]) \n",
      "\n",
      "Model# 9. 4987 nodes still misclassified out of torch.Size([13152]) \n",
      "\n",
      "Model# 10. 4987 nodes still misclassified out of torch.Size([13152]) \n",
      "\n",
      "Model# 11. 4987 nodes still misclassified out of torch.Size([13152]) \n",
      "\n",
      "Model# 12. 4987 nodes still misclassified out of torch.Size([13152]) \n",
      "\n",
      "Model# 13. 4987 nodes still misclassified out of torch.Size([13152]) \n",
      "\n",
      "Model# 14. 4987 nodes still misclassified out of torch.Size([13152]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 71/299 [00:40<01:49,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4987 nodes still misclassified out of torch.Size([13152]) \n",
      "\n",
      "Model# 16. 4987 nodes still misclassified out of torch.Size([13152]) \n",
      "\n",
      "Model# 17. 4987 nodes still misclassified out of torch.Size([13152]) \n",
      "\n",
      "Model# 18. 4987 nodes still misclassified out of torch.Size([13152]) \n",
      "\n",
      "Model# 19. 4987 nodes still misclassified out of torch.Size([13152]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13510/13510 [00:00<00:00, 4233157.56it/s]\n",
      "100%|██████████| 13510/13510 [00:00<00:00, 5031079.38it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2869273.50it/s]\n",
      "Inferring Phrases: 100%|██████████| 13510/13510 [00:00<00:00, 443052.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5116 nodes still misclassified out of torch.Size([13510]) \n",
      "\n",
      "Model# 1. 5116 nodes still misclassified out of torch.Size([13510]) \n",
      "\n",
      "Model# 2. 5116 nodes still misclassified out of torch.Size([13510]) \n",
      "\n",
      "Model# 3. 5116 nodes still misclassified out of torch.Size([13510]) \n",
      "\n",
      "Model# 4. 5116 nodes still misclassified out of torch.Size([13510]) \n",
      "\n",
      "Model# 5. 5116 nodes still misclassified out of torch.Size([13510]) \n",
      "\n",
      "Model# 6. 5116 nodes still misclassified out of torch.Size([13510]) \n",
      "\n",
      "Model# 7. 5116 nodes still misclassified out of torch.Size([13510]) \n",
      "\n",
      "Model# 8. 5116 nodes still misclassified out of torch.Size([13510]) \n",
      "\n",
      "Model# 9. 5116 nodes still misclassified out of torch.Size([13510]) \n",
      "\n",
      "Model# 10. 5116 nodes still misclassified out of torch.Size([13510]) \n",
      "\n",
      "Model# 11. 5116 nodes still misclassified out of torch.Size([13510]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 72/299 [00:41<02:03,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 12. 5116 nodes still misclassified out of torch.Size([13510]) \n",
      "\n",
      "Model# 13. 5116 nodes still misclassified out of torch.Size([13510]) \n",
      "\n",
      "Model# 14. 5116 nodes still misclassified out of torch.Size([13510]) \n",
      "\n",
      "Model# 15. 5116 nodes still misclassified out of torch.Size([13510]) \n",
      "\n",
      "Model# 16. 5116 nodes still misclassified out of torch.Size([13510]) \n",
      "\n",
      "Model# 17. 5116 nodes still misclassified out of torch.Size([13510]) \n",
      "\n",
      "Model# 18. 5116 nodes still misclassified out of torch.Size([13510]) \n",
      "\n",
      "Model# 19. 5116 nodes still misclassified out of torch.Size([13510]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12853/12853 [00:00<00:00, 2510566.26it/s]\n",
      "100%|██████████| 12853/12853 [00:00<00:00, 2938161.61it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1895159.58it/s]\n",
      "Inferring Phrases: 100%|██████████| 12853/12853 [00:00<00:00, 402005.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4628 nodes still misclassified out of torch.Size([12853]) \n",
      "\n",
      "Model# 1. 4628 nodes still misclassified out of torch.Size([12853]) \n",
      "\n",
      "Model# 2. 4628 nodes still misclassified out of torch.Size([12853]) \n",
      "\n",
      "Model# 3. 4628 nodes still misclassified out of torch.Size([12853]) \n",
      "\n",
      "Model# 4. 4628 nodes still misclassified out of torch.Size([12853]) \n",
      "\n",
      "Model# 5. 4628 nodes still misclassified out of torch.Size([12853]) \n",
      "\n",
      "Model# 6. 4628 nodes still misclassified out of torch.Size([12853]) \n",
      "\n",
      "Model# 7. 4628 nodes still misclassified out of torch.Size([12853]) \n",
      "\n",
      "Model# 8. 4628 nodes still misclassified out of torch.Size([12853]) \n",
      "\n",
      "Model# 9. 4628 nodes still misclassified out of torch.Size([12853]) \n",
      "\n",
      "Model# 10. 4628 nodes still misclassified out of torch.Size([12853]) \n",
      "\n",
      "Model# 11. 4628 nodes still misclassified out of torch.Size([12853]) \n",
      "\n",
      "Model# 12. 4628 nodes still misclassified out of torch.Size([12853]) \n",
      "\n",
      "Model# 13. 4628 nodes still misclassified out of torch.Size([12853]) \n",
      "\n",
      "Model# 14. 4628 nodes still misclassified out of torch.Size([12853]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 73/299 [00:42<02:01,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4628 nodes still misclassified out of torch.Size([12853]) \n",
      "\n",
      "Model# 16. 4628 nodes still misclassified out of torch.Size([12853]) \n",
      "\n",
      "Model# 17. 4628 nodes still misclassified out of torch.Size([12853]) \n",
      "\n",
      "Model# 18. 4628 nodes still misclassified out of torch.Size([12853]) \n",
      "\n",
      "Model# 19. 4628 nodes still misclassified out of torch.Size([12853]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13068/13068 [00:00<00:00, 2617659.14it/s]\n",
      "100%|██████████| 13068/13068 [00:00<00:00, 2932646.58it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1937382.52it/s]\n",
      "Inferring Phrases: 100%|██████████| 13068/13068 [00:00<00:00, 390743.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4964 nodes still misclassified out of torch.Size([13068]) \n",
      "\n",
      "Model# 1. 4964 nodes still misclassified out of torch.Size([13068]) \n",
      "\n",
      "Model# 2. 4964 nodes still misclassified out of torch.Size([13068]) \n",
      "\n",
      "Model# 3. 4964 nodes still misclassified out of torch.Size([13068]) \n",
      "\n",
      "Model# 4. 4964 nodes still misclassified out of torch.Size([13068]) \n",
      "\n",
      "Model# 5. 4964 nodes still misclassified out of torch.Size([13068]) \n",
      "\n",
      "Model# 6. 4964 nodes still misclassified out of torch.Size([13068]) \n",
      "\n",
      "Model# 7. 4964 nodes still misclassified out of torch.Size([13068]) \n",
      "\n",
      "Model# 8. 4964 nodes still misclassified out of torch.Size([13068]) \n",
      "\n",
      "Model# 9. 4964 nodes still misclassified out of torch.Size([13068]) \n",
      "\n",
      "Model# 10. 4964 nodes still misclassified out of torch.Size([13068]) \n",
      "\n",
      "Model# 11. 4964 nodes still misclassified out of torch.Size([13068]) \n",
      "\n",
      "Model# 12. 4964 nodes still misclassified out of torch.Size([13068]) \n",
      "\n",
      "Model# 13. 4964 nodes still misclassified out of torch.Size([13068]) \n",
      "\n",
      "Model# 14. 4964 nodes still misclassified out of torch.Size([13068]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 74/299 [00:42<02:01,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4964 nodes still misclassified out of torch.Size([13068]) \n",
      "\n",
      "Model# 16. 4964 nodes still misclassified out of torch.Size([13068]) \n",
      "\n",
      "Model# 17. 4964 nodes still misclassified out of torch.Size([13068]) \n",
      "\n",
      "Model# 18. 4964 nodes still misclassified out of torch.Size([13068]) \n",
      "\n",
      "Model# 19. 4964 nodes still misclassified out of torch.Size([13068]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12993/12993 [00:00<00:00, 4346167.31it/s]\n",
      "100%|██████████| 12993/12993 [00:00<00:00, 5267916.08it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2854886.44it/s]\n",
      "Inferring Phrases: 100%|██████████| 12993/12993 [00:00<00:00, 437126.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4841 nodes still misclassified out of torch.Size([12993]) \n",
      "\n",
      "Model# 1. 4841 nodes still misclassified out of torch.Size([12993]) \n",
      "\n",
      "Model# 2. 4841 nodes still misclassified out of torch.Size([12993]) \n",
      "\n",
      "Model# 3. 4841 nodes still misclassified out of torch.Size([12993]) \n",
      "\n",
      "Model# 4. 4841 nodes still misclassified out of torch.Size([12993]) \n",
      "\n",
      "Model# 5. 4841 nodes still misclassified out of torch.Size([12993]) \n",
      "\n",
      "Model# 6. 4841 nodes still misclassified out of torch.Size([12993]) \n",
      "\n",
      "Model# 7. 4841 nodes still misclassified out of torch.Size([12993]) \n",
      "\n",
      "Model# 8. 4841 nodes still misclassified out of torch.Size([12993]) \n",
      "\n",
      "Model# 9. 4841 nodes still misclassified out of torch.Size([12993]) \n",
      "\n",
      "Model# 10. 4841 nodes still misclassified out of torch.Size([12993]) \n",
      "\n",
      "Model# 11. 4841 nodes still misclassified out of torch.Size([12993]) \n",
      "\n",
      "Model# 12. 4841 nodes still misclassified out of torch.Size([12993]) \n",
      "\n",
      "Model# 13. 4841 nodes still misclassified out of torch.Size([12993]) \n",
      "\n",
      "Model# 14. 4841 nodes still misclassified out of torch.Size([12993]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 75/299 [00:43<02:08,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4841 nodes still misclassified out of torch.Size([12993]) \n",
      "\n",
      "Model# 16. 4841 nodes still misclassified out of torch.Size([12993]) \n",
      "\n",
      "Model# 17. 4841 nodes still misclassified out of torch.Size([12993]) \n",
      "\n",
      "Model# 18. 4841 nodes still misclassified out of torch.Size([12993]) \n",
      "\n",
      "Model# 19. 4841 nodes still misclassified out of torch.Size([12993]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12546/12546 [00:00<00:00, 2641388.31it/s]\n",
      "100%|██████████| 12546/12546 [00:00<00:00, 2948822.53it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1943276.86it/s]\n",
      "Inferring Phrases: 100%|██████████| 12546/12546 [00:00<00:00, 377771.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4348 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 1. 4348 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 2. 4348 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 3. 4348 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 4. 4348 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 5. 4348 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 6. 4348 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 7. 4348 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 8. 4348 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 9. 4348 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 10. 4348 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 11. 4348 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 12. 4348 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 13. 4348 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 14. 4348 nodes still misclassified out of torch.Size([12546]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 76/299 [00:43<02:04,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4348 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 16. 4348 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 17. 4348 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 18. 4348 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 19. 4348 nodes still misclassified out of torch.Size([12546]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12804/12804 [00:00<00:00, 4399071.79it/s]\n",
      "100%|██████████| 12804/12804 [00:00<00:00, 4598327.63it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2849262.26it/s]\n",
      "Inferring Phrases: 100%|██████████| 12804/12804 [00:00<00:00, 432739.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4756 nodes still misclassified out of torch.Size([12804]) \n",
      "\n",
      "Model# 1. 4756 nodes still misclassified out of torch.Size([12804]) \n",
      "\n",
      "Model# 2. 4756 nodes still misclassified out of torch.Size([12804]) \n",
      "\n",
      "Model# 3. 4756 nodes still misclassified out of torch.Size([12804]) \n",
      "\n",
      "Model# 4. 4756 nodes still misclassified out of torch.Size([12804]) \n",
      "\n",
      "Model# 5. 4756 nodes still misclassified out of torch.Size([12804]) \n",
      "\n",
      "Model# 6. 4756 nodes still misclassified out of torch.Size([12804]) \n",
      "\n",
      "Model# 7. 4756 nodes still misclassified out of torch.Size([12804]) \n",
      "\n",
      "Model# 8. 4756 nodes still misclassified out of torch.Size([12804]) \n",
      "\n",
      "Model# 9. 4756 nodes still misclassified out of torch.Size([12804]) \n",
      "\n",
      "Model# 10. 4756 nodes still misclassified out of torch.Size([12804]) \n",
      "\n",
      "Model# 11. 4756 nodes still misclassified out of torch.Size([12804]) \n",
      "\n",
      "Model# 12. 4756 nodes still misclassified out of torch.Size([12804]) \n",
      "\n",
      "Model# 13. 4756 nodes still misclassified out of torch.Size([12804]) \n",
      "\n",
      "Model# 14. 4756 nodes still misclassified out of torch.Size([12804]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 77/299 [00:44<02:09,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4756 nodes still misclassified out of torch.Size([12804]) \n",
      "\n",
      "Model# 16. 4756 nodes still misclassified out of torch.Size([12804]) \n",
      "\n",
      "Model# 17. 4756 nodes still misclassified out of torch.Size([12804]) \n",
      "\n",
      "Model# 18. 4756 nodes still misclassified out of torch.Size([12804]) \n",
      "\n",
      "Model# 19. 4756 nodes still misclassified out of torch.Size([12804]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12869/12869 [00:00<00:00, 2687938.76it/s]\n",
      "100%|██████████| 12869/12869 [00:00<00:00, 2988400.96it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1983935.42it/s]\n",
      "Inferring Phrases: 100%|██████████| 12869/12869 [00:00<00:00, 366977.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3804 nodes still misclassified out of torch.Size([12869]) \n",
      "\n",
      "Model# 1. 3804 nodes still misclassified out of torch.Size([12869]) \n",
      "\n",
      "Model# 2. 3804 nodes still misclassified out of torch.Size([12869]) \n",
      "\n",
      "Model# 3. 3804 nodes still misclassified out of torch.Size([12869]) \n",
      "\n",
      "Model# 4. 3804 nodes still misclassified out of torch.Size([12869]) \n",
      "\n",
      "Model# 5. 3804 nodes still misclassified out of torch.Size([12869]) \n",
      "\n",
      "Model# 6. 3804 nodes still misclassified out of torch.Size([12869]) \n",
      "\n",
      "Model# 7. 3804 nodes still misclassified out of torch.Size([12869]) \n",
      "\n",
      "Model# 8. 3804 nodes still misclassified out of torch.Size([12869]) \n",
      "\n",
      "Model# 9. 3804 nodes still misclassified out of torch.Size([12869]) \n",
      "\n",
      "Model# 10. 3804 nodes still misclassified out of torch.Size([12869]) \n",
      "\n",
      "Model# 11. 3804 nodes still misclassified out of torch.Size([12869]) \n",
      "\n",
      "Model# 12. 3804 nodes still misclassified out of torch.Size([12869]) \n",
      "\n",
      "Model# 13. 3804 nodes still misclassified out of torch.Size([12869]) \n",
      "\n",
      "Model# 14. 3804 nodes still misclassified out of torch.Size([12869]) \n",
      "\n",
      "Model# 15. 3804 nodes still misclassified out of torch.Size([12869]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 78/299 [00:45<02:04,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 16. 3804 nodes still misclassified out of torch.Size([12869]) \n",
      "\n",
      "Model# 17. 3804 nodes still misclassified out of torch.Size([12869]) \n",
      "\n",
      "Model# 18. 3804 nodes still misclassified out of torch.Size([12869]) \n",
      "\n",
      "Model# 19. 3804 nodes still misclassified out of torch.Size([12869]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12997/12997 [00:00<00:00, 2706721.40it/s]\n",
      "100%|██████████| 12997/12997 [00:00<00:00, 3013120.11it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1971347.19it/s]\n",
      "Inferring Phrases: 100%|██████████| 12997/12997 [00:00<00:00, 360259.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4751 nodes still misclassified out of torch.Size([12997]) \n",
      "\n",
      "Model# 1. 4751 nodes still misclassified out of torch.Size([12997]) \n",
      "\n",
      "Model# 2. 4751 nodes still misclassified out of torch.Size([12997]) \n",
      "\n",
      "Model# 3. 4751 nodes still misclassified out of torch.Size([12997]) \n",
      "\n",
      "Model# 4. 4751 nodes still misclassified out of torch.Size([12997]) \n",
      "\n",
      "Model# 5. 4751 nodes still misclassified out of torch.Size([12997]) \n",
      "\n",
      "Model# 6. 4751 nodes still misclassified out of torch.Size([12997]) \n",
      "\n",
      "Model# 7. 4751 nodes still misclassified out of torch.Size([12997]) \n",
      "\n",
      "Model# 8. 4751 nodes still misclassified out of torch.Size([12997]) \n",
      "\n",
      "Model# 9. 4751 nodes still misclassified out of torch.Size([12997]) \n",
      "\n",
      "Model# 10. 4751 nodes still misclassified out of torch.Size([12997]) \n",
      "\n",
      "Model# 11. 4751 nodes still misclassified out of torch.Size([12997]) \n",
      "\n",
      "Model# 12. 4751 nodes still misclassified out of torch.Size([12997]) \n",
      "\n",
      "Model# 13. 4751 nodes still misclassified out of torch.Size([12997]) \n",
      "\n",
      "Model# 14. 4751 nodes still misclassified out of torch.Size([12997]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 79/299 [00:45<02:02,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4751 nodes still misclassified out of torch.Size([12997]) \n",
      "\n",
      "Model# 16. 4751 nodes still misclassified out of torch.Size([12997]) \n",
      "\n",
      "Model# 17. 4751 nodes still misclassified out of torch.Size([12997]) \n",
      "\n",
      "Model# 18. 4751 nodes still misclassified out of torch.Size([12997]) \n",
      "\n",
      "Model# 19. 4751 nodes still misclassified out of torch.Size([12997]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12943/12943 [00:00<00:00, 4589303.97it/s]\n",
      "100%|██████████| 12943/12943 [00:00<00:00, 5408136.75it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2965220.22it/s]\n",
      "Inferring Phrases: 100%|██████████| 12943/12943 [00:00<00:00, 416837.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4781 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 1. 4781 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 2. 4781 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 3. 4781 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 4. 4781 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 5. 4781 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 6. 4781 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 7. 4781 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 8. 4781 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 9. 4781 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 10. 4781 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 11. 4781 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 12. 4781 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 13. 4781 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 14. 4781 nodes still misclassified out of torch.Size([12943]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 80/299 [00:46<02:11,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4781 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 16. 4781 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 17. 4781 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 18. 4781 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 19. 4781 nodes still misclassified out of torch.Size([12943]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13167/13167 [00:00<00:00, 2640390.17it/s]\n",
      "100%|██████████| 13167/13167 [00:00<00:00, 2988118.21it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1952897.94it/s]\n",
      "Inferring Phrases: 100%|██████████| 13167/13167 [00:00<00:00, 369254.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5460 nodes still misclassified out of torch.Size([13167]) \n",
      "\n",
      "Model# 1. 5460 nodes still misclassified out of torch.Size([13167]) \n",
      "\n",
      "Model# 2. 5460 nodes still misclassified out of torch.Size([13167]) \n",
      "\n",
      "Model# 3. 5460 nodes still misclassified out of torch.Size([13167]) \n",
      "\n",
      "Model# 4. 5460 nodes still misclassified out of torch.Size([13167]) \n",
      "\n",
      "Model# 5. 5460 nodes still misclassified out of torch.Size([13167]) \n",
      "\n",
      "Model# 6. 5460 nodes still misclassified out of torch.Size([13167]) \n",
      "\n",
      "Model# 7. 5460 nodes still misclassified out of torch.Size([13167]) \n",
      "\n",
      "Model# 8. 5460 nodes still misclassified out of torch.Size([13167]) \n",
      "\n",
      "Model# 9. 5460 nodes still misclassified out of torch.Size([13167]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 81/299 [00:46<02:14,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 5460 nodes still misclassified out of torch.Size([13167]) \n",
      "\n",
      "Model# 11. 5460 nodes still misclassified out of torch.Size([13167]) \n",
      "\n",
      "Model# 12. 5460 nodes still misclassified out of torch.Size([13167]) \n",
      "\n",
      "Model# 13. 5460 nodes still misclassified out of torch.Size([13167]) \n",
      "\n",
      "Model# 14. 5460 nodes still misclassified out of torch.Size([13167]) \n",
      "\n",
      "Model# 15. 5460 nodes still misclassified out of torch.Size([13167]) \n",
      "\n",
      "Model# 16. 5460 nodes still misclassified out of torch.Size([13167]) \n",
      "\n",
      "Model# 17. 5460 nodes still misclassified out of torch.Size([13167]) \n",
      "\n",
      "Model# 18. 5460 nodes still misclassified out of torch.Size([13167]) \n",
      "\n",
      "Model# 19. 5460 nodes still misclassified out of torch.Size([13167]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13199/13199 [00:00<00:00, 3981059.87it/s]\n",
      "100%|██████████| 13199/13199 [00:00<00:00, 4718770.75it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2523193.17it/s]\n",
      "Inferring Phrases: 100%|██████████| 13199/13199 [00:00<00:00, 408514.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5224 nodes still misclassified out of torch.Size([13199]) \n",
      "\n",
      "Model# 1. 5224 nodes still misclassified out of torch.Size([13199]) \n",
      "\n",
      "Model# 2. 5224 nodes still misclassified out of torch.Size([13199]) \n",
      "\n",
      "Model# 3. 5224 nodes still misclassified out of torch.Size([13199]) \n",
      "\n",
      "Model# 4. 5224 nodes still misclassified out of torch.Size([13199]) \n",
      "\n",
      "Model# 5. 5224 nodes still misclassified out of torch.Size([13199]) \n",
      "\n",
      "Model# 6. 5224 nodes still misclassified out of torch.Size([13199]) \n",
      "\n",
      "Model# 7. 5224 nodes still misclassified out of torch.Size([13199]) \n",
      "\n",
      "Model# 8. 5224 nodes still misclassified out of torch.Size([13199]) \n",
      "\n",
      "Model# 9. 5224 nodes still misclassified out of torch.Size([13199]) \n",
      "\n",
      "Model# 10. 5224 nodes still misclassified out of torch.Size([13199]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 82/299 [00:47<02:25,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 5224 nodes still misclassified out of torch.Size([13199]) \n",
      "\n",
      "Model# 12. 5224 nodes still misclassified out of torch.Size([13199]) \n",
      "\n",
      "Model# 13. 5224 nodes still misclassified out of torch.Size([13199]) \n",
      "\n",
      "Model# 14. 5224 nodes still misclassified out of torch.Size([13199]) \n",
      "\n",
      "Model# 15. 5224 nodes still misclassified out of torch.Size([13199]) \n",
      "\n",
      "Model# 16. 5224 nodes still misclassified out of torch.Size([13199]) \n",
      "\n",
      "Model# 17. 5224 nodes still misclassified out of torch.Size([13199]) \n",
      "\n",
      "Model# 18. 5224 nodes still misclassified out of torch.Size([13199]) \n",
      "\n",
      "Model# 19. 5224 nodes still misclassified out of torch.Size([13199]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13568/13568 [00:00<00:00, 2641983.13it/s]\n",
      "100%|██████████| 13568/13568 [00:00<00:00, 2936597.18it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1926880.03it/s]\n",
      "Inferring Phrases: 100%|██████████| 13568/13568 [00:00<00:00, 418905.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5123 nodes still misclassified out of torch.Size([13568]) \n",
      "\n",
      "Model# 1. 5123 nodes still misclassified out of torch.Size([13568]) \n",
      "\n",
      "Model# 2. 5123 nodes still misclassified out of torch.Size([13568]) \n",
      "\n",
      "Model# 3. 5123 nodes still misclassified out of torch.Size([13568]) \n",
      "\n",
      "Model# 4. 5123 nodes still misclassified out of torch.Size([13568]) \n",
      "\n",
      "Model# 5. 5123 nodes still misclassified out of torch.Size([13568]) \n",
      "\n",
      "Model# 6. 5123 nodes still misclassified out of torch.Size([13568]) \n",
      "\n",
      "Model# 7. 5123 nodes still misclassified out of torch.Size([13568]) \n",
      "\n",
      "Model# 8. 5123 nodes still misclassified out of torch.Size([13568]) \n",
      "\n",
      "Model# 9. 5123 nodes still misclassified out of torch.Size([13568]) \n",
      "\n",
      "Model# 10. 5123 nodes still misclassified out of torch.Size([13568]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 83/299 [00:48<02:23,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 5123 nodes still misclassified out of torch.Size([13568]) \n",
      "\n",
      "Model# 12. 5123 nodes still misclassified out of torch.Size([13568]) \n",
      "\n",
      "Model# 13. 5123 nodes still misclassified out of torch.Size([13568]) \n",
      "\n",
      "Model# 14. 5123 nodes still misclassified out of torch.Size([13568]) \n",
      "\n",
      "Model# 15. 5123 nodes still misclassified out of torch.Size([13568]) \n",
      "\n",
      "Model# 16. 5123 nodes still misclassified out of torch.Size([13568]) \n",
      "\n",
      "Model# 17. 5123 nodes still misclassified out of torch.Size([13568]) \n",
      "\n",
      "Model# 18. 5123 nodes still misclassified out of torch.Size([13568]) \n",
      "\n",
      "Model# 19. 5123 nodes still misclassified out of torch.Size([13568]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12408/12408 [00:00<00:00, 2224341.75it/s]\n",
      "100%|██████████| 12408/12408 [00:00<00:00, 2810093.09it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1838908.02it/s]\n",
      "Inferring Phrases: 100%|██████████| 12408/12408 [00:00<00:00, 348190.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4301 nodes still misclassified out of torch.Size([12408]) \n",
      "\n",
      "Model# 1. 4301 nodes still misclassified out of torch.Size([12408]) \n",
      "\n",
      "Model# 2. 4301 nodes still misclassified out of torch.Size([12408]) \n",
      "\n",
      "Model# 3. 4301 nodes still misclassified out of torch.Size([12408]) \n",
      "\n",
      "Model# 4. 4301 nodes still misclassified out of torch.Size([12408]) \n",
      "\n",
      "Model# 5. 4301 nodes still misclassified out of torch.Size([12408]) \n",
      "\n",
      "Model# 6. 4301 nodes still misclassified out of torch.Size([12408]) \n",
      "\n",
      "Model# 7. 4301 nodes still misclassified out of torch.Size([12408]) \n",
      "\n",
      "Model# 8. 4301 nodes still misclassified out of torch.Size([12408]) \n",
      "\n",
      "Model# 9. 4301 nodes still misclassified out of torch.Size([12408]) \n",
      "\n",
      "Model# 10. 4301 nodes still misclassified out of torch.Size([12408]) \n",
      "\n",
      "Model# 11. 4301 nodes still misclassified out of torch.Size([12408]) \n",
      "\n",
      "Model# 12. 4301 nodes still misclassified out of torch.Size([12408]) \n",
      "\n",
      "Model# 13. 4301 nodes still misclassified out of torch.Size([12408]) \n",
      "\n",
      "Model# 14. 4301 nodes still misclassified out of torch.Size([12408]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 84/299 [00:48<02:13,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4301 nodes still misclassified out of torch.Size([12408]) \n",
      "\n",
      "Model# 16. 4301 nodes still misclassified out of torch.Size([12408]) \n",
      "\n",
      "Model# 17. 4301 nodes still misclassified out of torch.Size([12408]) \n",
      "\n",
      "Model# 18. 4301 nodes still misclassified out of torch.Size([12408]) \n",
      "\n",
      "Model# 19. 4301 nodes still misclassified out of torch.Size([12408]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13282/13282 [00:00<00:00, 3789968.41it/s]\n",
      "100%|██████████| 13282/13282 [00:00<00:00, 4633129.22it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2710958.10it/s]\n",
      "Inferring Phrases: 100%|██████████| 13282/13282 [00:00<00:00, 431182.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5040 nodes still misclassified out of torch.Size([13282]) \n",
      "\n",
      "Model# 1. 5040 nodes still misclassified out of torch.Size([13282]) \n",
      "\n",
      "Model# 2. 5040 nodes still misclassified out of torch.Size([13282]) \n",
      "\n",
      "Model# 3. 5040 nodes still misclassified out of torch.Size([13282]) \n",
      "\n",
      "Model# 4. 5040 nodes still misclassified out of torch.Size([13282]) \n",
      "\n",
      "Model# 5. 5040 nodes still misclassified out of torch.Size([13282]) \n",
      "\n",
      "Model# 6. 5040 nodes still misclassified out of torch.Size([13282]) \n",
      "\n",
      "Model# 7. 5040 nodes still misclassified out of torch.Size([13282]) \n",
      "\n",
      "Model# 8. 5040 nodes still misclassified out of torch.Size([13282]) \n",
      "\n",
      "Model# 9. 5040 nodes still misclassified out of torch.Size([13282]) \n",
      "\n",
      "Model# 10. 5040 nodes still misclassified out of torch.Size([13282]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 85/299 [00:49<02:18,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 5040 nodes still misclassified out of torch.Size([13282]) \n",
      "\n",
      "Model# 12. 5040 nodes still misclassified out of torch.Size([13282]) \n",
      "\n",
      "Model# 13. 5040 nodes still misclassified out of torch.Size([13282]) \n",
      "\n",
      "Model# 14. 5040 nodes still misclassified out of torch.Size([13282]) \n",
      "\n",
      "Model# 15. 5040 nodes still misclassified out of torch.Size([13282]) \n",
      "\n",
      "Model# 16. 5040 nodes still misclassified out of torch.Size([13282]) \n",
      "\n",
      "Model# 17. 5040 nodes still misclassified out of torch.Size([13282]) \n",
      "\n",
      "Model# 18. 5040 nodes still misclassified out of torch.Size([13282]) \n",
      "\n",
      "Model# 19. 5040 nodes still misclassified out of torch.Size([13282]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13299/13299 [00:00<00:00, 4052899.00it/s]\n",
      "100%|██████████| 13299/13299 [00:00<00:00, 4750472.57it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2770834.14it/s]\n",
      "Inferring Phrases: 100%|██████████| 13299/13299 [00:00<00:00, 395808.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4373 nodes still misclassified out of torch.Size([13299]) \n",
      "\n",
      "Model# 1. 4373 nodes still misclassified out of torch.Size([13299]) \n",
      "\n",
      "Model# 2. 4373 nodes still misclassified out of torch.Size([13299]) \n",
      "\n",
      "Model# 3. 4373 nodes still misclassified out of torch.Size([13299]) \n",
      "\n",
      "Model# 4. 4373 nodes still misclassified out of torch.Size([13299]) \n",
      "\n",
      "Model# 5. 4373 nodes still misclassified out of torch.Size([13299]) \n",
      "\n",
      "Model# 6. 4373 nodes still misclassified out of torch.Size([13299]) \n",
      "\n",
      "Model# 7. 4373 nodes still misclassified out of torch.Size([13299]) \n",
      "\n",
      "Model# 8. 4373 nodes still misclassified out of torch.Size([13299]) \n",
      "\n",
      "Model# 9. 4373 nodes still misclassified out of torch.Size([13299]) \n",
      "\n",
      "Model# 10. 4373 nodes still misclassified out of torch.Size([13299]) \n",
      "\n",
      "Model# 11. 4373 nodes still misclassified out of torch.Size([13299]) \n",
      "\n",
      "Model# 12. 4373 nodes still misclassified out of torch.Size([13299]) \n",
      "\n",
      "Model# 13. 4373 nodes still misclassified out of torch.Size([13299]) \n",
      "\n",
      "Model# 14. 4373 nodes still misclassified out of torch.Size([13299]) \n",
      "\n",
      "Model# 15. 4373 nodes still misclassified out of torch.Size([13299]) \n",
      "\n",
      "Model# 16. 4373 nodes still misclassified out of torch.Size([13299]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 86/299 [00:50<02:05,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 17. 4373 nodes still misclassified out of torch.Size([13299]) \n",
      "\n",
      "Model# 18. 4373 nodes still misclassified out of torch.Size([13299]) \n",
      "\n",
      "Model# 19. 4373 nodes still misclassified out of torch.Size([13299]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13725/13725 [00:00<00:00, 4016103.14it/s]\n",
      "100%|██████████| 13725/13725 [00:00<00:00, 4784078.98it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2722513.31it/s]\n",
      "Inferring Phrases: 100%|██████████| 13725/13725 [00:00<00:00, 404662.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5490 nodes still misclassified out of torch.Size([13725]) \n",
      "\n",
      "Model# 1. 5490 nodes still misclassified out of torch.Size([13725]) \n",
      "\n",
      "Model# 2. 5490 nodes still misclassified out of torch.Size([13725]) \n",
      "\n",
      "Model# 3. 5490 nodes still misclassified out of torch.Size([13725]) \n",
      "\n",
      "Model# 4. 5490 nodes still misclassified out of torch.Size([13725]) \n",
      "\n",
      "Model# 5. 5490 nodes still misclassified out of torch.Size([13725]) \n",
      "\n",
      "Model# 6. 5490 nodes still misclassified out of torch.Size([13725]) \n",
      "\n",
      "Model# 7. 5490 nodes still misclassified out of torch.Size([13725]) \n",
      "\n",
      "Model# 8. 5490 nodes still misclassified out of torch.Size([13725]) \n",
      "\n",
      "Model# 9. 5490 nodes still misclassified out of torch.Size([13725]) \n",
      "\n",
      "Model# 10. 5490 nodes still misclassified out of torch.Size([13725]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 87/299 [00:50<02:03,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 5490 nodes still misclassified out of torch.Size([13725]) \n",
      "\n",
      "Model# 12. 5490 nodes still misclassified out of torch.Size([13725]) \n",
      "\n",
      "Model# 13. 5490 nodes still misclassified out of torch.Size([13725]) \n",
      "\n",
      "Model# 14. 5490 nodes still misclassified out of torch.Size([13725]) \n",
      "\n",
      "Model# 15. 5490 nodes still misclassified out of torch.Size([13725]) \n",
      "\n",
      "Model# 16. 5490 nodes still misclassified out of torch.Size([13725]) \n",
      "\n",
      "Model# 17. 5490 nodes still misclassified out of torch.Size([13725]) \n",
      "\n",
      "Model# 18. 5490 nodes still misclassified out of torch.Size([13725]) \n",
      "\n",
      "Model# 19. 5490 nodes still misclassified out of torch.Size([13725]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13307/13307 [00:00<00:00, 4508368.60it/s]\n",
      "100%|██████████| 13307/13307 [00:00<00:00, 5446292.28it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2950825.95it/s]\n",
      "Inferring Phrases: 100%|██████████| 13307/13307 [00:00<00:00, 439169.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5230 nodes still misclassified out of torch.Size([13307]) \n",
      "\n",
      "Model# 1. 5230 nodes still misclassified out of torch.Size([13307]) \n",
      "\n",
      "Model# 2. 5230 nodes still misclassified out of torch.Size([13307]) \n",
      "\n",
      "Model# 3. 5230 nodes still misclassified out of torch.Size([13307]) \n",
      "\n",
      "Model# 4. 5230 nodes still misclassified out of torch.Size([13307]) \n",
      "\n",
      "Model# 5. 5230 nodes still misclassified out of torch.Size([13307]) \n",
      "\n",
      "Model# 6. 5230 nodes still misclassified out of torch.Size([13307]) \n",
      "\n",
      "Model# 7. 5230 nodes still misclassified out of torch.Size([13307]) \n",
      "\n",
      "Model# 8. 5230 nodes still misclassified out of torch.Size([13307]) \n",
      "\n",
      "Model# 9. 5230 nodes still misclassified out of torch.Size([13307]) \n",
      "\n",
      "Model# 10. 5230 nodes still misclassified out of torch.Size([13307]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 88/299 [00:51<02:13,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 5230 nodes still misclassified out of torch.Size([13307]) \n",
      "\n",
      "Model# 12. 5230 nodes still misclassified out of torch.Size([13307]) \n",
      "\n",
      "Model# 13. 5230 nodes still misclassified out of torch.Size([13307]) \n",
      "\n",
      "Model# 14. 5230 nodes still misclassified out of torch.Size([13307]) \n",
      "\n",
      "Model# 15. 5230 nodes still misclassified out of torch.Size([13307]) \n",
      "\n",
      "Model# 16. 5230 nodes still misclassified out of torch.Size([13307]) \n",
      "\n",
      "Model# 17. 5230 nodes still misclassified out of torch.Size([13307]) \n",
      "\n",
      "Model# 18. 5230 nodes still misclassified out of torch.Size([13307]) \n",
      "\n",
      "Model# 19. 5230 nodes still misclassified out of torch.Size([13307]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13381/13381 [00:00<00:00, 2657763.03it/s]\n",
      "100%|██████████| 13381/13381 [00:00<00:00, 2971881.48it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1975215.37it/s]\n",
      "Inferring Phrases: 100%|██████████| 13381/13381 [00:00<00:00, 397892.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5207 nodes still misclassified out of torch.Size([13381]) \n",
      "\n",
      "Model# 1. 5207 nodes still misclassified out of torch.Size([13381]) \n",
      "\n",
      "Model# 2. 5207 nodes still misclassified out of torch.Size([13381]) \n",
      "\n",
      "Model# 3. 5207 nodes still misclassified out of torch.Size([13381]) \n",
      "\n",
      "Model# 4. 5207 nodes still misclassified out of torch.Size([13381]) \n",
      "\n",
      "Model# 5. 5207 nodes still misclassified out of torch.Size([13381]) \n",
      "\n",
      "Model# 6. 5207 nodes still misclassified out of torch.Size([13381]) \n",
      "\n",
      "Model# 7. 5207 nodes still misclassified out of torch.Size([13381]) \n",
      "\n",
      "Model# 8. 5207 nodes still misclassified out of torch.Size([13381]) \n",
      "\n",
      "Model# 9. 5207 nodes still misclassified out of torch.Size([13381]) \n",
      "\n",
      "Model# 10. 5207 nodes still misclassified out of torch.Size([13381]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 89/299 [00:52<02:13,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 5207 nodes still misclassified out of torch.Size([13381]) \n",
      "\n",
      "Model# 12. 5207 nodes still misclassified out of torch.Size([13381]) \n",
      "\n",
      "Model# 13. 5207 nodes still misclassified out of torch.Size([13381]) \n",
      "\n",
      "Model# 14. 5207 nodes still misclassified out of torch.Size([13381]) \n",
      "\n",
      "Model# 15. 5207 nodes still misclassified out of torch.Size([13381]) \n",
      "\n",
      "Model# 16. 5207 nodes still misclassified out of torch.Size([13381]) \n",
      "\n",
      "Model# 17. 5207 nodes still misclassified out of torch.Size([13381]) \n",
      "\n",
      "Model# 18. 5207 nodes still misclassified out of torch.Size([13381]) \n",
      "\n",
      "Model# 19. 5207 nodes still misclassified out of torch.Size([13381]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12911/12911 [00:00<00:00, 2684945.16it/s]\n",
      "100%|██████████| 12911/12911 [00:00<00:00, 2958838.32it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2015491.02it/s]\n",
      "Inferring Phrases: 100%|██████████| 12911/12911 [00:00<00:00, 379424.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4155 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 1. 4155 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 2. 4155 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 3. 4155 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 4. 4155 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 5. 4155 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 6. 4155 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 7. 4155 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 8. 4155 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 9. 4155 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 10. 4155 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 11. 4155 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 12. 4155 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 13. 4155 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 14. 4155 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 15. 4155 nodes still misclassified out of torch.Size([12911]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 90/299 [00:52<02:05,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 16. 4155 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 17. 4155 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 18. 4155 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 19. 4155 nodes still misclassified out of torch.Size([12911]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12983/12983 [00:00<00:00, 4691939.41it/s]\n",
      "100%|██████████| 12983/12983 [00:00<00:00, 5378236.92it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2874779.99it/s]\n",
      "Inferring Phrases: 100%|██████████| 12983/12983 [00:00<00:00, 443571.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4890 nodes still misclassified out of torch.Size([12983]) \n",
      "\n",
      "Model# 1. 4890 nodes still misclassified out of torch.Size([12983]) \n",
      "\n",
      "Model# 2. 4890 nodes still misclassified out of torch.Size([12983]) \n",
      "\n",
      "Model# 3. 4890 nodes still misclassified out of torch.Size([12983]) \n",
      "\n",
      "Model# 4. 4890 nodes still misclassified out of torch.Size([12983]) \n",
      "\n",
      "Model# 5. 4890 nodes still misclassified out of torch.Size([12983]) \n",
      "\n",
      "Model# 6. 4890 nodes still misclassified out of torch.Size([12983]) \n",
      "\n",
      "Model# 7. 4890 nodes still misclassified out of torch.Size([12983]) \n",
      "\n",
      "Model# 8. 4890 nodes still misclassified out of torch.Size([12983]) \n",
      "\n",
      "Model# 9. 4890 nodes still misclassified out of torch.Size([12983]) \n",
      "\n",
      "Model# 10. 4890 nodes still misclassified out of torch.Size([12983]) \n",
      "\n",
      "Model# 11. 4890 nodes still misclassified out of torch.Size([12983]) \n",
      "\n",
      "Model# 12. 4890 nodes still misclassified out of torch.Size([12983]) \n",
      "\n",
      "Model# 13. 4890 nodes still misclassified out of torch.Size([12983]) \n",
      "\n",
      "Model# 14. 4890 nodes still misclassified out of torch.Size([12983]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 91/299 [00:53<02:07,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4890 nodes still misclassified out of torch.Size([12983]) \n",
      "\n",
      "Model# 16. 4890 nodes still misclassified out of torch.Size([12983]) \n",
      "\n",
      "Model# 17. 4890 nodes still misclassified out of torch.Size([12983]) \n",
      "\n",
      "Model# 18. 4890 nodes still misclassified out of torch.Size([12983]) \n",
      "\n",
      "Model# 19. 4890 nodes still misclassified out of torch.Size([12983]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12700/12700 [00:00<00:00, 2651451.51it/s]\n",
      "100%|██████████| 12700/12700 [00:00<00:00, 2932433.85it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1977357.11it/s]\n",
      "Inferring Phrases: 100%|██████████| 12700/12700 [00:00<00:00, 347097.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4678 nodes still misclassified out of torch.Size([12700]) \n",
      "\n",
      "Model# 1. 4678 nodes still misclassified out of torch.Size([12700]) \n",
      "\n",
      "Model# 2. 4678 nodes still misclassified out of torch.Size([12700]) \n",
      "\n",
      "Model# 3. 4678 nodes still misclassified out of torch.Size([12700]) \n",
      "\n",
      "Model# 4. 4678 nodes still misclassified out of torch.Size([12700]) \n",
      "\n",
      "Model# 5. 4678 nodes still misclassified out of torch.Size([12700]) \n",
      "\n",
      "Model# 6. 4678 nodes still misclassified out of torch.Size([12700]) \n",
      "\n",
      "Model# 7. 4678 nodes still misclassified out of torch.Size([12700]) \n",
      "\n",
      "Model# 8. 4678 nodes still misclassified out of torch.Size([12700]) \n",
      "\n",
      "Model# 9. 4678 nodes still misclassified out of torch.Size([12700]) \n",
      "\n",
      "Model# 10. 4678 nodes still misclassified out of torch.Size([12700]) \n",
      "\n",
      "Model# 11. 4678 nodes still misclassified out of torch.Size([12700]) \n",
      "\n",
      "Model# 12. 4678 nodes still misclassified out of torch.Size([12700]) \n",
      "\n",
      "Model# 13. 4678 nodes still misclassified out of torch.Size([12700]) \n",
      "\n",
      "Model# 14. 4678 nodes still misclassified out of torch.Size([12700]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 92/299 [00:53<02:01,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4678 nodes still misclassified out of torch.Size([12700]) \n",
      "\n",
      "Model# 16. 4678 nodes still misclassified out of torch.Size([12700]) \n",
      "\n",
      "Model# 17. 4678 nodes still misclassified out of torch.Size([12700]) \n",
      "\n",
      "Model# 18. 4678 nodes still misclassified out of torch.Size([12700]) \n",
      "\n",
      "Model# 19. 4678 nodes still misclassified out of torch.Size([12700]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13186/13186 [00:00<00:00, 4052322.14it/s]\n",
      "100%|██████████| 13186/13186 [00:00<00:00, 4932758.88it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2699732.23it/s]\n",
      "Inferring Phrases: 100%|██████████| 13186/13186 [00:00<00:00, 440921.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5046 nodes still misclassified out of torch.Size([13186]) \n",
      "\n",
      "Model# 1. 5046 nodes still misclassified out of torch.Size([13186]) \n",
      "\n",
      "Model# 2. 5046 nodes still misclassified out of torch.Size([13186]) \n",
      "\n",
      "Model# 3. 5046 nodes still misclassified out of torch.Size([13186]) \n",
      "\n",
      "Model# 4. 5046 nodes still misclassified out of torch.Size([13186]) \n",
      "\n",
      "Model# 5. 5046 nodes still misclassified out of torch.Size([13186]) \n",
      "\n",
      "Model# 6. 5046 nodes still misclassified out of torch.Size([13186]) \n",
      "\n",
      "Model# 7. 5046 nodes still misclassified out of torch.Size([13186]) \n",
      "\n",
      "Model# 8. 5046 nodes still misclassified out of torch.Size([13186]) \n",
      "\n",
      "Model# 9. 5046 nodes still misclassified out of torch.Size([13186]) \n",
      "\n",
      "Model# 10. 5046 nodes still misclassified out of torch.Size([13186]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 93/299 [00:54<02:13,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 5046 nodes still misclassified out of torch.Size([13186]) \n",
      "\n",
      "Model# 12. 5046 nodes still misclassified out of torch.Size([13186]) \n",
      "\n",
      "Model# 13. 5046 nodes still misclassified out of torch.Size([13186]) \n",
      "\n",
      "Model# 14. 5046 nodes still misclassified out of torch.Size([13186]) \n",
      "\n",
      "Model# 15. 5046 nodes still misclassified out of torch.Size([13186]) \n",
      "\n",
      "Model# 16. 5046 nodes still misclassified out of torch.Size([13186]) \n",
      "\n",
      "Model# 17. 5046 nodes still misclassified out of torch.Size([13186]) \n",
      "\n",
      "Model# 18. 5046 nodes still misclassified out of torch.Size([13186]) \n",
      "\n",
      "Model# 19. 5046 nodes still misclassified out of torch.Size([13186]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12876/12876 [00:00<00:00, 2755822.74it/s]\n",
      "100%|██████████| 12876/12876 [00:00<00:00, 3056877.70it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1995355.61it/s]\n",
      "Inferring Phrases: 100%|██████████| 12876/12876 [00:00<00:00, 366392.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4927 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 1. 4927 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 2. 4927 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 3. 4927 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 4. 4927 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 5. 4927 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 6. 4927 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 7. 4927 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 8. 4927 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 9. 4927 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 10. 4927 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 11. 4927 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 12. 4927 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 13. 4927 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 14. 4927 nodes still misclassified out of torch.Size([12876]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 94/299 [00:55<02:05,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4927 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 16. 4927 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 17. 4927 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 18. 4927 nodes still misclassified out of torch.Size([12876]) \n",
      "\n",
      "Model# 19. 4927 nodes still misclassified out of torch.Size([12876]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14647/14647 [00:00<00:00, 2682823.30it/s]\n",
      "100%|██████████| 14647/14647 [00:00<00:00, 3005869.98it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1982341.39it/s]\n",
      "Inferring Phrases: 100%|██████████| 14647/14647 [00:00<00:00, 415316.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6401 nodes still misclassified out of torch.Size([14647]) \n",
      "\n",
      "Model# 1. 6401 nodes still misclassified out of torch.Size([14647]) \n",
      "\n",
      "Model# 2. 6401 nodes still misclassified out of torch.Size([14647]) \n",
      "\n",
      "Model# 3. 6401 nodes still misclassified out of torch.Size([14647]) \n",
      "\n",
      "Model# 4. 6401 nodes still misclassified out of torch.Size([14647]) \n",
      "\n",
      "Model# 5. 6401 nodes still misclassified out of torch.Size([14647]) \n",
      "\n",
      "Model# 6. 6401 nodes still misclassified out of torch.Size([14647]) \n",
      "\n",
      "Model# 7. 6401 nodes still misclassified out of torch.Size([14647]) \n",
      "\n",
      "Model# 8. 6401 nodes still misclassified out of torch.Size([14647]) \n",
      "\n",
      "Model# 9. 6401 nodes still misclassified out of torch.Size([14647]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 95/299 [00:55<02:07,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 6401 nodes still misclassified out of torch.Size([14647]) \n",
      "\n",
      "Model# 11. 6401 nodes still misclassified out of torch.Size([14647]) \n",
      "\n",
      "Model# 12. 6401 nodes still misclassified out of torch.Size([14647]) \n",
      "\n",
      "Model# 13. 6401 nodes still misclassified out of torch.Size([14647]) \n",
      "\n",
      "Model# 14. 6401 nodes still misclassified out of torch.Size([14647]) \n",
      "\n",
      "Model# 15. 6401 nodes still misclassified out of torch.Size([14647]) \n",
      "\n",
      "Model# 16. 6401 nodes still misclassified out of torch.Size([14647]) \n",
      "\n",
      "Model# 17. 6401 nodes still misclassified out of torch.Size([14647]) \n",
      "\n",
      "Model# 18. 6401 nodes still misclassified out of torch.Size([14647]) \n",
      "\n",
      "Model# 19. 6401 nodes still misclassified out of torch.Size([14647]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14843/14843 [00:00<00:00, 4372835.17it/s]\n",
      "100%|██████████| 14843/14843 [00:00<00:00, 5350296.86it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2997715.78it/s]\n",
      "Inferring Phrases: 100%|██████████| 14843/14843 [00:00<00:00, 463898.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6569 nodes still misclassified out of torch.Size([14843]) \n",
      "\n",
      "Model# 1. 6569 nodes still misclassified out of torch.Size([14843]) \n",
      "\n",
      "Model# 2. 6569 nodes still misclassified out of torch.Size([14843]) \n",
      "\n",
      "Model# 3. 6569 nodes still misclassified out of torch.Size([14843]) \n",
      "\n",
      "Model# 4. 6569 nodes still misclassified out of torch.Size([14843]) \n",
      "\n",
      "Model# 5. 6569 nodes still misclassified out of torch.Size([14843]) \n",
      "\n",
      "Model# 6. 6569 nodes still misclassified out of torch.Size([14843]) \n",
      "\n",
      "Model# 7. 6569 nodes still misclassified out of torch.Size([14843]) \n",
      "\n",
      "Model# 8. 6569 nodes still misclassified out of torch.Size([14843]) \n",
      "\n",
      "Model# 9. 6569 nodes still misclassified out of torch.Size([14843]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 96/299 [00:56<02:17,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 6569 nodes still misclassified out of torch.Size([14843]) \n",
      "\n",
      "Model# 11. 6569 nodes still misclassified out of torch.Size([14843]) \n",
      "\n",
      "Model# 12. 6569 nodes still misclassified out of torch.Size([14843]) \n",
      "\n",
      "Model# 13. 6569 nodes still misclassified out of torch.Size([14843]) \n",
      "\n",
      "Model# 14. 6569 nodes still misclassified out of torch.Size([14843]) \n",
      "\n",
      "Model# 15. 6569 nodes still misclassified out of torch.Size([14843]) \n",
      "\n",
      "Model# 16. 6569 nodes still misclassified out of torch.Size([14843]) \n",
      "\n",
      "Model# 17. 6569 nodes still misclassified out of torch.Size([14843]) \n",
      "\n",
      "Model# 18. 6569 nodes still misclassified out of torch.Size([14843]) \n",
      "\n",
      "Model# 19. 6569 nodes still misclassified out of torch.Size([14843]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13829/13829 [00:00<00:00, 2690307.51it/s]\n",
      "100%|██████████| 13829/13829 [00:00<00:00, 3019418.53it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1941028.60it/s]\n",
      "Inferring Phrases: 100%|██████████| 13829/13829 [00:00<00:00, 436162.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5494 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 1. 5494 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 2. 5494 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 3. 5494 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 4. 5494 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 5. 5494 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 6. 5494 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 7. 5494 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 8. 5494 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 9. 5494 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 10. 5494 nodes still misclassified out of torch.Size([13829]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 97/299 [00:57<02:15,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 5494 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 12. 5494 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 13. 5494 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 14. 5494 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 15. 5494 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 16. 5494 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 17. 5494 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 18. 5494 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 19. 5494 nodes still misclassified out of torch.Size([13829]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12710/12710 [00:00<00:00, 2682919.17it/s]\n",
      "100%|██████████| 12710/12710 [00:00<00:00, 2983356.87it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1951534.97it/s]\n",
      "Inferring Phrases: 100%|██████████| 12710/12710 [00:00<00:00, 375459.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4635 nodes still misclassified out of torch.Size([12710]) \n",
      "\n",
      "Model# 1. 4635 nodes still misclassified out of torch.Size([12710]) \n",
      "\n",
      "Model# 2. 4635 nodes still misclassified out of torch.Size([12710]) \n",
      "\n",
      "Model# 3. 4635 nodes still misclassified out of torch.Size([12710]) \n",
      "\n",
      "Model# 4. 4635 nodes still misclassified out of torch.Size([12710]) \n",
      "\n",
      "Model# 5. 4635 nodes still misclassified out of torch.Size([12710]) \n",
      "\n",
      "Model# 6. 4635 nodes still misclassified out of torch.Size([12710]) \n",
      "\n",
      "Model# 7. 4635 nodes still misclassified out of torch.Size([12710]) \n",
      "\n",
      "Model# 8. 4635 nodes still misclassified out of torch.Size([12710]) \n",
      "\n",
      "Model# 9. 4635 nodes still misclassified out of torch.Size([12710]) \n",
      "\n",
      "Model# 10. 4635 nodes still misclassified out of torch.Size([12710]) \n",
      "\n",
      "Model# 11. 4635 nodes still misclassified out of torch.Size([12710]) \n",
      "\n",
      "Model# 12. 4635 nodes still misclassified out of torch.Size([12710]) \n",
      "\n",
      "Model# 13. 4635 nodes still misclassified out of torch.Size([12710]) \n",
      "\n",
      "Model# 14. 4635 nodes still misclassified out of torch.Size([12710]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 98/299 [00:57<02:06,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4635 nodes still misclassified out of torch.Size([12710]) \n",
      "\n",
      "Model# 16. 4635 nodes still misclassified out of torch.Size([12710]) \n",
      "\n",
      "Model# 17. 4635 nodes still misclassified out of torch.Size([12710]) \n",
      "\n",
      "Model# 18. 4635 nodes still misclassified out of torch.Size([12710]) \n",
      "\n",
      "Model# 19. 4635 nodes still misclassified out of torch.Size([12710]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12759/12759 [00:00<00:00, 4427860.73it/s]\n",
      "100%|██████████| 12759/12759 [00:00<00:00, 5267236.69it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2884731.88it/s]\n",
      "Inferring Phrases: 100%|██████████| 12759/12759 [00:00<00:00, 401940.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4740 nodes still misclassified out of torch.Size([12759]) \n",
      "\n",
      "Model# 1. 4740 nodes still misclassified out of torch.Size([12759]) \n",
      "\n",
      "Model# 2. 4740 nodes still misclassified out of torch.Size([12759]) \n",
      "\n",
      "Model# 3. 4740 nodes still misclassified out of torch.Size([12759]) \n",
      "\n",
      "Model# 4. 4740 nodes still misclassified out of torch.Size([12759]) \n",
      "\n",
      "Model# 5. 4740 nodes still misclassified out of torch.Size([12759]) \n",
      "\n",
      "Model# 6. 4740 nodes still misclassified out of torch.Size([12759]) \n",
      "\n",
      "Model# 7. 4740 nodes still misclassified out of torch.Size([12759]) \n",
      "\n",
      "Model# 8. 4740 nodes still misclassified out of torch.Size([12759]) \n",
      "\n",
      "Model# 9. 4740 nodes still misclassified out of torch.Size([12759]) \n",
      "\n",
      "Model# 10. 4740 nodes still misclassified out of torch.Size([12759]) \n",
      "\n",
      "Model# 11. 4740 nodes still misclassified out of torch.Size([12759]) \n",
      "\n",
      "Model# 12. 4740 nodes still misclassified out of torch.Size([12759]) \n",
      "\n",
      "Model# 13. 4740 nodes still misclassified out of torch.Size([12759]) \n",
      "\n",
      "Model# 14. 4740 nodes still misclassified out of torch.Size([12759]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 99/299 [00:58<02:08,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4740 nodes still misclassified out of torch.Size([12759]) \n",
      "\n",
      "Model# 16. 4740 nodes still misclassified out of torch.Size([12759]) \n",
      "\n",
      "Model# 17. 4740 nodes still misclassified out of torch.Size([12759]) \n",
      "\n",
      "Model# 18. 4740 nodes still misclassified out of torch.Size([12759]) \n",
      "\n",
      "Model# 19. 4740 nodes still misclassified out of torch.Size([12759]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13829/13829 [00:00<00:00, 2689808.48it/s]\n",
      "100%|██████████| 13829/13829 [00:00<00:00, 2989230.57it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2017332.86it/s]\n",
      "Inferring Phrases: 100%|██████████| 13829/13829 [00:00<00:00, 397381.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5773 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 1. 5773 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 2. 5773 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 3. 5773 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 4. 5773 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 5. 5773 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 6. 5773 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 7. 5773 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 8. 5773 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 9. 5773 nodes still misclassified out of torch.Size([13829]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 100/299 [00:58<02:08,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 5773 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 11. 5773 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 12. 5773 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 13. 5773 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 14. 5773 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 15. 5773 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 16. 5773 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 17. 5773 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 18. 5773 nodes still misclassified out of torch.Size([13829]) \n",
      "\n",
      "Model# 19. 5773 nodes still misclassified out of torch.Size([13829]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13687/13687 [00:00<00:00, 3945799.63it/s]\n",
      "100%|██████████| 13687/13687 [00:00<00:00, 4936151.23it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2715697.33it/s]\n",
      "Inferring Phrases: 100%|██████████| 13687/13687 [00:00<00:00, 456658.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5000 nodes still misclassified out of torch.Size([13687]) \n",
      "\n",
      "Model# 1. 5000 nodes still misclassified out of torch.Size([13687]) \n",
      "\n",
      "Model# 2. 5000 nodes still misclassified out of torch.Size([13687]) \n",
      "\n",
      "Model# 3. 5000 nodes still misclassified out of torch.Size([13687]) \n",
      "\n",
      "Model# 4. 5000 nodes still misclassified out of torch.Size([13687]) \n",
      "\n",
      "Model# 5. 5000 nodes still misclassified out of torch.Size([13687]) \n",
      "\n",
      "Model# 6. 5000 nodes still misclassified out of torch.Size([13687]) \n",
      "\n",
      "Model# 7. 5000 nodes still misclassified out of torch.Size([13687]) \n",
      "\n",
      "Model# 8. 5000 nodes still misclassified out of torch.Size([13687]) \n",
      "\n",
      "Model# 9. 5000 nodes still misclassified out of torch.Size([13687]) \n",
      "\n",
      "Model# 10. 5000 nodes still misclassified out of torch.Size([13687]) \n",
      "\n",
      "Model# 11. 5000 nodes still misclassified out of torch.Size([13687]) \n",
      "\n",
      "Model# 12. 5000 nodes still misclassified out of torch.Size([13687]) \n",
      "\n",
      "Model# 13. 5000 nodes still misclassified out of torch.Size([13687]) \n",
      "\n",
      "Model# 14. 5000 nodes still misclassified out of torch.Size([13687]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 101/299 [00:59<02:11,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 5000 nodes still misclassified out of torch.Size([13687]) \n",
      "\n",
      "Model# 16. 5000 nodes still misclassified out of torch.Size([13687]) \n",
      "\n",
      "Model# 17. 5000 nodes still misclassified out of torch.Size([13687]) \n",
      "\n",
      "Model# 18. 5000 nodes still misclassified out of torch.Size([13687]) \n",
      "\n",
      "Model# 19. 5000 nodes still misclassified out of torch.Size([13687]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13607/13607 [00:00<00:00, 2464244.15it/s]\n",
      "100%|██████████| 13607/13607 [00:00<00:00, 2893965.55it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1904741.38it/s]\n",
      "Inferring Phrases: 100%|██████████| 13607/13607 [00:00<00:00, 388839.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5687 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 1. 5687 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 2. 5687 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 3. 5687 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 4. 5687 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 5. 5687 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 6. 5687 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 7. 5687 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 8. 5687 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 9. 5687 nodes still misclassified out of torch.Size([13607]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 102/299 [01:00<02:10,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 5687 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 11. 5687 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 12. 5687 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 13. 5687 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 14. 5687 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 15. 5687 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 16. 5687 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 17. 5687 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 18. 5687 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 19. 5687 nodes still misclassified out of torch.Size([13607]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14518/14518 [00:00<00:00, 2522385.38it/s]\n",
      "100%|██████████| 14518/14518 [00:00<00:00, 2950380.61it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1924875.63it/s]\n",
      "Inferring Phrases: 100%|██████████| 14518/14518 [00:00<00:00, 429285.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6405 nodes still misclassified out of torch.Size([14518]) \n",
      "\n",
      "Model# 1. 6405 nodes still misclassified out of torch.Size([14518]) \n",
      "\n",
      "Model# 2. 6405 nodes still misclassified out of torch.Size([14518]) \n",
      "\n",
      "Model# 3. 6405 nodes still misclassified out of torch.Size([14518]) \n",
      "\n",
      "Model# 4. 6405 nodes still misclassified out of torch.Size([14518]) \n",
      "\n",
      "Model# 5. 6405 nodes still misclassified out of torch.Size([14518]) \n",
      "\n",
      "Model# 6. 6405 nodes still misclassified out of torch.Size([14518]) \n",
      "\n",
      "Model# 7. 6405 nodes still misclassified out of torch.Size([14518]) \n",
      "\n",
      "Model# 8. 6405 nodes still misclassified out of torch.Size([14518]) \n",
      "\n",
      "Model# 9. 6405 nodes still misclassified out of torch.Size([14518]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 103/299 [01:01<02:09,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 6405 nodes still misclassified out of torch.Size([14518]) \n",
      "\n",
      "Model# 11. 6405 nodes still misclassified out of torch.Size([14518]) \n",
      "\n",
      "Model# 12. 6405 nodes still misclassified out of torch.Size([14518]) \n",
      "\n",
      "Model# 13. 6405 nodes still misclassified out of torch.Size([14518]) \n",
      "\n",
      "Model# 14. 6405 nodes still misclassified out of torch.Size([14518]) \n",
      "\n",
      "Model# 15. 6405 nodes still misclassified out of torch.Size([14518]) \n",
      "\n",
      "Model# 16. 6405 nodes still misclassified out of torch.Size([14518]) \n",
      "\n",
      "Model# 17. 6405 nodes still misclassified out of torch.Size([14518]) \n",
      "\n",
      "Model# 18. 6405 nodes still misclassified out of torch.Size([14518]) \n",
      "\n",
      "Model# 19. 6405 nodes still misclassified out of torch.Size([14518]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13484/13484 [00:00<00:00, 4567597.73it/s]\n",
      "100%|██████████| 13484/13484 [00:00<00:00, 5363808.34it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2930006.29it/s]\n",
      "Inferring Phrases: 100%|██████████| 13484/13484 [00:00<00:00, 444273.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5456 nodes still misclassified out of torch.Size([13484]) \n",
      "\n",
      "Model# 1. 5456 nodes still misclassified out of torch.Size([13484]) \n",
      "\n",
      "Model# 2. 5456 nodes still misclassified out of torch.Size([13484]) \n",
      "\n",
      "Model# 3. 5456 nodes still misclassified out of torch.Size([13484]) \n",
      "\n",
      "Model# 4. 5456 nodes still misclassified out of torch.Size([13484]) \n",
      "\n",
      "Model# 5. 5456 nodes still misclassified out of torch.Size([13484]) \n",
      "\n",
      "Model# 6. 5456 nodes still misclassified out of torch.Size([13484]) \n",
      "\n",
      "Model# 7. 5456 nodes still misclassified out of torch.Size([13484]) \n",
      "\n",
      "Model# 8. 5456 nodes still misclassified out of torch.Size([13484]) \n",
      "\n",
      "Model# 9. 5456 nodes still misclassified out of torch.Size([13484]) \n",
      "\n",
      "Model# 10. 5456 nodes still misclassified out of torch.Size([13484]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 104/299 [01:01<02:15,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 5456 nodes still misclassified out of torch.Size([13484]) \n",
      "\n",
      "Model# 12. 5456 nodes still misclassified out of torch.Size([13484]) \n",
      "\n",
      "Model# 13. 5456 nodes still misclassified out of torch.Size([13484]) \n",
      "\n",
      "Model# 14. 5456 nodes still misclassified out of torch.Size([13484]) \n",
      "\n",
      "Model# 15. 5456 nodes still misclassified out of torch.Size([13484]) \n",
      "\n",
      "Model# 16. 5456 nodes still misclassified out of torch.Size([13484]) \n",
      "\n",
      "Model# 17. 5456 nodes still misclassified out of torch.Size([13484]) \n",
      "\n",
      "Model# 18. 5456 nodes still misclassified out of torch.Size([13484]) \n",
      "\n",
      "Model# 19. 5456 nodes still misclassified out of torch.Size([13484]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12785/12785 [00:00<00:00, 3981303.49it/s]\n",
      "100%|██████████| 12785/12785 [00:00<00:00, 4612038.93it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2756025.93it/s]\n",
      "Inferring Phrases: 100%|██████████| 12785/12785 [00:00<00:00, 382393.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4953 nodes still misclassified out of torch.Size([12785]) \n",
      "\n",
      "Model# 1. 4953 nodes still misclassified out of torch.Size([12785]) \n",
      "\n",
      "Model# 2. 4953 nodes still misclassified out of torch.Size([12785]) \n",
      "\n",
      "Model# 3. 4953 nodes still misclassified out of torch.Size([12785]) \n",
      "\n",
      "Model# 4. 4953 nodes still misclassified out of torch.Size([12785]) \n",
      "\n",
      "Model# 5. 4953 nodes still misclassified out of torch.Size([12785]) \n",
      "\n",
      "Model# 6. 4953 nodes still misclassified out of torch.Size([12785]) \n",
      "\n",
      "Model# 7. 4953 nodes still misclassified out of torch.Size([12785]) \n",
      "\n",
      "Model# 8. 4953 nodes still misclassified out of torch.Size([12785]) \n",
      "\n",
      "Model# 9. 4953 nodes still misclassified out of torch.Size([12785]) \n",
      "\n",
      "Model# 10. 4953 nodes still misclassified out of torch.Size([12785]) \n",
      "\n",
      "Model# 11. 4953 nodes still misclassified out of torch.Size([12785]) \n",
      "\n",
      "Model# 12. 4953 nodes still misclassified out of torch.Size([12785]) \n",
      "\n",
      "Model# 13. 4953 nodes still misclassified out of torch.Size([12785]) \n",
      "\n",
      "Model# 14. 4953 nodes still misclassified out of torch.Size([12785]) \n",
      "\n",
      "Model# 15. 4953 nodes still misclassified out of torch.Size([12785]) \n",
      "\n",
      "Model# 16. 4953 nodes still misclassified out of torch.Size([12785]) \n",
      "\n",
      "Model# 17. 4953 nodes still misclassified out of torch.Size([12785]) \n",
      "\n",
      "Model# 18. 4953 nodes still misclassified out of torch.Size([12785]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 105/299 [01:02<01:57,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4953 nodes still misclassified out of torch.Size([12785]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13344/13344 [00:00<00:00, 3678769.07it/s]\n",
      "100%|██████████| 13344/13344 [00:00<00:00, 4440910.31it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2635495.98it/s]\n",
      "Inferring Phrases: 100%|██████████| 13344/13344 [00:00<00:00, 249334.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5221 nodes still misclassified out of torch.Size([13344]) \n",
      "\n",
      "Model# 1. 5221 nodes still misclassified out of torch.Size([13344]) \n",
      "\n",
      "Model# 2. 5221 nodes still misclassified out of torch.Size([13344]) \n",
      "\n",
      "Model# 3. 5221 nodes still misclassified out of torch.Size([13344]) \n",
      "\n",
      "Model# 4. 5221 nodes still misclassified out of torch.Size([13344]) \n",
      "\n",
      "Model# 5. 5221 nodes still misclassified out of torch.Size([13344]) \n",
      "\n",
      "Model# 6. 5221 nodes still misclassified out of torch.Size([13344]) \n",
      "\n",
      "Model# 7. 5221 nodes still misclassified out of torch.Size([13344]) \n",
      "\n",
      "Model# 8. 5221 nodes still misclassified out of torch.Size([13344]) \n",
      "\n",
      "Model# 9. 5221 nodes still misclassified out of torch.Size([13344]) \n",
      "\n",
      "Model# 10. 5221 nodes still misclassified out of torch.Size([13344]) \n",
      "\n",
      "Model# 11. 5221 nodes still misclassified out of torch.Size([13344]) \n",
      "\n",
      "Model# 12. 5221 nodes still misclassified out of torch.Size([13344]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 106/299 [01:02<01:53,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 13. 5221 nodes still misclassified out of torch.Size([13344]) \n",
      "\n",
      "Model# 14. 5221 nodes still misclassified out of torch.Size([13344]) \n",
      "\n",
      "Model# 15. 5221 nodes still misclassified out of torch.Size([13344]) \n",
      "\n",
      "Model# 16. 5221 nodes still misclassified out of torch.Size([13344]) \n",
      "\n",
      "Model# 17. 5221 nodes still misclassified out of torch.Size([13344]) \n",
      "\n",
      "Model# 18. 5221 nodes still misclassified out of torch.Size([13344]) \n",
      "\n",
      "Model# 19. 5221 nodes still misclassified out of torch.Size([13344]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13948/13948 [00:00<00:00, 4482923.54it/s]\n",
      "100%|██████████| 13948/13948 [00:00<00:00, 5163473.27it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2906387.03it/s]\n",
      "Inferring Phrases: 100%|██████████| 13948/13948 [00:00<00:00, 445516.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5040 nodes still misclassified out of torch.Size([13948]) \n",
      "\n",
      "Model# 1. 5040 nodes still misclassified out of torch.Size([13948]) \n",
      "\n",
      "Model# 2. 5040 nodes still misclassified out of torch.Size([13948]) \n",
      "\n",
      "Model# 3. 5040 nodes still misclassified out of torch.Size([13948]) \n",
      "\n",
      "Model# 4. 5040 nodes still misclassified out of torch.Size([13948]) \n",
      "\n",
      "Model# 5. 5040 nodes still misclassified out of torch.Size([13948]) \n",
      "\n",
      "Model# 6. 5040 nodes still misclassified out of torch.Size([13948]) \n",
      "\n",
      "Model# 7. 5040 nodes still misclassified out of torch.Size([13948]) \n",
      "\n",
      "Model# 8. 5040 nodes still misclassified out of torch.Size([13948]) \n",
      "\n",
      "Model# 9. 5040 nodes still misclassified out of torch.Size([13948]) \n",
      "\n",
      "Model# 10. 5040 nodes still misclassified out of torch.Size([13948]) \n",
      "\n",
      "Model# 11. 5040 nodes still misclassified out of torch.Size([13948]) \n",
      "\n",
      "Model# 12. 5040 nodes still misclassified out of torch.Size([13948]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 107/299 [01:03<01:56,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 13. 5040 nodes still misclassified out of torch.Size([13948]) \n",
      "\n",
      "Model# 14. 5040 nodes still misclassified out of torch.Size([13948]) \n",
      "\n",
      "Model# 15. 5040 nodes still misclassified out of torch.Size([13948]) \n",
      "\n",
      "Model# 16. 5040 nodes still misclassified out of torch.Size([13948]) \n",
      "\n",
      "Model# 17. 5040 nodes still misclassified out of torch.Size([13948]) \n",
      "\n",
      "Model# 18. 5040 nodes still misclassified out of torch.Size([13948]) \n",
      "\n",
      "Model# 19. 5040 nodes still misclassified out of torch.Size([13948]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12653/12653 [00:00<00:00, 2756480.99it/s]\n",
      "100%|██████████| 12653/12653 [00:00<00:00, 3038678.99it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2006748.00it/s]\n",
      "Inferring Phrases: 100%|██████████| 12653/12653 [00:00<00:00, 376661.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4679 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 1. 4679 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 2. 4679 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 3. 4679 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 4. 4679 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 5. 4679 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 6. 4679 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 7. 4679 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 8. 4679 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 9. 4679 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 10. 4679 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 11. 4679 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 12. 4679 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 13. 4679 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 14. 4679 nodes still misclassified out of torch.Size([12653]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 108/299 [01:03<01:51,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4679 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 16. 4679 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 17. 4679 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 18. 4679 nodes still misclassified out of torch.Size([12653]) \n",
      "\n",
      "Model# 19. 4679 nodes still misclassified out of torch.Size([12653]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12611/12611 [00:00<00:00, 4019328.86it/s]\n",
      "100%|██████████| 12611/12611 [00:00<00:00, 5191320.81it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2810253.94it/s]\n",
      "Inferring Phrases: 100%|██████████| 12611/12611 [00:00<00:00, 424428.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4334 nodes still misclassified out of torch.Size([12611]) \n",
      "\n",
      "Model# 1. 4334 nodes still misclassified out of torch.Size([12611]) \n",
      "\n",
      "Model# 2. 4334 nodes still misclassified out of torch.Size([12611]) \n",
      "\n",
      "Model# 3. 4334 nodes still misclassified out of torch.Size([12611]) \n",
      "\n",
      "Model# 4. 4334 nodes still misclassified out of torch.Size([12611]) \n",
      "\n",
      "Model# 5. 4334 nodes still misclassified out of torch.Size([12611]) \n",
      "\n",
      "Model# 6. 4334 nodes still misclassified out of torch.Size([12611]) \n",
      "\n",
      "Model# 7. 4334 nodes still misclassified out of torch.Size([12611]) \n",
      "\n",
      "Model# 8. 4334 nodes still misclassified out of torch.Size([12611]) \n",
      "\n",
      "Model# 9. 4334 nodes still misclassified out of torch.Size([12611]) \n",
      "\n",
      "Model# 10. 4334 nodes still misclassified out of torch.Size([12611]) \n",
      "\n",
      "Model# 11. 4334 nodes still misclassified out of torch.Size([12611]) \n",
      "\n",
      "Model# 12. 4334 nodes still misclassified out of torch.Size([12611]) \n",
      "\n",
      "Model# 13. 4334 nodes still misclassified out of torch.Size([12611]) \n",
      "\n",
      "Model# 14. 4334 nodes still misclassified out of torch.Size([12611]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 109/299 [01:04<01:55,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4334 nodes still misclassified out of torch.Size([12611]) \n",
      "\n",
      "Model# 16. 4334 nodes still misclassified out of torch.Size([12611]) \n",
      "\n",
      "Model# 17. 4334 nodes still misclassified out of torch.Size([12611]) \n",
      "\n",
      "Model# 18. 4334 nodes still misclassified out of torch.Size([12611]) \n",
      "\n",
      "Model# 19. 4334 nodes still misclassified out of torch.Size([12611]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12410/12410 [00:00<00:00, 2708748.58it/s]\n",
      "100%|██████████| 12410/12410 [00:00<00:00, 3040735.64it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1989298.85it/s]\n",
      "Inferring Phrases: 100%|██████████| 12410/12410 [00:00<00:00, 361296.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4432 nodes still misclassified out of torch.Size([12410]) \n",
      "\n",
      "Model# 1. 4432 nodes still misclassified out of torch.Size([12410]) \n",
      "\n",
      "Model# 2. 4432 nodes still misclassified out of torch.Size([12410]) \n",
      "\n",
      "Model# 3. 4432 nodes still misclassified out of torch.Size([12410]) \n",
      "\n",
      "Model# 4. 4432 nodes still misclassified out of torch.Size([12410]) \n",
      "\n",
      "Model# 5. 4432 nodes still misclassified out of torch.Size([12410]) \n",
      "\n",
      "Model# 6. 4432 nodes still misclassified out of torch.Size([12410]) \n",
      "\n",
      "Model# 7. 4432 nodes still misclassified out of torch.Size([12410]) \n",
      "\n",
      "Model# 8. 4432 nodes still misclassified out of torch.Size([12410]) \n",
      "\n",
      "Model# 9. 4432 nodes still misclassified out of torch.Size([12410]) \n",
      "\n",
      "Model# 10. 4432 nodes still misclassified out of torch.Size([12410]) \n",
      "\n",
      "Model# 11. 4432 nodes still misclassified out of torch.Size([12410]) \n",
      "\n",
      "Model# 12. 4432 nodes still misclassified out of torch.Size([12410]) \n",
      "\n",
      "Model# 13. 4432 nodes still misclassified out of torch.Size([12410]) \n",
      "\n",
      "Model# 14. 4432 nodes still misclassified out of torch.Size([12410]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 110/299 [01:05<01:50,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4432 nodes still misclassified out of torch.Size([12410]) \n",
      "\n",
      "Model# 16. 4432 nodes still misclassified out of torch.Size([12410]) \n",
      "\n",
      "Model# 17. 4432 nodes still misclassified out of torch.Size([12410]) \n",
      "\n",
      "Model# 18. 4432 nodes still misclassified out of torch.Size([12410]) \n",
      "\n",
      "Model# 19. 4432 nodes still misclassified out of torch.Size([12410]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12327/12327 [00:00<00:00, 2706547.95it/s]\n",
      "100%|██████████| 12327/12327 [00:00<00:00, 3015466.31it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2048366.73it/s]\n",
      "Inferring Phrases: 100%|██████████| 12327/12327 [00:00<00:00, 349504.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4459 nodes still misclassified out of torch.Size([12327]) \n",
      "\n",
      "Model# 1. 4459 nodes still misclassified out of torch.Size([12327]) \n",
      "\n",
      "Model# 2. 4459 nodes still misclassified out of torch.Size([12327]) \n",
      "\n",
      "Model# 3. 4459 nodes still misclassified out of torch.Size([12327]) \n",
      "\n",
      "Model# 4. 4459 nodes still misclassified out of torch.Size([12327]) \n",
      "\n",
      "Model# 5. 4459 nodes still misclassified out of torch.Size([12327]) \n",
      "\n",
      "Model# 6. 4459 nodes still misclassified out of torch.Size([12327]) \n",
      "\n",
      "Model# 7. 4459 nodes still misclassified out of torch.Size([12327]) \n",
      "\n",
      "Model# 8. 4459 nodes still misclassified out of torch.Size([12327]) \n",
      "\n",
      "Model# 9. 4459 nodes still misclassified out of torch.Size([12327]) \n",
      "\n",
      "Model# 10. 4459 nodes still misclassified out of torch.Size([12327]) \n",
      "\n",
      "Model# 11. 4459 nodes still misclassified out of torch.Size([12327]) \n",
      "\n",
      "Model# 12. 4459 nodes still misclassified out of torch.Size([12327]) \n",
      "\n",
      "Model# 13. 4459 nodes still misclassified out of torch.Size([12327]) \n",
      "\n",
      "Model# 14. 4459 nodes still misclassified out of torch.Size([12327]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 111/299 [01:05<01:46,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4459 nodes still misclassified out of torch.Size([12327]) \n",
      "\n",
      "Model# 16. 4459 nodes still misclassified out of torch.Size([12327]) \n",
      "\n",
      "Model# 17. 4459 nodes still misclassified out of torch.Size([12327]) \n",
      "\n",
      "Model# 18. 4459 nodes still misclassified out of torch.Size([12327]) \n",
      "\n",
      "Model# 19. 4459 nodes still misclassified out of torch.Size([12327]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12467/12467 [00:00<00:00, 4180889.74it/s]\n",
      "100%|██████████| 12467/12467 [00:00<00:00, 5078709.01it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2765353.61it/s]\n",
      "Inferring Phrases: 100%|██████████| 12467/12467 [00:00<00:00, 400686.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4482 nodes still misclassified out of torch.Size([12467]) \n",
      "\n",
      "Model# 1. 4482 nodes still misclassified out of torch.Size([12467]) \n",
      "\n",
      "Model# 2. 4482 nodes still misclassified out of torch.Size([12467]) \n",
      "\n",
      "Model# 3. 4482 nodes still misclassified out of torch.Size([12467]) \n",
      "\n",
      "Model# 4. 4482 nodes still misclassified out of torch.Size([12467]) \n",
      "\n",
      "Model# 5. 4482 nodes still misclassified out of torch.Size([12467]) \n",
      "\n",
      "Model# 6. 4482 nodes still misclassified out of torch.Size([12467]) \n",
      "\n",
      "Model# 7. 4482 nodes still misclassified out of torch.Size([12467]) \n",
      "\n",
      "Model# 8. 4482 nodes still misclassified out of torch.Size([12467]) \n",
      "\n",
      "Model# 9. 4482 nodes still misclassified out of torch.Size([12467]) \n",
      "\n",
      "Model# 10. 4482 nodes still misclassified out of torch.Size([12467]) \n",
      "\n",
      "Model# 11. 4482 nodes still misclassified out of torch.Size([12467]) \n",
      "\n",
      "Model# 12. 4482 nodes still misclassified out of torch.Size([12467]) \n",
      "\n",
      "Model# 13. 4482 nodes still misclassified out of torch.Size([12467]) \n",
      "\n",
      "Model# 14. 4482 nodes still misclassified out of torch.Size([12467]) \n",
      "\n",
      "Model# 15. 4482 nodes still misclassified out of torch.Size([12467]) \n",
      "\n",
      "Model# 16. 4482 nodes still misclassified out of torch.Size([12467]) \n",
      "\n",
      "Model# 17. 4482 nodes still misclassified out of torch.Size([12467]) \n",
      "\n",
      "Model# 18. 4482 nodes still misclassified out of torch.Size([12467]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 112/299 [01:06<01:48,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4482 nodes still misclassified out of torch.Size([12467]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12546/12546 [00:00<00:00, 2683139.81it/s]\n",
      "100%|██████████| 12546/12546 [00:00<00:00, 3037505.08it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1970081.73it/s]\n",
      "Inferring Phrases: 100%|██████████| 12546/12546 [00:00<00:00, 356175.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4225 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 1. 4225 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 2. 4225 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 3. 4225 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 4. 4225 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 5. 4225 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 6. 4225 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 7. 4225 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 8. 4225 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 9. 4225 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 10. 4225 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 11. 4225 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 12. 4225 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 13. 4225 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 14. 4225 nodes still misclassified out of torch.Size([12546]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 113/299 [01:06<01:44,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4225 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 16. 4225 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 17. 4225 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 18. 4225 nodes still misclassified out of torch.Size([12546]) \n",
      "\n",
      "Model# 19. 4225 nodes still misclassified out of torch.Size([12546]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12588/12588 [00:00<00:00, 2677242.47it/s]\n",
      "100%|██████████| 12588/12588 [00:00<00:00, 2971181.70it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1986848.78it/s]\n",
      "Inferring Phrases: 100%|██████████| 12588/12588 [00:00<00:00, 369355.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4549 nodes still misclassified out of torch.Size([12588]) \n",
      "\n",
      "Model# 1. 4549 nodes still misclassified out of torch.Size([12588]) \n",
      "\n",
      "Model# 2. 4549 nodes still misclassified out of torch.Size([12588]) \n",
      "\n",
      "Model# 3. 4549 nodes still misclassified out of torch.Size([12588]) \n",
      "\n",
      "Model# 4. 4549 nodes still misclassified out of torch.Size([12588]) \n",
      "\n",
      "Model# 5. 4549 nodes still misclassified out of torch.Size([12588]) \n",
      "\n",
      "Model# 6. 4549 nodes still misclassified out of torch.Size([12588]) \n",
      "\n",
      "Model# 7. 4549 nodes still misclassified out of torch.Size([12588]) \n",
      "\n",
      "Model# 8. 4549 nodes still misclassified out of torch.Size([12588]) \n",
      "\n",
      "Model# 9. 4549 nodes still misclassified out of torch.Size([12588]) \n",
      "\n",
      "Model# 10. 4549 nodes still misclassified out of torch.Size([12588]) \n",
      "\n",
      "Model# 11. 4549 nodes still misclassified out of torch.Size([12588]) \n",
      "\n",
      "Model# 12. 4549 nodes still misclassified out of torch.Size([12588]) \n",
      "\n",
      "Model# 13. 4549 nodes still misclassified out of torch.Size([12588]) \n",
      "\n",
      "Model# 14. 4549 nodes still misclassified out of torch.Size([12588]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 114/299 [01:07<01:42,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4549 nodes still misclassified out of torch.Size([12588]) \n",
      "\n",
      "Model# 16. 4549 nodes still misclassified out of torch.Size([12588]) \n",
      "\n",
      "Model# 17. 4549 nodes still misclassified out of torch.Size([12588]) \n",
      "\n",
      "Model# 18. 4549 nodes still misclassified out of torch.Size([12588]) \n",
      "\n",
      "Model# 19. 4549 nodes still misclassified out of torch.Size([12588]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12695/12695 [00:00<00:00, 3603105.24it/s]\n",
      "100%|██████████| 12695/12695 [00:00<00:00, 4424319.84it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2501970.89it/s]\n",
      "Inferring Phrases: 100%|██████████| 12695/12695 [00:00<00:00, 401038.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4562 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 1. 4562 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 2. 4562 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 3. 4562 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 4. 4562 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 5. 4562 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 6. 4562 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 7. 4562 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 8. 4562 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 9. 4562 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 10. 4562 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 11. 4562 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 12. 4562 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 13. 4562 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 14. 4562 nodes still misclassified out of torch.Size([12695]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 115/299 [01:07<01:47,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4562 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 16. 4562 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 17. 4562 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 18. 4562 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 19. 4562 nodes still misclassified out of torch.Size([12695]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12865/12865 [00:00<00:00, 2711135.05it/s]\n",
      "100%|██████████| 12865/12865 [00:00<00:00, 2989458.22it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1973511.50it/s]\n",
      "Inferring Phrases: 100%|██████████| 12865/12865 [00:00<00:00, 347186.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4822 nodes still misclassified out of torch.Size([12865]) \n",
      "\n",
      "Model# 1. 4822 nodes still misclassified out of torch.Size([12865]) \n",
      "\n",
      "Model# 2. 4822 nodes still misclassified out of torch.Size([12865]) \n",
      "\n",
      "Model# 3. 4822 nodes still misclassified out of torch.Size([12865]) \n",
      "\n",
      "Model# 4. 4822 nodes still misclassified out of torch.Size([12865]) \n",
      "\n",
      "Model# 5. 4822 nodes still misclassified out of torch.Size([12865]) \n",
      "\n",
      "Model# 6. 4822 nodes still misclassified out of torch.Size([12865]) \n",
      "\n",
      "Model# 7. 4822 nodes still misclassified out of torch.Size([12865]) \n",
      "\n",
      "Model# 8. 4822 nodes still misclassified out of torch.Size([12865]) \n",
      "\n",
      "Model# 9. 4822 nodes still misclassified out of torch.Size([12865]) \n",
      "\n",
      "Model# 10. 4822 nodes still misclassified out of torch.Size([12865]) \n",
      "\n",
      "Model# 11. 4822 nodes still misclassified out of torch.Size([12865]) \n",
      "\n",
      "Model# 12. 4822 nodes still misclassified out of torch.Size([12865]) \n",
      "\n",
      "Model# 13. 4822 nodes still misclassified out of torch.Size([12865]) \n",
      "\n",
      "Model# 14. 4822 nodes still misclassified out of torch.Size([12865]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 116/299 [01:08<01:43,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4822 nodes still misclassified out of torch.Size([12865]) \n",
      "\n",
      "Model# 16. 4822 nodes still misclassified out of torch.Size([12865]) \n",
      "\n",
      "Model# 17. 4822 nodes still misclassified out of torch.Size([12865]) \n",
      "\n",
      "Model# 18. 4822 nodes still misclassified out of torch.Size([12865]) \n",
      "\n",
      "Model# 19. 4822 nodes still misclassified out of torch.Size([12865]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12859/12859 [00:00<00:00, 2693764.62it/s]\n",
      "100%|██████████| 12859/12859 [00:00<00:00, 3002368.91it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1898333.23it/s]\n",
      "Inferring Phrases: 100%|██████████| 12859/12859 [00:00<00:00, 412873.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4927 nodes still misclassified out of torch.Size([12859]) \n",
      "\n",
      "Model# 1. 4927 nodes still misclassified out of torch.Size([12859]) \n",
      "\n",
      "Model# 2. 4927 nodes still misclassified out of torch.Size([12859]) \n",
      "\n",
      "Model# 3. 4927 nodes still misclassified out of torch.Size([12859]) \n",
      "\n",
      "Model# 4. 4927 nodes still misclassified out of torch.Size([12859]) \n",
      "\n",
      "Model# 5. 4927 nodes still misclassified out of torch.Size([12859]) \n",
      "\n",
      "Model# 6. 4927 nodes still misclassified out of torch.Size([12859]) \n",
      "\n",
      "Model# 7. 4927 nodes still misclassified out of torch.Size([12859]) \n",
      "\n",
      "Model# 8. 4927 nodes still misclassified out of torch.Size([12859]) \n",
      "\n",
      "Model# 9. 4927 nodes still misclassified out of torch.Size([12859]) \n",
      "\n",
      "Model# 10. 4927 nodes still misclassified out of torch.Size([12859]) \n",
      "\n",
      "Model# 11. 4927 nodes still misclassified out of torch.Size([12859]) \n",
      "\n",
      "Model# 12. 4927 nodes still misclassified out of torch.Size([12859]) \n",
      "\n",
      "Model# 13. 4927 nodes still misclassified out of torch.Size([12859]) \n",
      "\n",
      "Model# 14. 4927 nodes still misclassified out of torch.Size([12859]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 117/299 [01:08<01:40,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4927 nodes still misclassified out of torch.Size([12859]) \n",
      "\n",
      "Model# 16. 4927 nodes still misclassified out of torch.Size([12859]) \n",
      "\n",
      "Model# 17. 4927 nodes still misclassified out of torch.Size([12859]) \n",
      "\n",
      "Model# 18. 4927 nodes still misclassified out of torch.Size([12859]) \n",
      "\n",
      "Model# 19. 4927 nodes still misclassified out of torch.Size([12859]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13475/13475 [00:00<00:00, 4588637.36it/s]\n",
      "100%|██████████| 13475/13475 [00:00<00:00, 5280598.56it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2950825.95it/s]\n",
      "Inferring Phrases: 100%|██████████| 13475/13475 [00:00<00:00, 434822.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4434 nodes still misclassified out of torch.Size([13475]) \n",
      "\n",
      "Model# 1. 4434 nodes still misclassified out of torch.Size([13475]) \n",
      "\n",
      "Model# 2. 4434 nodes still misclassified out of torch.Size([13475]) \n",
      "\n",
      "Model# 3. 4434 nodes still misclassified out of torch.Size([13475]) \n",
      "\n",
      "Model# 4. 4434 nodes still misclassified out of torch.Size([13475]) \n",
      "\n",
      "Model# 5. 4434 nodes still misclassified out of torch.Size([13475]) \n",
      "\n",
      "Model# 6. 4434 nodes still misclassified out of torch.Size([13475]) \n",
      "\n",
      "Model# 7. 4434 nodes still misclassified out of torch.Size([13475]) \n",
      "\n",
      "Model# 8. 4434 nodes still misclassified out of torch.Size([13475]) \n",
      "\n",
      "Model# 9. 4434 nodes still misclassified out of torch.Size([13475]) \n",
      "\n",
      "Model# 10. 4434 nodes still misclassified out of torch.Size([13475]) \n",
      "\n",
      "Model# 11. 4434 nodes still misclassified out of torch.Size([13475]) \n",
      "\n",
      "Model# 12. 4434 nodes still misclassified out of torch.Size([13475]) \n",
      "\n",
      "Model# 13. 4434 nodes still misclassified out of torch.Size([13475]) \n",
      "\n",
      "Model# 14. 4434 nodes still misclassified out of torch.Size([13475]) \n",
      "\n",
      "Model# 15. 4434 nodes still misclassified out of torch.Size([13475]) \n",
      "\n",
      "Model# 16. 4434 nodes still misclassified out of torch.Size([13475]) \n",
      "\n",
      "Model# 17. 4434 nodes still misclassified out of torch.Size([13475]) \n",
      "\n",
      "Model# 18. 4434 nodes still misclassified out of torch.Size([13475]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 118/299 [01:09<01:41,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4434 nodes still misclassified out of torch.Size([13475]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14204/14204 [00:00<00:00, 4024854.35it/s]\n",
      "100%|██████████| 14204/14204 [00:00<00:00, 4540499.51it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1924286.89it/s]\n",
      "Inferring Phrases: 100%|██████████| 14204/14204 [00:00<00:00, 258967.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5926 nodes still misclassified out of torch.Size([14204]) \n",
      "\n",
      "Model# 1. 5926 nodes still misclassified out of torch.Size([14204]) \n",
      "\n",
      "Model# 2. 5926 nodes still misclassified out of torch.Size([14204]) \n",
      "\n",
      "Model# 3. 5926 nodes still misclassified out of torch.Size([14204]) \n",
      "\n",
      "Model# 4. 5926 nodes still misclassified out of torch.Size([14204]) \n",
      "\n",
      "Model# 5. 5926 nodes still misclassified out of torch.Size([14204]) \n",
      "\n",
      "Model# 6. 5926 nodes still misclassified out of torch.Size([14204]) \n",
      "\n",
      "Model# 7. 5926 nodes still misclassified out of torch.Size([14204]) \n",
      "\n",
      "Model# 8. 5926 nodes still misclassified out of torch.Size([14204]) \n",
      "\n",
      "Model# 9. 5926 nodes still misclassified out of torch.Size([14204]) \n",
      "\n",
      "Model# 10. 5926 nodes still misclassified out of torch.Size([14204]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 119/299 [01:10<01:42,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 5926 nodes still misclassified out of torch.Size([14204]) \n",
      "\n",
      "Model# 12. 5926 nodes still misclassified out of torch.Size([14204]) \n",
      "\n",
      "Model# 13. 5926 nodes still misclassified out of torch.Size([14204]) \n",
      "\n",
      "Model# 14. 5926 nodes still misclassified out of torch.Size([14204]) \n",
      "\n",
      "Model# 15. 5926 nodes still misclassified out of torch.Size([14204]) \n",
      "\n",
      "Model# 16. 5926 nodes still misclassified out of torch.Size([14204]) \n",
      "\n",
      "Model# 17. 5926 nodes still misclassified out of torch.Size([14204]) \n",
      "\n",
      "Model# 18. 5926 nodes still misclassified out of torch.Size([14204]) \n",
      "\n",
      "Model# 19. 5926 nodes still misclassified out of torch.Size([14204]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12644/12644 [00:00<00:00, 4105022.04it/s]\n",
      "100%|██████████| 12644/12644 [00:00<00:00, 4951244.49it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2830291.96it/s]\n",
      "Inferring Phrases: 100%|██████████| 12644/12644 [00:00<00:00, 419430.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4558 nodes still misclassified out of torch.Size([12644]) \n",
      "\n",
      "Model# 1. 4558 nodes still misclassified out of torch.Size([12644]) \n",
      "\n",
      "Model# 2. 4558 nodes still misclassified out of torch.Size([12644]) \n",
      "\n",
      "Model# 3. 4558 nodes still misclassified out of torch.Size([12644]) \n",
      "\n",
      "Model# 4. 4558 nodes still misclassified out of torch.Size([12644]) \n",
      "\n",
      "Model# 5. 4558 nodes still misclassified out of torch.Size([12644]) \n",
      "\n",
      "Model# 6. 4558 nodes still misclassified out of torch.Size([12644]) \n",
      "\n",
      "Model# 7. 4558 nodes still misclassified out of torch.Size([12644]) \n",
      "\n",
      "Model# 8. 4558 nodes still misclassified out of torch.Size([12644]) \n",
      "\n",
      "Model# 9. 4558 nodes still misclassified out of torch.Size([12644]) \n",
      "\n",
      "Model# 10. 4558 nodes still misclassified out of torch.Size([12644]) \n",
      "\n",
      "Model# 11. 4558 nodes still misclassified out of torch.Size([12644]) \n",
      "\n",
      "Model# 12. 4558 nodes still misclassified out of torch.Size([12644]) \n",
      "\n",
      "Model# 13. 4558 nodes still misclassified out of torch.Size([12644]) \n",
      "\n",
      "Model# 14. 4558 nodes still misclassified out of torch.Size([12644]) \n",
      "\n",
      "Model# 15. 4558 nodes still misclassified out of torch.Size([12644]) \n",
      "\n",
      "Model# 16. 4558 nodes still misclassified out of torch.Size([12644]) \n",
      "\n",
      "Model# 17. 4558 nodes still misclassified out of torch.Size([12644]) \n",
      "\n",
      "Model# 18. 4558 nodes still misclassified out of torch.Size([12644]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 120/299 [01:10<01:40,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4558 nodes still misclassified out of torch.Size([12644]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12297/12297 [00:00<00:00, 3968710.09it/s]\n",
      "100%|██████████| 12297/12297 [00:00<00:00, 4716290.81it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2843917.28it/s]\n",
      "Inferring Phrases: 100%|██████████| 12297/12297 [00:00<00:00, 372106.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4309 nodes still misclassified out of torch.Size([12297]) \n",
      "\n",
      "Model# 1. 4309 nodes still misclassified out of torch.Size([12297]) \n",
      "\n",
      "Model# 2. 4309 nodes still misclassified out of torch.Size([12297]) \n",
      "\n",
      "Model# 3. 4309 nodes still misclassified out of torch.Size([12297]) \n",
      "\n",
      "Model# 4. 4309 nodes still misclassified out of torch.Size([12297]) \n",
      "\n",
      "Model# 5. 4309 nodes still misclassified out of torch.Size([12297]) \n",
      "\n",
      "Model# 6. 4309 nodes still misclassified out of torch.Size([12297]) \n",
      "\n",
      "Model# 7. 4309 nodes still misclassified out of torch.Size([12297]) \n",
      "\n",
      "Model# 8. 4309 nodes still misclassified out of torch.Size([12297]) \n",
      "\n",
      "Model# 9. 4309 nodes still misclassified out of torch.Size([12297]) \n",
      "\n",
      "Model# 10. 4309 nodes still misclassified out of torch.Size([12297]) \n",
      "\n",
      "Model# 11. 4309 nodes still misclassified out of torch.Size([12297]) \n",
      "\n",
      "Model# 12. 4309 nodes still misclassified out of torch.Size([12297]) \n",
      "\n",
      "Model# 13. 4309 nodes still misclassified out of torch.Size([12297]) \n",
      "\n",
      "Model# 14. 4309 nodes still misclassified out of torch.Size([12297]) \n",
      "\n",
      "Model# 15. 4309 nodes still misclassified out of torch.Size([12297]) \n",
      "\n",
      "Model# 16. 4309 nodes still misclassified out of torch.Size([12297]) \n",
      "\n",
      "Model# 17. 4309 nodes still misclassified out of torch.Size([12297]) \n",
      "\n",
      "Model# 18. 4309 nodes still misclassified out of torch.Size([12297]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 121/299 [01:11<01:32,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4309 nodes still misclassified out of torch.Size([12297]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12911/12911 [00:00<00:00, 4111194.88it/s]\n",
      "100%|██████████| 12911/12911 [00:00<00:00, 4753151.84it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2844753.12it/s]\n",
      "Inferring Phrases: 100%|██████████| 12911/12911 [00:00<00:00, 389038.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4978 nodes still misclassified out of torch.Size([12911]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 1. 4978 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 2. 4978 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 3. 4978 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 4. 4978 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 5. 4978 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 6. 4978 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 7. 4978 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 8. 4978 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 9. 4978 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 10. 4978 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 11. 4978 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 12. 4978 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 13. 4978 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 14. 4978 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 15. 4978 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 16. 4978 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 17. 4978 nodes still misclassified out of torch.Size([12911]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 122/299 [01:11<01:26,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 18. 4978 nodes still misclassified out of torch.Size([12911]) \n",
      "\n",
      "Model# 19. 4978 nodes still misclassified out of torch.Size([12911]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12491/12491 [00:00<00:00, 4398912.78it/s]\n",
      "100%|██████████| 12491/12491 [00:00<00:00, 4702122.71it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2897552.62it/s]\n",
      "Inferring Phrases: 100%|██████████| 12491/12491 [00:00<00:00, 427002.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4481 nodes still misclassified out of torch.Size([12491]) \n",
      "\n",
      "Model# 1. 4481 nodes still misclassified out of torch.Size([12491]) \n",
      "\n",
      "Model# 2. 4481 nodes still misclassified out of torch.Size([12491]) \n",
      "\n",
      "Model# 3. 4481 nodes still misclassified out of torch.Size([12491]) \n",
      "\n",
      "Model# 4. 4481 nodes still misclassified out of torch.Size([12491]) \n",
      "\n",
      "Model# 5. 4481 nodes still misclassified out of torch.Size([12491]) \n",
      "\n",
      "Model# 6. 4481 nodes still misclassified out of torch.Size([12491]) \n",
      "\n",
      "Model# 7. 4481 nodes still misclassified out of torch.Size([12491]) \n",
      "\n",
      "Model# 8. 4481 nodes still misclassified out of torch.Size([12491]) \n",
      "\n",
      "Model# 9. 4481 nodes still misclassified out of torch.Size([12491]) \n",
      "\n",
      "Model# 10. 4481 nodes still misclassified out of torch.Size([12491]) \n",
      "\n",
      "Model# 11. 4481 nodes still misclassified out of torch.Size([12491]) \n",
      "\n",
      "Model# 12. 4481 nodes still misclassified out of torch.Size([12491]) \n",
      "\n",
      "Model# 13. 4481 nodes still misclassified out of torch.Size([12491]) \n",
      "\n",
      "Model# 14. 4481 nodes still misclassified out of torch.Size([12491]) \n",
      "\n",
      "Model# 15. 4481 nodes still misclassified out of torch.Size([12491]) \n",
      "\n",
      "Model# 16. 4481 nodes still misclassified out of torch.Size([12491]) \n",
      "\n",
      "Model# 17. 4481 nodes still misclassified out of torch.Size([12491]) \n",
      "\n",
      "Model# 18. 4481 nodes still misclassified out of torch.Size([12491]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 123/299 [01:12<01:31,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4481 nodes still misclassified out of torch.Size([12491]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12528/12528 [00:00<00:00, 3973250.70it/s]\n",
      "100%|██████████| 12528/12528 [00:00<00:00, 4676596.70it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2758079.87it/s]\n",
      "Inferring Phrases: 100%|██████████| 12528/12528 [00:00<00:00, 376916.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4294 nodes still misclassified out of torch.Size([12528]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 1. 4294 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 2. 4294 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 3. 4294 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 4. 4294 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 5. 4294 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 6. 4294 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 7. 4294 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 8. 4294 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 9. 4294 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 10. 4294 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 11. 4294 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 12. 4294 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 13. 4294 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 14. 4294 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 15. 4294 nodes still misclassified out of torch.Size([12528]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 124/299 [01:12<01:27,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 16. 4294 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 17. 4294 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 18. 4294 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 19. 4294 nodes still misclassified out of torch.Size([12528]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12768/12768 [00:00<00:00, 2622056.08it/s]\n",
      "100%|██████████| 12768/12768 [00:00<00:00, 4070295.16it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2754095.60it/s]\n",
      "Inferring Phrases: 100%|██████████| 12768/12768 [00:00<00:00, 401918.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3548 nodes still misclassified out of torch.Size([12768]) \n",
      "\n",
      "Model# 1. 3548 nodes still misclassified out of torch.Size([12768]) \n",
      "\n",
      "Model# 2. 3548 nodes still misclassified out of torch.Size([12768]) \n",
      "\n",
      "Model# 3. 3548 nodes still misclassified out of torch.Size([12768]) \n",
      "\n",
      "Model# 4. 3548 nodes still misclassified out of torch.Size([12768]) \n",
      "\n",
      "Model# 5. 3548 nodes still misclassified out of torch.Size([12768]) \n",
      "\n",
      "Model# 6. 3548 nodes still misclassified out of torch.Size([12768]) \n",
      "\n",
      "Model# 7. 3548 nodes still misclassified out of torch.Size([12768]) \n",
      "\n",
      "Model# 8. 3548 nodes still misclassified out of torch.Size([12768]) \n",
      "\n",
      "Model# 9. 3548 nodes still misclassified out of torch.Size([12768]) \n",
      "\n",
      "Model# 10. 3548 nodes still misclassified out of torch.Size([12768]) \n",
      "\n",
      "Model# 11. 3548 nodes still misclassified out of torch.Size([12768]) \n",
      "\n",
      "Model# 12. 3548 nodes still misclassified out of torch.Size([12768]) \n",
      "\n",
      "Model# 13. 3548 nodes still misclassified out of torch.Size([12768]) \n",
      "\n",
      "Model# 14. 3548 nodes still misclassified out of torch.Size([12768]) \n",
      "\n",
      "Model# 15. 3548 nodes still misclassified out of torch.Size([12768]) \n",
      "\n",
      "Model# 16. 3548 nodes still misclassified out of torch.Size([12768]) \n",
      "\n",
      "Model# 17. 3548 nodes still misclassified out of torch.Size([12768]) \n",
      "\n",
      "Model# 18. 3548 nodes still misclassified out of torch.Size([12768]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 125/299 [01:13<01:24,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 3548 nodes still misclassified out of torch.Size([12768]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13015/13015 [00:00<00:00, 4073796.01it/s]\n",
      "100%|██████████| 13015/13015 [00:00<00:00, 4848464.92it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2749762.24it/s]\n",
      "Inferring Phrases: 100%|██████████| 13015/13015 [00:00<00:00, 416159.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4272 nodes still misclassified out of torch.Size([13015]) \n",
      "\n",
      "Model# 1. 4272 nodes still misclassified out of torch.Size([13015]) \n",
      "\n",
      "Model# 2. 4272 nodes still misclassified out of torch.Size([13015]) \n",
      "\n",
      "Model# 3. 4272 nodes still misclassified out of torch.Size([13015]) \n",
      "\n",
      "Model# 4. 4272 nodes still misclassified out of torch.Size([13015]) \n",
      "\n",
      "Model# 5. 4272 nodes still misclassified out of torch.Size([13015]) \n",
      "\n",
      "Model# 6. 4272 nodes still misclassified out of torch.Size([13015]) \n",
      "\n",
      "Model# 7. 4272 nodes still misclassified out of torch.Size([13015]) \n",
      "\n",
      "Model# 8. 4272 nodes still misclassified out of torch.Size([13015]) \n",
      "\n",
      "Model# 9. 4272 nodes still misclassified out of torch.Size([13015]) \n",
      "\n",
      "Model# 10. 4272 nodes still misclassified out of torch.Size([13015]) \n",
      "\n",
      "Model# 11. 4272 nodes still misclassified out of torch.Size([13015]) \n",
      "\n",
      "Model# 12. 4272 nodes still misclassified out of torch.Size([13015]) \n",
      "\n",
      "Model# 13. 4272 nodes still misclassified out of torch.Size([13015]) \n",
      "\n",
      "Model# 14. 4272 nodes still misclassified out of torch.Size([13015]) \n",
      "\n",
      "Model# 15. 4272 nodes still misclassified out of torch.Size([13015]) \n",
      "\n",
      "Model# 16. 4272 nodes still misclassified out of torch.Size([13015]) \n",
      "\n",
      "Model# 17. 4272 nodes still misclassified out of torch.Size([13015]) \n",
      "\n",
      "Model# 18. 4272 nodes still misclassified out of torch.Size([13015]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 126/299 [01:13<01:30,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4272 nodes still misclassified out of torch.Size([13015]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12632/12632 [00:00<00:00, 4155486.13it/s]\n",
      "100%|██████████| 12632/12632 [00:00<00:00, 4735226.39it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2823179.72it/s]\n",
      "Inferring Phrases: 100%|██████████| 12632/12632 [00:00<00:00, 383641.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4531 nodes still misclassified out of torch.Size([12632]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 1. 4531 nodes still misclassified out of torch.Size([12632]) \n",
      "\n",
      "Model# 2. 4531 nodes still misclassified out of torch.Size([12632]) \n",
      "\n",
      "Model# 3. 4531 nodes still misclassified out of torch.Size([12632]) \n",
      "\n",
      "Model# 4. 4531 nodes still misclassified out of torch.Size([12632]) \n",
      "\n",
      "Model# 5. 4531 nodes still misclassified out of torch.Size([12632]) \n",
      "\n",
      "Model# 6. 4531 nodes still misclassified out of torch.Size([12632]) \n",
      "\n",
      "Model# 7. 4531 nodes still misclassified out of torch.Size([12632]) \n",
      "\n",
      "Model# 8. 4531 nodes still misclassified out of torch.Size([12632]) \n",
      "\n",
      "Model# 9. 4531 nodes still misclassified out of torch.Size([12632]) \n",
      "\n",
      "Model# 10. 4531 nodes still misclassified out of torch.Size([12632]) \n",
      "\n",
      "Model# 11. 4531 nodes still misclassified out of torch.Size([12632]) \n",
      "\n",
      "Model# 12. 4531 nodes still misclassified out of torch.Size([12632]) \n",
      "\n",
      "Model# 13. 4531 nodes still misclassified out of torch.Size([12632]) \n",
      "\n",
      "Model# 14. 4531 nodes still misclassified out of torch.Size([12632]) \n",
      "\n",
      "Model# 15. 4531 nodes still misclassified out of torch.Size([12632]) \n",
      "\n",
      "Model# 16. 4531 nodes still misclassified out of torch.Size([12632]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 127/299 [01:14<01:25,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 17. 4531 nodes still misclassified out of torch.Size([12632]) \n",
      "\n",
      "Model# 18. 4531 nodes still misclassified out of torch.Size([12632]) \n",
      "\n",
      "Model# 19. 4531 nodes still misclassified out of torch.Size([12632]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12727/12727 [00:00<00:00, 2700233.04it/s]\n",
      "100%|██████████| 12727/12727 [00:00<00:00, 3025956.98it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1992227.99it/s]\n",
      "Inferring Phrases: 100%|██████████| 12727/12727 [00:00<00:00, 357234.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4529 nodes still misclassified out of torch.Size([12727]) \n",
      "\n",
      "Model# 1. 4529 nodes still misclassified out of torch.Size([12727]) \n",
      "\n",
      "Model# 2. 4529 nodes still misclassified out of torch.Size([12727]) \n",
      "\n",
      "Model# 3. 4529 nodes still misclassified out of torch.Size([12727]) \n",
      "\n",
      "Model# 4. 4529 nodes still misclassified out of torch.Size([12727]) \n",
      "\n",
      "Model# 5. 4529 nodes still misclassified out of torch.Size([12727]) \n",
      "\n",
      "Model# 6. 4529 nodes still misclassified out of torch.Size([12727]) \n",
      "\n",
      "Model# 7. 4529 nodes still misclassified out of torch.Size([12727]) \n",
      "\n",
      "Model# 8. 4529 nodes still misclassified out of torch.Size([12727]) \n",
      "\n",
      "Model# 9. 4529 nodes still misclassified out of torch.Size([12727]) \n",
      "\n",
      "Model# 10. 4529 nodes still misclassified out of torch.Size([12727]) \n",
      "\n",
      "Model# 11. 4529 nodes still misclassified out of torch.Size([12727]) \n",
      "\n",
      "Model# 12. 4529 nodes still misclassified out of torch.Size([12727]) \n",
      "\n",
      "Model# 13. 4529 nodes still misclassified out of torch.Size([12727]) \n",
      "\n",
      "Model# 14. 4529 nodes still misclassified out of torch.Size([12727]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 128/299 [01:14<01:26,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4529 nodes still misclassified out of torch.Size([12727]) \n",
      "\n",
      "Model# 16. 4529 nodes still misclassified out of torch.Size([12727]) \n",
      "\n",
      "Model# 17. 4529 nodes still misclassified out of torch.Size([12727]) \n",
      "\n",
      "Model# 18. 4529 nodes still misclassified out of torch.Size([12727]) \n",
      "\n",
      "Model# 19. 4529 nodes still misclassified out of torch.Size([12727]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12603/12603 [00:00<00:00, 4054676.18it/s]\n",
      "100%|██████████| 12603/12603 [00:00<00:00, 4769970.52it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2588064.75it/s]\n",
      "Inferring Phrases: 100%|██████████| 12603/12603 [00:00<00:00, 401525.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4655 nodes still misclassified out of torch.Size([12603]) \n",
      "\n",
      "Model# 1. 4655 nodes still misclassified out of torch.Size([12603]) \n",
      "\n",
      "Model# 2. 4655 nodes still misclassified out of torch.Size([12603]) \n",
      "\n",
      "Model# 3. 4655 nodes still misclassified out of torch.Size([12603]) \n",
      "\n",
      "Model# 4. 4655 nodes still misclassified out of torch.Size([12603]) \n",
      "\n",
      "Model# 5. 4655 nodes still misclassified out of torch.Size([12603]) \n",
      "\n",
      "Model# 6. 4655 nodes still misclassified out of torch.Size([12603]) \n",
      "\n",
      "Model# 7. 4655 nodes still misclassified out of torch.Size([12603]) \n",
      "\n",
      "Model# 8. 4655 nodes still misclassified out of torch.Size([12603]) \n",
      "\n",
      "Model# 9. 4655 nodes still misclassified out of torch.Size([12603]) \n",
      "\n",
      "Model# 10. 4655 nodes still misclassified out of torch.Size([12603]) \n",
      "\n",
      "Model# 11. 4655 nodes still misclassified out of torch.Size([12603]) \n",
      "\n",
      "Model# 12. 4655 nodes still misclassified out of torch.Size([12603]) \n",
      "\n",
      "Model# 13. 4655 nodes still misclassified out of torch.Size([12603]) \n",
      "\n",
      "Model# 14. 4655 nodes still misclassified out of torch.Size([12603]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 129/299 [01:15<01:34,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4655 nodes still misclassified out of torch.Size([12603]) \n",
      "\n",
      "Model# 16. 4655 nodes still misclassified out of torch.Size([12603]) \n",
      "\n",
      "Model# 17. 4655 nodes still misclassified out of torch.Size([12603]) \n",
      "\n",
      "Model# 18. 4655 nodes still misclassified out of torch.Size([12603]) \n",
      "\n",
      "Model# 19. 4655 nodes still misclassified out of torch.Size([12603]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13248/13248 [00:00<00:00, 2544586.68it/s]\n",
      "100%|██████████| 13248/13248 [00:00<00:00, 2972882.10it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1903761.56it/s]\n",
      "Inferring Phrases: 100%|██████████| 13248/13248 [00:00<00:00, 411363.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4777 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 1. 4777 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 2. 4777 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 3. 4777 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 4. 4777 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 5. 4777 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 6. 4777 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 7. 4777 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 8. 4777 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 9. 4777 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 10. 4777 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 11. 4777 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 12. 4777 nodes still misclassified out of torch.Size([13248]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 130/299 [01:15<01:34,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 13. 4777 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 14. 4777 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 15. 4777 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 16. 4777 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 17. 4777 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 18. 4777 nodes still misclassified out of torch.Size([13248]) \n",
      "\n",
      "Model# 19. 4777 nodes still misclassified out of torch.Size([13248]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13852/13852 [00:00<00:00, 3705561.52it/s]\n",
      "100%|██████████| 13852/13852 [00:00<00:00, 4502092.14it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2388782.53it/s]\n",
      "Inferring Phrases: 100%|██████████| 13852/13852 [00:00<00:00, 438851.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5474 nodes still misclassified out of torch.Size([13852]) \n",
      "\n",
      "Model# 1. 5474 nodes still misclassified out of torch.Size([13852]) \n",
      "\n",
      "Model# 2. 5474 nodes still misclassified out of torch.Size([13852]) \n",
      "\n",
      "Model# 3. 5474 nodes still misclassified out of torch.Size([13852]) \n",
      "\n",
      "Model# 4. 5474 nodes still misclassified out of torch.Size([13852]) \n",
      "\n",
      "Model# 5. 5474 nodes still misclassified out of torch.Size([13852]) \n",
      "\n",
      "Model# 6. 5474 nodes still misclassified out of torch.Size([13852]) \n",
      "\n",
      "Model# 7. 5474 nodes still misclassified out of torch.Size([13852]) \n",
      "\n",
      "Model# 8. 5474 nodes still misclassified out of torch.Size([13852]) \n",
      "\n",
      "Model# 9. 5474 nodes still misclassified out of torch.Size([13852]) \n",
      "\n",
      "Model# 10. 5474 nodes still misclassified out of torch.Size([13852]) \n",
      "\n",
      "Model# 11. 5474 nodes still misclassified out of torch.Size([13852]) \n",
      "\n",
      "Model# 12. 5474 nodes still misclassified out of torch.Size([13852]) \n",
      "\n",
      "Model# 13. 5474 nodes still misclassified out of torch.Size([13852]) \n",
      "\n",
      "Model# 14. 5474 nodes still misclassified out of torch.Size([13852]) \n",
      "\n",
      "Model# 15. 5474 nodes still misclassified out of torch.Size([13852]) \n",
      "\n",
      "Model# 16. 5474 nodes still misclassified out of torch.Size([13852]) \n",
      "\n",
      "Model# 17. 5474 nodes still misclassified out of torch.Size([13852]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 131/299 [01:16<01:51,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 18. 5474 nodes still misclassified out of torch.Size([13852]) \n",
      "\n",
      "Model# 19. 5474 nodes still misclassified out of torch.Size([13852]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13281/13281 [00:00<00:00, 2638650.53it/s]\n",
      "100%|██████████| 13281/13281 [00:00<00:00, 2992133.61it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1936875.55it/s]\n",
      "Inferring Phrases: 100%|██████████| 13281/13281 [00:00<00:00, 400766.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5008 nodes still misclassified out of torch.Size([13281]) \n",
      "\n",
      "Model# 1. 5008 nodes still misclassified out of torch.Size([13281]) \n",
      "\n",
      "Model# 2. 5008 nodes still misclassified out of torch.Size([13281]) \n",
      "\n",
      "Model# 3. 5008 nodes still misclassified out of torch.Size([13281]) \n",
      "\n",
      "Model# 4. 5008 nodes still misclassified out of torch.Size([13281]) \n",
      "\n",
      "Model# 5. 5008 nodes still misclassified out of torch.Size([13281]) \n",
      "\n",
      "Model# 6. 5008 nodes still misclassified out of torch.Size([13281]) \n",
      "\n",
      "Model# 7. 5008 nodes still misclassified out of torch.Size([13281]) \n",
      "\n",
      "Model# 8. 5008 nodes still misclassified out of torch.Size([13281]) \n",
      "\n",
      "Model# 9. 5008 nodes still misclassified out of torch.Size([13281]) \n",
      "\n",
      "Model# 10. 5008 nodes still misclassified out of torch.Size([13281]) \n",
      "\n",
      "Model# 11. 5008 nodes still misclassified out of torch.Size([13281]) \n",
      "\n",
      "Model# 12. 5008 nodes still misclassified out of torch.Size([13281]) \n",
      "\n",
      "Model# 13. 5008 nodes still misclassified out of torch.Size([13281]) \n",
      "\n",
      "Model# 14. 5008 nodes still misclassified out of torch.Size([13281]) \n",
      "\n",
      "Model# 15. 5008 nodes still misclassified out of torch.Size([13281]) \n",
      "\n",
      "Model# 16. 5008 nodes still misclassified out of torch.Size([13281]) \n",
      "\n",
      "Model# 17. 5008 nodes still misclassified out of torch.Size([13281]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 132/299 [01:17<01:53,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 18. 5008 nodes still misclassified out of torch.Size([13281]) \n",
      "\n",
      "Model# 19. 5008 nodes still misclassified out of torch.Size([13281]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13607/13607 [00:00<00:00, 2850886.38it/s]\n",
      "100%|██████████| 13607/13607 [00:00<00:00, 3731408.60it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1961880.35it/s]\n",
      "Inferring Phrases: 100%|██████████| 13607/13607 [00:00<00:00, 369156.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5658 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 1. 5658 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 2. 5658 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 3. 5658 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 4. 5658 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 5. 5658 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 6. 5658 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 7. 5658 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 8. 5658 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 9. 5658 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 10. 5658 nodes still misclassified out of torch.Size([13607]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 133/299 [01:18<01:49,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 5658 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 12. 5658 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 13. 5658 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 14. 5658 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 15. 5658 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 16. 5658 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 17. 5658 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 18. 5658 nodes still misclassified out of torch.Size([13607]) \n",
      "\n",
      "Model# 19. 5658 nodes still misclassified out of torch.Size([13607]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13111/13111 [00:00<00:00, 3861221.72it/s]\n",
      "100%|██████████| 13111/13111 [00:00<00:00, 4704955.49it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2484531.94it/s]\n",
      "Inferring Phrases: 100%|██████████| 13111/13111 [00:00<00:00, 399458.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4798 nodes still misclassified out of torch.Size([13111]) \n",
      "\n",
      "Model# 1. 4798 nodes still misclassified out of torch.Size([13111]) \n",
      "\n",
      "Model# 2. 4798 nodes still misclassified out of torch.Size([13111]) \n",
      "\n",
      "Model# 3. 4798 nodes still misclassified out of torch.Size([13111]) \n",
      "\n",
      "Model# 4. 4798 nodes still misclassified out of torch.Size([13111]) \n",
      "\n",
      "Model# 5. 4798 nodes still misclassified out of torch.Size([13111]) \n",
      "\n",
      "Model# 6. 4798 nodes still misclassified out of torch.Size([13111]) \n",
      "\n",
      "Model# 7. 4798 nodes still misclassified out of torch.Size([13111]) \n",
      "\n",
      "Model# 8. 4798 nodes still misclassified out of torch.Size([13111]) \n",
      "\n",
      "Model# 9. 4798 nodes still misclassified out of torch.Size([13111]) \n",
      "\n",
      "Model# 10. 4798 nodes still misclassified out of torch.Size([13111]) \n",
      "\n",
      "Model# 11. 4798 nodes still misclassified out of torch.Size([13111]) \n",
      "\n",
      "Model# 12. 4798 nodes still misclassified out of torch.Size([13111]) \n",
      "\n",
      "Model# 13. 4798 nodes still misclassified out of torch.Size([13111]) \n",
      "\n",
      "Model# 14. 4798 nodes still misclassified out of torch.Size([13111]) \n",
      "\n",
      "Model# 15. 4798 nodes still misclassified out of torch.Size([13111]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 134/299 [01:18<01:49,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 16. 4798 nodes still misclassified out of torch.Size([13111]) \n",
      "\n",
      "Model# 17. 4798 nodes still misclassified out of torch.Size([13111]) \n",
      "\n",
      "Model# 18. 4798 nodes still misclassified out of torch.Size([13111]) \n",
      "\n",
      "Model# 19. 4798 nodes still misclassified out of torch.Size([13111]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13222/13222 [00:00<00:00, 3246711.99it/s]\n",
      "100%|██████████| 13222/13222 [00:00<00:00, 4229491.11it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2184116.23it/s]\n",
      "Inferring Phrases: 100%|██████████| 13222/13222 [00:00<00:00, 366973.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5124 nodes still misclassified out of torch.Size([13222]) \n",
      "\n",
      "Model# 1. 5124 nodes still misclassified out of torch.Size([13222]) \n",
      "\n",
      "Model# 2. 5124 nodes still misclassified out of torch.Size([13222]) \n",
      "\n",
      "Model# 3. 5124 nodes still misclassified out of torch.Size([13222]) \n",
      "\n",
      "Model# 4. 5124 nodes still misclassified out of torch.Size([13222]) \n",
      "\n",
      "Model# 5. 5124 nodes still misclassified out of torch.Size([13222]) \n",
      "\n",
      "Model# 6. 5124 nodes still misclassified out of torch.Size([13222]) \n",
      "\n",
      "Model# 7. 5124 nodes still misclassified out of torch.Size([13222]) \n",
      "\n",
      "Model# 8. 5124 nodes still misclassified out of torch.Size([13222]) \n",
      "\n",
      "Model# 9. 5124 nodes still misclassified out of torch.Size([13222]) \n",
      "\n",
      "Model# 10. 5124 nodes still misclassified out of torch.Size([13222]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 135/299 [01:19<01:47,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 5124 nodes still misclassified out of torch.Size([13222]) \n",
      "\n",
      "Model# 12. 5124 nodes still misclassified out of torch.Size([13222]) \n",
      "\n",
      "Model# 13. 5124 nodes still misclassified out of torch.Size([13222]) \n",
      "\n",
      "Model# 14. 5124 nodes still misclassified out of torch.Size([13222]) \n",
      "\n",
      "Model# 15. 5124 nodes still misclassified out of torch.Size([13222]) \n",
      "\n",
      "Model# 16. 5124 nodes still misclassified out of torch.Size([13222]) \n",
      "\n",
      "Model# 17. 5124 nodes still misclassified out of torch.Size([13222]) \n",
      "\n",
      "Model# 18. 5124 nodes still misclassified out of torch.Size([13222]) \n",
      "\n",
      "Model# 19. 5124 nodes still misclassified out of torch.Size([13222]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12894/12894 [00:00<00:00, 2713701.43it/s]\n",
      "100%|██████████| 12894/12894 [00:00<00:00, 3431775.86it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1854327.78it/s]\n",
      "Inferring Phrases: 100%|██████████| 12894/12894 [00:00<00:00, 299676.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4669 nodes still misclassified out of torch.Size([12894]) \n",
      "\n",
      "Model# 1. 4669 nodes still misclassified out of torch.Size([12894]) \n",
      "\n",
      "Model# 2. 4669 nodes still misclassified out of torch.Size([12894]) \n",
      "\n",
      "Model# 3. 4669 nodes still misclassified out of torch.Size([12894]) \n",
      "\n",
      "Model# 4. 4669 nodes still misclassified out of torch.Size([12894]) \n",
      "\n",
      "Model# 5. 4669 nodes still misclassified out of torch.Size([12894]) \n",
      "\n",
      "Model# 6. 4669 nodes still misclassified out of torch.Size([12894]) \n",
      "\n",
      "Model# 7. 4669 nodes still misclassified out of torch.Size([12894]) \n",
      "\n",
      "Model# 8. 4669 nodes still misclassified out of torch.Size([12894]) \n",
      "\n",
      "Model# 9. 4669 nodes still misclassified out of torch.Size([12894]) \n",
      "\n",
      "Model# 10. 4669 nodes still misclassified out of torch.Size([12894]) \n",
      "\n",
      "Model# 11. 4669 nodes still misclassified out of torch.Size([12894]) \n",
      "\n",
      "Model# 12. 4669 nodes still misclassified out of torch.Size([12894]) \n",
      "\n",
      "Model# 13. 4669 nodes still misclassified out of torch.Size([12894]) \n",
      "\n",
      "Model# 14. 4669 nodes still misclassified out of torch.Size([12894]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 136/299 [01:20<01:51,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4669 nodes still misclassified out of torch.Size([12894]) \n",
      "\n",
      "Model# 16. 4669 nodes still misclassified out of torch.Size([12894]) \n",
      "\n",
      "Model# 17. 4669 nodes still misclassified out of torch.Size([12894]) \n",
      "\n",
      "Model# 18. 4669 nodes still misclassified out of torch.Size([12894]) \n",
      "\n",
      "Model# 19. 4669 nodes still misclassified out of torch.Size([12894]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12734/12734 [00:00<00:00, 3139933.40it/s]\n",
      "100%|██████████| 12734/12734 [00:00<00:00, 3761021.56it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1542401.57it/s]\n",
      "Inferring Phrases: 100%|██████████| 12734/12734 [00:00<00:00, 312251.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3439 nodes still misclassified out of torch.Size([12734]) \n",
      "\n",
      "Model# 1. 3439 nodes still misclassified out of torch.Size([12734]) \n",
      "\n",
      "Model# 2. 3439 nodes still misclassified out of torch.Size([12734]) \n",
      "\n",
      "Model# 3. 3439 nodes still misclassified out of torch.Size([12734]) \n",
      "\n",
      "Model# 4. 3439 nodes still misclassified out of torch.Size([12734]) \n",
      "\n",
      "Model# 5. 3439 nodes still misclassified out of torch.Size([12734]) \n",
      "\n",
      "Model# 6. 3439 nodes still misclassified out of torch.Size([12734]) \n",
      "\n",
      "Model# 7. 3439 nodes still misclassified out of torch.Size([12734]) \n",
      "\n",
      "Model# 8. 3439 nodes still misclassified out of torch.Size([12734]) \n",
      "\n",
      "Model# 9. 3439 nodes still misclassified out of torch.Size([12734]) \n",
      "\n",
      "Model# 10. 3439 nodes still misclassified out of torch.Size([12734]) \n",
      "\n",
      "Model# 11. 3439 nodes still misclassified out of torch.Size([12734]) \n",
      "\n",
      "Model# 12. 3439 nodes still misclassified out of torch.Size([12734]) \n",
      "\n",
      "Model# 13. 3439 nodes still misclassified out of torch.Size([12734]) \n",
      "\n",
      "Model# 14. 3439 nodes still misclassified out of torch.Size([12734]) \n",
      "\n",
      "Model# 15. 3439 nodes still misclassified out of torch.Size([12734]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 137/299 [01:20<01:42,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 16. 3439 nodes still misclassified out of torch.Size([12734]) \n",
      "\n",
      "Model# 17. 3439 nodes still misclassified out of torch.Size([12734]) \n",
      "\n",
      "Model# 18. 3439 nodes still misclassified out of torch.Size([12734]) \n",
      "\n",
      "Model# 19. 3439 nodes still misclassified out of torch.Size([12734]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12716/12716 [00:00<00:00, 3542190.99it/s]\n",
      "100%|██████████| 12716/12716 [00:00<00:00, 4403828.72it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2291259.90it/s]\n",
      "Inferring Phrases: 100%|██████████| 12716/12716 [00:00<00:00, 350607.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4490 nodes still misclassified out of torch.Size([12716]) \n",
      "\n",
      "Model# 1. 4490 nodes still misclassified out of torch.Size([12716]) \n",
      "\n",
      "Model# 2. 4490 nodes still misclassified out of torch.Size([12716]) \n",
      "\n",
      "Model# 3. 4490 nodes still misclassified out of torch.Size([12716]) \n",
      "\n",
      "Model# 4. 4490 nodes still misclassified out of torch.Size([12716]) \n",
      "\n",
      "Model# 5. 4490 nodes still misclassified out of torch.Size([12716]) \n",
      "\n",
      "Model# 6. 4490 nodes still misclassified out of torch.Size([12716]) \n",
      "\n",
      "Model# 7. 4490 nodes still misclassified out of torch.Size([12716]) \n",
      "\n",
      "Model# 8. 4490 nodes still misclassified out of torch.Size([12716]) \n",
      "\n",
      "Model# 9. 4490 nodes still misclassified out of torch.Size([12716]) \n",
      "\n",
      "Model# 10. 4490 nodes still misclassified out of torch.Size([12716]) \n",
      "\n",
      "Model# 11. 4490 nodes still misclassified out of torch.Size([12716]) \n",
      "\n",
      "Model# 12. 4490 nodes still misclassified out of torch.Size([12716]) \n",
      "\n",
      "Model# 13. 4490 nodes still misclassified out of torch.Size([12716]) \n",
      "\n",
      "Model# 14. 4490 nodes still misclassified out of torch.Size([12716]) \n",
      "\n",
      "Model# 15. 4490 nodes still misclassified out of torch.Size([12716]) \n",
      "\n",
      "Model# 16. 4490 nodes still misclassified out of torch.Size([12716]) \n",
      "\n",
      "Model# 17. 4490 nodes still misclassified out of torch.Size([12716]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 138/299 [01:21<01:33,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 18. 4490 nodes still misclassified out of torch.Size([12716]) \n",
      "\n",
      "Model# 19. 4490 nodes still misclassified out of torch.Size([12716]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12625/12625 [00:00<00:00, 2832321.78it/s]\n",
      "100%|██████████| 12625/12625 [00:00<00:00, 3647409.29it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1916753.55it/s]\n",
      "Inferring Phrases: 100%|██████████| 12625/12625 [00:00<00:00, 296925.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4573 nodes still misclassified out of torch.Size([12625]) \n",
      "\n",
      "Model# 1. 4573 nodes still misclassified out of torch.Size([12625]) \n",
      "\n",
      "Model# 2. 4573 nodes still misclassified out of torch.Size([12625]) \n",
      "\n",
      "Model# 3. 4573 nodes still misclassified out of torch.Size([12625]) \n",
      "\n",
      "Model# 4. 4573 nodes still misclassified out of torch.Size([12625]) \n",
      "\n",
      "Model# 5. 4573 nodes still misclassified out of torch.Size([12625]) \n",
      "\n",
      "Model# 6. 4573 nodes still misclassified out of torch.Size([12625]) \n",
      "\n",
      "Model# 7. 4573 nodes still misclassified out of torch.Size([12625]) \n",
      "\n",
      "Model# 8. 4573 nodes still misclassified out of torch.Size([12625]) \n",
      "\n",
      "Model# 9. 4573 nodes still misclassified out of torch.Size([12625]) \n",
      "\n",
      "Model# 10. 4573 nodes still misclassified out of torch.Size([12625]) \n",
      "\n",
      "Model# 11. 4573 nodes still misclassified out of torch.Size([12625]) \n",
      "\n",
      "Model# 12. 4573 nodes still misclassified out of torch.Size([12625]) \n",
      "\n",
      "Model# 13. 4573 nodes still misclassified out of torch.Size([12625]) \n",
      "\n",
      "Model# 14. 4573 nodes still misclassified out of torch.Size([12625]) \n",
      "\n",
      "Model# 15. 4573 nodes still misclassified out of torch.Size([12625]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 139/299 [01:21<01:39,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 16. 4573 nodes still misclassified out of torch.Size([12625]) \n",
      "\n",
      "Model# 17. 4573 nodes still misclassified out of torch.Size([12625]) \n",
      "\n",
      "Model# 18. 4573 nodes still misclassified out of torch.Size([12625]) \n",
      "\n",
      "Model# 19. 4573 nodes still misclassified out of torch.Size([12625]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12680/12680 [00:00<00:00, 2881340.05it/s]\n",
      "100%|██████████| 12680/12680 [00:00<00:00, 3604213.52it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2041586.81it/s]\n",
      "Inferring Phrases: 100%|██████████| 12680/12680 [00:00<00:00, 300120.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4735 nodes still misclassified out of torch.Size([12680]) \n",
      "\n",
      "Model# 1. 4735 nodes still misclassified out of torch.Size([12680]) \n",
      "\n",
      "Model# 2. 4735 nodes still misclassified out of torch.Size([12680]) \n",
      "\n",
      "Model# 3. 4735 nodes still misclassified out of torch.Size([12680]) \n",
      "\n",
      "Model# 4. 4735 nodes still misclassified out of torch.Size([12680]) \n",
      "\n",
      "Model# 5. 4735 nodes still misclassified out of torch.Size([12680]) \n",
      "\n",
      "Model# 6. 4735 nodes still misclassified out of torch.Size([12680]) \n",
      "\n",
      "Model# 7. 4735 nodes still misclassified out of torch.Size([12680]) \n",
      "\n",
      "Model# 8. 4735 nodes still misclassified out of torch.Size([12680]) \n",
      "\n",
      "Model# 9. 4735 nodes still misclassified out of torch.Size([12680]) \n",
      "\n",
      "Model# 10. 4735 nodes still misclassified out of torch.Size([12680]) \n",
      "\n",
      "Model# 11. 4735 nodes still misclassified out of torch.Size([12680]) \n",
      "\n",
      "Model# 12. 4735 nodes still misclassified out of torch.Size([12680]) \n",
      "\n",
      "Model# 13. 4735 nodes still misclassified out of torch.Size([12680]) \n",
      "\n",
      "Model# 14. 4735 nodes still misclassified out of torch.Size([12680]) \n",
      "\n",
      "Model# 15. 4735 nodes still misclassified out of torch.Size([12680]) \n",
      "\n",
      "Model# 16. 4735 nodes still misclassified out of torch.Size([12680]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 140/299 [01:22<01:33,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 17. 4735 nodes still misclassified out of torch.Size([12680]) \n",
      "\n",
      "Model# 18. 4735 nodes still misclassified out of torch.Size([12680]) \n",
      "\n",
      "Model# 19. 4735 nodes still misclassified out of torch.Size([12680]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12705/12705 [00:00<00:00, 3545248.64it/s]\n",
      "100%|██████████| 12705/12705 [00:00<00:00, 4387701.30it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2315461.42it/s]\n",
      "Inferring Phrases: 100%|██████████| 12705/12705 [00:00<00:00, 357505.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4695 nodes still misclassified out of torch.Size([12705]) \n",
      "\n",
      "Model# 1. 4695 nodes still misclassified out of torch.Size([12705]) \n",
      "\n",
      "Model# 2. 4695 nodes still misclassified out of torch.Size([12705]) \n",
      "\n",
      "Model# 3. 4695 nodes still misclassified out of torch.Size([12705]) \n",
      "\n",
      "Model# 4. 4695 nodes still misclassified out of torch.Size([12705]) \n",
      "\n",
      "Model# 5. 4695 nodes still misclassified out of torch.Size([12705]) \n",
      "\n",
      "Model# 6. 4695 nodes still misclassified out of torch.Size([12705]) \n",
      "\n",
      "Model# 7. 4695 nodes still misclassified out of torch.Size([12705]) \n",
      "\n",
      "Model# 8. 4695 nodes still misclassified out of torch.Size([12705]) \n",
      "\n",
      "Model# 9. 4695 nodes still misclassified out of torch.Size([12705]) \n",
      "\n",
      "Model# 10. 4695 nodes still misclassified out of torch.Size([12705]) \n",
      "\n",
      "Model# 11. 4695 nodes still misclassified out of torch.Size([12705]) \n",
      "\n",
      "Model# 12. 4695 nodes still misclassified out of torch.Size([12705]) \n",
      "\n",
      "Model# 13. 4695 nodes still misclassified out of torch.Size([12705]) \n",
      "\n",
      "Model# 14. 4695 nodes still misclassified out of torch.Size([12705]) \n",
      "\n",
      "Model# 15. 4695 nodes still misclassified out of torch.Size([12705]) \n",
      "\n",
      "Model# 16. 4695 nodes still misclassified out of torch.Size([12705]) \n",
      "\n",
      "Model# 17. 4695 nodes still misclassified out of torch.Size([12705]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 141/299 [01:22<01:25,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 18. 4695 nodes still misclassified out of torch.Size([12705]) \n",
      "\n",
      "Model# 19. 4695 nodes still misclassified out of torch.Size([12705]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15077/15077 [00:00<00:00, 3914666.42it/s]\n",
      "100%|██████████| 15077/15077 [00:00<00:00, 4791810.37it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2122981.61it/s]\n",
      "Inferring Phrases: 100%|██████████| 15077/15077 [00:00<00:00, 414226.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6728 nodes still misclassified out of torch.Size([15077]) \n",
      "\n",
      "Model# 1. 6728 nodes still misclassified out of torch.Size([15077]) \n",
      "\n",
      "Model# 2. 6728 nodes still misclassified out of torch.Size([15077]) \n",
      "\n",
      "Model# 3. 6728 nodes still misclassified out of torch.Size([15077]) \n",
      "\n",
      "Model# 4. 6728 nodes still misclassified out of torch.Size([15077]) \n",
      "\n",
      "Model# 5. 6728 nodes still misclassified out of torch.Size([15077]) \n",
      "\n",
      "Model# 6. 6728 nodes still misclassified out of torch.Size([15077]) \n",
      "\n",
      "Model# 7. 6728 nodes still misclassified out of torch.Size([15077]) \n",
      "\n",
      "Model# 8. 6728 nodes still misclassified out of torch.Size([15077]) \n",
      "\n",
      "Model# 9. 6728 nodes still misclassified out of torch.Size([15077]) \n",
      "\n",
      "Model# 10. 6728 nodes still misclassified out of torch.Size([15077]) \n",
      "\n",
      "Model# 11. 6728 nodes still misclassified out of torch.Size([15077]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 142/299 [01:23<01:39,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 12. 6728 nodes still misclassified out of torch.Size([15077]) \n",
      "\n",
      "Model# 13. 6728 nodes still misclassified out of torch.Size([15077]) \n",
      "\n",
      "Model# 14. 6728 nodes still misclassified out of torch.Size([15077]) \n",
      "\n",
      "Model# 15. 6728 nodes still misclassified out of torch.Size([15077]) \n",
      "\n",
      "Model# 16. 6728 nodes still misclassified out of torch.Size([15077]) \n",
      "\n",
      "Model# 17. 6728 nodes still misclassified out of torch.Size([15077]) \n",
      "\n",
      "Model# 18. 6728 nodes still misclassified out of torch.Size([15077]) \n",
      "\n",
      "Model# 19. 6728 nodes still misclassified out of torch.Size([15077]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14998/14998 [00:00<00:00, 3555226.14it/s]\n",
      "100%|██████████| 14998/14998 [00:00<00:00, 4333276.25it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2232675.40it/s]\n",
      "Inferring Phrases: 100%|██████████| 14998/14998 [00:00<00:00, 404606.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6533 nodes still misclassified out of torch.Size([14998]) \n",
      "\n",
      "Model# 1. 6533 nodes still misclassified out of torch.Size([14998]) \n",
      "\n",
      "Model# 2. 6533 nodes still misclassified out of torch.Size([14998]) \n",
      "\n",
      "Model# 3. 6533 nodes still misclassified out of torch.Size([14998]) \n",
      "\n",
      "Model# 4. 6533 nodes still misclassified out of torch.Size([14998]) \n",
      "\n",
      "Model# 5. 6533 nodes still misclassified out of torch.Size([14998]) \n",
      "\n",
      "Model# 6. 6533 nodes still misclassified out of torch.Size([14998]) \n",
      "\n",
      "Model# 7. 6533 nodes still misclassified out of torch.Size([14998]) \n",
      "\n",
      "Model# 8. 6533 nodes still misclassified out of torch.Size([14998]) \n",
      "\n",
      "Model# 9. 6533 nodes still misclassified out of torch.Size([14998]) \n",
      "\n",
      "Model# 10. 6533 nodes still misclassified out of torch.Size([14998]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 143/299 [01:24<01:37,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 6533 nodes still misclassified out of torch.Size([14998]) \n",
      "\n",
      "Model# 12. 6533 nodes still misclassified out of torch.Size([14998]) \n",
      "\n",
      "Model# 13. 6533 nodes still misclassified out of torch.Size([14998]) \n",
      "\n",
      "Model# 14. 6533 nodes still misclassified out of torch.Size([14998]) \n",
      "\n",
      "Model# 15. 6533 nodes still misclassified out of torch.Size([14998]) \n",
      "\n",
      "Model# 16. 6533 nodes still misclassified out of torch.Size([14998]) \n",
      "\n",
      "Model# 17. 6533 nodes still misclassified out of torch.Size([14998]) \n",
      "\n",
      "Model# 18. 6533 nodes still misclassified out of torch.Size([14998]) \n",
      "\n",
      "Model# 19. 6533 nodes still misclassified out of torch.Size([14998]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14677/14677 [00:00<00:00, 3220833.98it/s]\n",
      "100%|██████████| 14677/14677 [00:00<00:00, 4040417.42it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2194323.98it/s]\n",
      "Inferring Phrases: 100%|██████████| 14677/14677 [00:00<00:00, 396112.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5894 nodes still misclassified out of torch.Size([14677]) \n",
      "\n",
      "Model# 1. 5894 nodes still misclassified out of torch.Size([14677]) \n",
      "\n",
      "Model# 2. 5894 nodes still misclassified out of torch.Size([14677]) \n",
      "\n",
      "Model# 3. 5894 nodes still misclassified out of torch.Size([14677]) \n",
      "\n",
      "Model# 4. 5894 nodes still misclassified out of torch.Size([14677]) \n",
      "\n",
      "Model# 5. 5894 nodes still misclassified out of torch.Size([14677]) \n",
      "\n",
      "Model# 6. 5894 nodes still misclassified out of torch.Size([14677]) \n",
      "\n",
      "Model# 7. 5894 nodes still misclassified out of torch.Size([14677]) \n",
      "\n",
      "Model# 8. 5894 nodes still misclassified out of torch.Size([14677]) \n",
      "\n",
      "Model# 9. 5894 nodes still misclassified out of torch.Size([14677]) \n",
      "\n",
      "Model# 10. 5894 nodes still misclassified out of torch.Size([14677]) \n",
      "\n",
      "Model# 11. 5894 nodes still misclassified out of torch.Size([14677]) \n",
      "\n",
      "Model# 12. 5894 nodes still misclassified out of torch.Size([14677]) \n",
      "\n",
      "Model# 13. 5894 nodes still misclassified out of torch.Size([14677]) \n",
      "\n",
      "Model# 14. 5894 nodes still misclassified out of torch.Size([14677]) \n",
      "\n",
      "Model# 15. 5894 nodes still misclassified out of torch.Size([14677]) \n",
      "\n",
      "Model# 16. 5894 nodes still misclassified out of torch.Size([14677]) \n",
      "\n",
      "Model# 17. 5894 nodes still misclassified out of torch.Size([14677]) \n",
      "\n",
      "Model# 18. 5894 nodes still misclassified out of torch.Size([14677]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 144/299 [01:24<01:37,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 5894 nodes still misclassified out of torch.Size([14677]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15164/15164 [00:00<00:00, 3575379.50it/s]\n",
      "100%|██████████| 15164/15164 [00:00<00:00, 4758523.56it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2216237.85it/s]\n",
      "Inferring Phrases: 100%|██████████| 15164/15164 [00:00<00:00, 441181.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6740 nodes still misclassified out of torch.Size([15164]) \n",
      "\n",
      "Model# 1. 6740 nodes still misclassified out of torch.Size([15164]) \n",
      "\n",
      "Model# 2. 6740 nodes still misclassified out of torch.Size([15164]) \n",
      "\n",
      "Model# 3. 6740 nodes still misclassified out of torch.Size([15164]) \n",
      "\n",
      "Model# 4. 6740 nodes still misclassified out of torch.Size([15164]) \n",
      "\n",
      "Model# 5. 6740 nodes still misclassified out of torch.Size([15164]) \n",
      "\n",
      "Model# 6. 6740 nodes still misclassified out of torch.Size([15164]) \n",
      "\n",
      "Model# 7. 6740 nodes still misclassified out of torch.Size([15164]) \n",
      "\n",
      "Model# 8. 6740 nodes still misclassified out of torch.Size([15164]) \n",
      "\n",
      "Model# 9. 6740 nodes still misclassified out of torch.Size([15164]) \n",
      "\n",
      "Model# 10. 6740 nodes still misclassified out of torch.Size([15164]) \n",
      "\n",
      "Model# 11. 6740 nodes still misclassified out of torch.Size([15164]) \n",
      "\n",
      "Model# 12. 6740 nodes still misclassified out of torch.Size([15164]) \n",
      "\n",
      "Model# 13. 6740 nodes still misclassified out of torch.Size([15164]) \n",
      "\n",
      "Model# 14. 6740 nodes still misclassified out of torch.Size([15164]) \n",
      "\n",
      "Model# 15. 6740 nodes still misclassified out of torch.Size([15164]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 145/299 [01:25<01:52,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 16. 6740 nodes still misclassified out of torch.Size([15164]) \n",
      "\n",
      "Model# 17. 6740 nodes still misclassified out of torch.Size([15164]) \n",
      "\n",
      "Model# 18. 6740 nodes still misclassified out of torch.Size([15164]) \n",
      "\n",
      "Model# 19. 6740 nodes still misclassified out of torch.Size([15164]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14461/14461 [00:00<00:00, 2737951.07it/s]\n",
      "100%|██████████| 14461/14461 [00:00<00:00, 3760311.85it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2036267.60it/s]\n",
      "Inferring Phrases: 100%|██████████| 14461/14461 [00:00<00:00, 409936.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6322 nodes still misclassified out of torch.Size([14461]) \n",
      "\n",
      "Model# 1. 6322 nodes still misclassified out of torch.Size([14461]) \n",
      "\n",
      "Model# 2. 6322 nodes still misclassified out of torch.Size([14461]) \n",
      "\n",
      "Model# 3. 6322 nodes still misclassified out of torch.Size([14461]) \n",
      "\n",
      "Model# 4. 6322 nodes still misclassified out of torch.Size([14461]) \n",
      "\n",
      "Model# 5. 6322 nodes still misclassified out of torch.Size([14461]) \n",
      "\n",
      "Model# 6. 6322 nodes still misclassified out of torch.Size([14461]) \n",
      "\n",
      "Model# 7. 6322 nodes still misclassified out of torch.Size([14461]) \n",
      "\n",
      "Model# 8. 6322 nodes still misclassified out of torch.Size([14461]) \n",
      "\n",
      "Model# 9. 6322 nodes still misclassified out of torch.Size([14461]) \n",
      "\n",
      "Model# 10. 6322 nodes still misclassified out of torch.Size([14461]) \n",
      "\n",
      "Model# 11. 6322 nodes still misclassified out of torch.Size([14461]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 146/299 [01:26<01:46,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 12. 6322 nodes still misclassified out of torch.Size([14461]) \n",
      "\n",
      "Model# 13. 6322 nodes still misclassified out of torch.Size([14461]) \n",
      "\n",
      "Model# 14. 6322 nodes still misclassified out of torch.Size([14461]) \n",
      "\n",
      "Model# 15. 6322 nodes still misclassified out of torch.Size([14461]) \n",
      "\n",
      "Model# 16. 6322 nodes still misclassified out of torch.Size([14461]) \n",
      "\n",
      "Model# 17. 6322 nodes still misclassified out of torch.Size([14461]) \n",
      "\n",
      "Model# 18. 6322 nodes still misclassified out of torch.Size([14461]) \n",
      "\n",
      "Model# 19. 6322 nodes still misclassified out of torch.Size([14461]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14866/14866 [00:00<00:00, 3866823.15it/s]\n",
      "100%|██████████| 14866/14866 [00:00<00:00, 4910034.12it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2320585.73it/s]\n",
      "Inferring Phrases: 100%|██████████| 14866/14866 [00:00<00:00, 416271.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6597 nodes still misclassified out of torch.Size([14866]) \n",
      "\n",
      "Model# 1. 6597 nodes still misclassified out of torch.Size([14866]) \n",
      "\n",
      "Model# 2. 6597 nodes still misclassified out of torch.Size([14866]) \n",
      "\n",
      "Model# 3. 6597 nodes still misclassified out of torch.Size([14866]) \n",
      "\n",
      "Model# 4. 6597 nodes still misclassified out of torch.Size([14866]) \n",
      "\n",
      "Model# 5. 6597 nodes still misclassified out of torch.Size([14866]) \n",
      "\n",
      "Model# 6. 6597 nodes still misclassified out of torch.Size([14866]) \n",
      "\n",
      "Model# 7. 6597 nodes still misclassified out of torch.Size([14866]) \n",
      "\n",
      "Model# 8. 6597 nodes still misclassified out of torch.Size([14866]) \n",
      "\n",
      "Model# 9. 6597 nodes still misclassified out of torch.Size([14866]) \n",
      "\n",
      "Model# 10. 6597 nodes still misclassified out of torch.Size([14866]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 147/299 [01:27<01:52,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 6597 nodes still misclassified out of torch.Size([14866]) \n",
      "\n",
      "Model# 12. 6597 nodes still misclassified out of torch.Size([14866]) \n",
      "\n",
      "Model# 13. 6597 nodes still misclassified out of torch.Size([14866]) \n",
      "\n",
      "Model# 14. 6597 nodes still misclassified out of torch.Size([14866]) \n",
      "\n",
      "Model# 15. 6597 nodes still misclassified out of torch.Size([14866]) \n",
      "\n",
      "Model# 16. 6597 nodes still misclassified out of torch.Size([14866]) \n",
      "\n",
      "Model# 17. 6597 nodes still misclassified out of torch.Size([14866]) \n",
      "\n",
      "Model# 18. 6597 nodes still misclassified out of torch.Size([14866]) \n",
      "\n",
      "Model# 19. 6597 nodes still misclassified out of torch.Size([14866]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14316/14316 [00:00<00:00, 2250839.90it/s]\n",
      "100%|██████████| 14316/14316 [00:00<00:00, 2790484.99it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1956876.56it/s]\n",
      "Inferring Phrases: 100%|██████████| 14316/14316 [00:00<00:00, 397837.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5994 nodes still misclassified out of torch.Size([14316]) \n",
      "\n",
      "Model# 1. 5994 nodes still misclassified out of torch.Size([14316]) \n",
      "\n",
      "Model# 2. 5994 nodes still misclassified out of torch.Size([14316]) \n",
      "\n",
      "Model# 3. 5994 nodes still misclassified out of torch.Size([14316]) \n",
      "\n",
      "Model# 4. 5994 nodes still misclassified out of torch.Size([14316]) \n",
      "\n",
      "Model# 5. 5994 nodes still misclassified out of torch.Size([14316]) \n",
      "\n",
      "Model# 6. 5994 nodes still misclassified out of torch.Size([14316]) \n",
      "\n",
      "Model# 7. 5994 nodes still misclassified out of torch.Size([14316]) \n",
      "\n",
      "Model# 8. 5994 nodes still misclassified out of torch.Size([14316]) \n",
      "\n",
      "Model# 9. 5994 nodes still misclassified out of torch.Size([14316]) \n",
      "\n",
      "Model# 10. 5994 nodes still misclassified out of torch.Size([14316]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 148/299 [01:27<01:48,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 5994 nodes still misclassified out of torch.Size([14316]) \n",
      "\n",
      "Model# 12. 5994 nodes still misclassified out of torch.Size([14316]) \n",
      "\n",
      "Model# 13. 5994 nodes still misclassified out of torch.Size([14316]) \n",
      "\n",
      "Model# 14. 5994 nodes still misclassified out of torch.Size([14316]) \n",
      "\n",
      "Model# 15. 5994 nodes still misclassified out of torch.Size([14316]) \n",
      "\n",
      "Model# 16. 5994 nodes still misclassified out of torch.Size([14316]) \n",
      "\n",
      "Model# 17. 5994 nodes still misclassified out of torch.Size([14316]) \n",
      "\n",
      "Model# 18. 5994 nodes still misclassified out of torch.Size([14316]) \n",
      "\n",
      "Model# 19. 5994 nodes still misclassified out of torch.Size([14316]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13560/13560 [00:00<00:00, 3394494.91it/s]\n",
      "100%|██████████| 13560/13560 [00:00<00:00, 4280159.71it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2346726.35it/s]\n",
      "Inferring Phrases: 100%|██████████| 13560/13560 [00:00<00:00, 373942.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4664 nodes still misclassified out of torch.Size([13560]) \n",
      "\n",
      "Model# 1. 4664 nodes still misclassified out of torch.Size([13560]) \n",
      "\n",
      "Model# 2. 4664 nodes still misclassified out of torch.Size([13560]) \n",
      "\n",
      "Model# 3. 4664 nodes still misclassified out of torch.Size([13560]) \n",
      "\n",
      "Model# 4. 4664 nodes still misclassified out of torch.Size([13560]) \n",
      "\n",
      "Model# 5. 4664 nodes still misclassified out of torch.Size([13560]) \n",
      "\n",
      "Model# 6. 4664 nodes still misclassified out of torch.Size([13560]) \n",
      "\n",
      "Model# 7. 4664 nodes still misclassified out of torch.Size([13560]) \n",
      "\n",
      "Model# 8. 4664 nodes still misclassified out of torch.Size([13560]) \n",
      "\n",
      "Model# 9. 4664 nodes still misclassified out of torch.Size([13560]) \n",
      "\n",
      "Model# 10. 4664 nodes still misclassified out of torch.Size([13560]) \n",
      "\n",
      "Model# 11. 4664 nodes still misclassified out of torch.Size([13560]) \n",
      "\n",
      "Model# 12. 4664 nodes still misclassified out of torch.Size([13560]) \n",
      "\n",
      "Model# 13. 4664 nodes still misclassified out of torch.Size([13560]) \n",
      "\n",
      "Model# 14. 4664 nodes still misclassified out of torch.Size([13560]) \n",
      "\n",
      "Model# 15. 4664 nodes still misclassified out of torch.Size([13560]) \n",
      "\n",
      "Model# 16. 4664 nodes still misclassified out of torch.Size([13560]) \n",
      "\n",
      "Model# 17. 4664 nodes still misclassified out of torch.Size([13560]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 149/299 [01:28<01:35,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 18. 4664 nodes still misclassified out of torch.Size([13560]) \n",
      "\n",
      "Model# 19. 4664 nodes still misclassified out of torch.Size([13560]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14642/14642 [00:00<00:00, 3645986.65it/s]\n",
      "100%|██████████| 14642/14642 [00:00<00:00, 4814062.80it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2362367.08it/s]\n",
      "Inferring Phrases: 100%|██████████| 14642/14642 [00:00<00:00, 428481.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6358 nodes still misclassified out of torch.Size([14642]) \n",
      "\n",
      "Model# 1. 6358 nodes still misclassified out of torch.Size([14642]) \n",
      "\n",
      "Model# 2. 6358 nodes still misclassified out of torch.Size([14642]) \n",
      "\n",
      "Model# 3. 6358 nodes still misclassified out of torch.Size([14642]) \n",
      "\n",
      "Model# 4. 6358 nodes still misclassified out of torch.Size([14642]) \n",
      "\n",
      "Model# 5. 6358 nodes still misclassified out of torch.Size([14642]) \n",
      "\n",
      "Model# 6. 6358 nodes still misclassified out of torch.Size([14642]) \n",
      "\n",
      "Model# 7. 6358 nodes still misclassified out of torch.Size([14642]) \n",
      "\n",
      "Model# 8. 6358 nodes still misclassified out of torch.Size([14642]) \n",
      "\n",
      "Model# 9. 6358 nodes still misclassified out of torch.Size([14642]) \n",
      "\n",
      "Model# 10. 6358 nodes still misclassified out of torch.Size([14642]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 150/299 [01:29<01:43,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 6358 nodes still misclassified out of torch.Size([14642]) \n",
      "\n",
      "Model# 12. 6358 nodes still misclassified out of torch.Size([14642]) \n",
      "\n",
      "Model# 13. 6358 nodes still misclassified out of torch.Size([14642]) \n",
      "\n",
      "Model# 14. 6358 nodes still misclassified out of torch.Size([14642]) \n",
      "\n",
      "Model# 15. 6358 nodes still misclassified out of torch.Size([14642]) \n",
      "\n",
      "Model# 16. 6358 nodes still misclassified out of torch.Size([14642]) \n",
      "\n",
      "Model# 17. 6358 nodes still misclassified out of torch.Size([14642]) \n",
      "\n",
      "Model# 18. 6358 nodes still misclassified out of torch.Size([14642]) \n",
      "\n",
      "Model# 19. 6358 nodes still misclassified out of torch.Size([14642]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14749/14749 [00:00<00:00, 3459831.64it/s]\n",
      "100%|██████████| 14749/14749 [00:00<00:00, 4339959.99it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2270709.93it/s]\n",
      "Inferring Phrases: 100%|██████████| 14749/14749 [00:00<00:00, 320472.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6607 nodes still misclassified out of torch.Size([14749]) \n",
      "\n",
      "Model# 1. 6607 nodes still misclassified out of torch.Size([14749]) \n",
      "\n",
      "Model# 2. 6607 nodes still misclassified out of torch.Size([14749]) \n",
      "\n",
      "Model# 3. 6607 nodes still misclassified out of torch.Size([14749]) \n",
      "\n",
      "Model# 4. 6607 nodes still misclassified out of torch.Size([14749]) \n",
      "\n",
      "Model# 5. 6607 nodes still misclassified out of torch.Size([14749]) \n",
      "\n",
      "Model# 6. 6607 nodes still misclassified out of torch.Size([14749]) \n",
      "\n",
      "Model# 7. 6607 nodes still misclassified out of torch.Size([14749]) \n",
      "\n",
      "Model# 8. 6607 nodes still misclassified out of torch.Size([14749]) \n",
      "\n",
      "Model# 9. 6607 nodes still misclassified out of torch.Size([14749]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 151/299 [01:29<01:41,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 6607 nodes still misclassified out of torch.Size([14749]) \n",
      "\n",
      "Model# 11. 6607 nodes still misclassified out of torch.Size([14749]) \n",
      "\n",
      "Model# 12. 6607 nodes still misclassified out of torch.Size([14749]) \n",
      "\n",
      "Model# 13. 6607 nodes still misclassified out of torch.Size([14749]) \n",
      "\n",
      "Model# 14. 6607 nodes still misclassified out of torch.Size([14749]) \n",
      "\n",
      "Model# 15. 6607 nodes still misclassified out of torch.Size([14749]) \n",
      "\n",
      "Model# 16. 6607 nodes still misclassified out of torch.Size([14749]) \n",
      "\n",
      "Model# 17. 6607 nodes still misclassified out of torch.Size([14749]) \n",
      "\n",
      "Model# 18. 6607 nodes still misclassified out of torch.Size([14749]) \n",
      "\n",
      "Model# 19. 6607 nodes still misclassified out of torch.Size([14749]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14646/14646 [00:00<00:00, 3483400.99it/s]\n",
      "100%|██████████| 14646/14646 [00:00<00:00, 4676800.64it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2235690.27it/s]\n",
      "Inferring Phrases: 100%|██████████| 14646/14646 [00:00<00:00, 410456.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6293 nodes still misclassified out of torch.Size([14646]) \n",
      "\n",
      "Model# 1. 6293 nodes still misclassified out of torch.Size([14646]) \n",
      "\n",
      "Model# 2. 6293 nodes still misclassified out of torch.Size([14646]) \n",
      "\n",
      "Model# 3. 6293 nodes still misclassified out of torch.Size([14646]) \n",
      "\n",
      "Model# 4. 6293 nodes still misclassified out of torch.Size([14646]) \n",
      "\n",
      "Model# 5. 6293 nodes still misclassified out of torch.Size([14646]) \n",
      "\n",
      "Model# 6. 6293 nodes still misclassified out of torch.Size([14646]) \n",
      "\n",
      "Model# 7. 6293 nodes still misclassified out of torch.Size([14646]) \n",
      "\n",
      "Model# 8. 6293 nodes still misclassified out of torch.Size([14646]) \n",
      "\n",
      "Model# 9. 6293 nodes still misclassified out of torch.Size([14646]) \n",
      "\n",
      "Model# 10. 6293 nodes still misclassified out of torch.Size([14646]) \n",
      "\n",
      "Model# 11. 6293 nodes still misclassified out of torch.Size([14646]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 152/299 [01:30<01:44,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 12. 6293 nodes still misclassified out of torch.Size([14646]) \n",
      "\n",
      "Model# 13. 6293 nodes still misclassified out of torch.Size([14646]) \n",
      "\n",
      "Model# 14. 6293 nodes still misclassified out of torch.Size([14646]) \n",
      "\n",
      "Model# 15. 6293 nodes still misclassified out of torch.Size([14646]) \n",
      "\n",
      "Model# 16. 6293 nodes still misclassified out of torch.Size([14646]) \n",
      "\n",
      "Model# 17. 6293 nodes still misclassified out of torch.Size([14646]) \n",
      "\n",
      "Model# 18. 6293 nodes still misclassified out of torch.Size([14646]) \n",
      "\n",
      "Model# 19. 6293 nodes still misclassified out of torch.Size([14646]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14206/14206 [00:00<00:00, 3568989.67it/s]\n",
      "100%|██████████| 14206/14206 [00:00<00:00, 4438638.46it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2350496.33it/s]\n",
      "Inferring Phrases: 100%|██████████| 14206/14206 [00:00<00:00, 382374.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5875 nodes still misclassified out of torch.Size([14206]) \n",
      "\n",
      "Model# 1. 5875 nodes still misclassified out of torch.Size([14206]) \n",
      "\n",
      "Model# 2. 5875 nodes still misclassified out of torch.Size([14206]) \n",
      "\n",
      "Model# 3. 5875 nodes still misclassified out of torch.Size([14206]) \n",
      "\n",
      "Model# 4. 5875 nodes still misclassified out of torch.Size([14206]) \n",
      "\n",
      "Model# 5. 5875 nodes still misclassified out of torch.Size([14206]) \n",
      "\n",
      "Model# 6. 5875 nodes still misclassified out of torch.Size([14206]) \n",
      "\n",
      "Model# 7. 5875 nodes still misclassified out of torch.Size([14206]) \n",
      "\n",
      "Model# 8. 5875 nodes still misclassified out of torch.Size([14206]) \n",
      "\n",
      "Model# 9. 5875 nodes still misclassified out of torch.Size([14206]) \n",
      "\n",
      "Model# 10. 5875 nodes still misclassified out of torch.Size([14206]) \n",
      "\n",
      "Model# 11. 5875 nodes still misclassified out of torch.Size([14206]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 153/299 [01:31<01:37,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 12. 5875 nodes still misclassified out of torch.Size([14206]) \n",
      "\n",
      "Model# 13. 5875 nodes still misclassified out of torch.Size([14206]) \n",
      "\n",
      "Model# 14. 5875 nodes still misclassified out of torch.Size([14206]) \n",
      "\n",
      "Model# 15. 5875 nodes still misclassified out of torch.Size([14206]) \n",
      "\n",
      "Model# 16. 5875 nodes still misclassified out of torch.Size([14206]) \n",
      "\n",
      "Model# 17. 5875 nodes still misclassified out of torch.Size([14206]) \n",
      "\n",
      "Model# 18. 5875 nodes still misclassified out of torch.Size([14206]) \n",
      "\n",
      "Model# 19. 5875 nodes still misclassified out of torch.Size([14206]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14185/14185 [00:00<00:00, 2327525.32it/s]\n",
      "100%|██████████| 14185/14185 [00:00<00:00, 2394695.20it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1686423.55it/s]\n",
      "Inferring Phrases: 100%|██████████| 14185/14185 [00:00<00:00, 353695.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5399 nodes still misclassified out of torch.Size([14185]) \n",
      "\n",
      "Model# 1. 5399 nodes still misclassified out of torch.Size([14185]) \n",
      "\n",
      "Model# 2. 5399 nodes still misclassified out of torch.Size([14185]) \n",
      "\n",
      "Model# 3. 5399 nodes still misclassified out of torch.Size([14185]) \n",
      "\n",
      "Model# 4. 5399 nodes still misclassified out of torch.Size([14185]) \n",
      "\n",
      "Model# 5. 5399 nodes still misclassified out of torch.Size([14185]) \n",
      "\n",
      "Model# 6. 5399 nodes still misclassified out of torch.Size([14185]) \n",
      "\n",
      "Model# 7. 5399 nodes still misclassified out of torch.Size([14185]) \n",
      "\n",
      "Model# 8. 5399 nodes still misclassified out of torch.Size([14185]) \n",
      "\n",
      "Model# 9. 5399 nodes still misclassified out of torch.Size([14185]) \n",
      "\n",
      "Model# 10. 5399 nodes still misclassified out of torch.Size([14185]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 154/299 [01:31<01:34,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 5399 nodes still misclassified out of torch.Size([14185]) \n",
      "\n",
      "Model# 12. 5399 nodes still misclassified out of torch.Size([14185]) \n",
      "\n",
      "Model# 13. 5399 nodes still misclassified out of torch.Size([14185]) \n",
      "\n",
      "Model# 14. 5399 nodes still misclassified out of torch.Size([14185]) \n",
      "\n",
      "Model# 15. 5399 nodes still misclassified out of torch.Size([14185]) \n",
      "\n",
      "Model# 16. 5399 nodes still misclassified out of torch.Size([14185]) \n",
      "\n",
      "Model# 17. 5399 nodes still misclassified out of torch.Size([14185]) \n",
      "\n",
      "Model# 18. 5399 nodes still misclassified out of torch.Size([14185]) \n",
      "\n",
      "Model# 19. 5399 nodes still misclassified out of torch.Size([14185]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12904/12904 [00:00<00:00, 3914319.72it/s]\n",
      "100%|██████████| 12904/12904 [00:00<00:00, 4800292.58it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2332933.85it/s]\n",
      "Inferring Phrases: 100%|██████████| 12904/12904 [00:00<00:00, 378940.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4601 nodes still misclassified out of torch.Size([12904]) \n",
      "\n",
      "Model# 1. 4601 nodes still misclassified out of torch.Size([12904]) \n",
      "\n",
      "Model# 2. 4601 nodes still misclassified out of torch.Size([12904]) \n",
      "\n",
      "Model# 3. 4601 nodes still misclassified out of torch.Size([12904]) \n",
      "\n",
      "Model# 4. 4601 nodes still misclassified out of torch.Size([12904]) \n",
      "\n",
      "Model# 5. 4601 nodes still misclassified out of torch.Size([12904]) \n",
      "\n",
      "Model# 6. 4601 nodes still misclassified out of torch.Size([12904]) \n",
      "\n",
      "Model# 7. 4601 nodes still misclassified out of torch.Size([12904]) \n",
      "\n",
      "Model# 8. 4601 nodes still misclassified out of torch.Size([12904]) \n",
      "\n",
      "Model# 9. 4601 nodes still misclassified out of torch.Size([12904]) \n",
      "\n",
      "Model# 10. 4601 nodes still misclassified out of torch.Size([12904]) \n",
      "\n",
      "Model# 11. 4601 nodes still misclassified out of torch.Size([12904]) \n",
      "\n",
      "Model# 12. 4601 nodes still misclassified out of torch.Size([12904]) \n",
      "\n",
      "Model# 13. 4601 nodes still misclassified out of torch.Size([12904]) \n",
      "\n",
      "Model# 14. 4601 nodes still misclassified out of torch.Size([12904]) \n",
      "\n",
      "Model# 15. 4601 nodes still misclassified out of torch.Size([12904]) \n",
      "\n",
      "Model# 16. 4601 nodes still misclassified out of torch.Size([12904]) \n",
      "\n",
      "Model# 17. 4601 nodes still misclassified out of torch.Size([12904]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 155/299 [01:32<01:34,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 18. 4601 nodes still misclassified out of torch.Size([12904]) \n",
      "\n",
      "Model# 19. 4601 nodes still misclassified out of torch.Size([12904]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12446/12446 [00:00<00:00, 3583108.49it/s]\n",
      "100%|██████████| 12446/12446 [00:00<00:00, 4371320.35it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2366054.04it/s]\n",
      "Inferring Phrases: 100%|██████████| 12446/12446 [00:00<00:00, 315082.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4329 nodes still misclassified out of torch.Size([12446]) \n",
      "\n",
      "Model# 1. 4329 nodes still misclassified out of torch.Size([12446]) \n",
      "\n",
      "Model# 2. 4329 nodes still misclassified out of torch.Size([12446]) \n",
      "\n",
      "Model# 3. 4329 nodes still misclassified out of torch.Size([12446]) \n",
      "\n",
      "Model# 4. 4329 nodes still misclassified out of torch.Size([12446]) \n",
      "\n",
      "Model# 5. 4329 nodes still misclassified out of torch.Size([12446]) \n",
      "\n",
      "Model# 6. 4329 nodes still misclassified out of torch.Size([12446]) \n",
      "\n",
      "Model# 7. 4329 nodes still misclassified out of torch.Size([12446]) \n",
      "\n",
      "Model# 8. 4329 nodes still misclassified out of torch.Size([12446]) \n",
      "\n",
      "Model# 9. 4329 nodes still misclassified out of torch.Size([12446]) \n",
      "\n",
      "Model# 10. 4329 nodes still misclassified out of torch.Size([12446]) \n",
      "\n",
      "Model# 11. 4329 nodes still misclassified out of torch.Size([12446]) \n",
      "\n",
      "Model# 12. 4329 nodes still misclassified out of torch.Size([12446]) \n",
      "\n",
      "Model# 13. 4329 nodes still misclassified out of torch.Size([12446]) \n",
      "\n",
      "Model# 14. 4329 nodes still misclassified out of torch.Size([12446]) \n",
      "\n",
      "Model# 15. 4329 nodes still misclassified out of torch.Size([12446]) \n",
      "\n",
      "Model# 16. 4329 nodes still misclassified out of torch.Size([12446]) \n",
      "\n",
      "Model# 17. 4329 nodes still misclassified out of torch.Size([12446]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 156/299 [01:32<01:25,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 18. 4329 nodes still misclassified out of torch.Size([12446]) \n",
      "\n",
      "Model# 19. 4329 nodes still misclassified out of torch.Size([12446]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12723/12723 [00:00<00:00, 3518204.76it/s]\n",
      "100%|██████████| 12723/12723 [00:00<00:00, 4395727.33it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2404898.90it/s]\n",
      "Inferring Phrases: 100%|██████████| 12723/12723 [00:00<00:00, 387601.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3501 nodes still misclassified out of torch.Size([12723]) \n",
      "\n",
      "Model# 1. 3501 nodes still misclassified out of torch.Size([12723]) \n",
      "\n",
      "Model# 2. 3501 nodes still misclassified out of torch.Size([12723]) \n",
      "\n",
      "Model# 3. 3501 nodes still misclassified out of torch.Size([12723]) \n",
      "\n",
      "Model# 4. 3501 nodes still misclassified out of torch.Size([12723]) \n",
      "\n",
      "Model# 5. 3501 nodes still misclassified out of torch.Size([12723]) \n",
      "\n",
      "Model# 6. 3501 nodes still misclassified out of torch.Size([12723]) \n",
      "\n",
      "Model# 7. 3501 nodes still misclassified out of torch.Size([12723]) \n",
      "\n",
      "Model# 8. 3501 nodes still misclassified out of torch.Size([12723]) \n",
      "\n",
      "Model# 9. 3501 nodes still misclassified out of torch.Size([12723]) \n",
      "\n",
      "Model# 10. 3501 nodes still misclassified out of torch.Size([12723]) \n",
      "\n",
      "Model# 11. 3501 nodes still misclassified out of torch.Size([12723]) \n",
      "\n",
      "Model# 12. 3501 nodes still misclassified out of torch.Size([12723]) \n",
      "\n",
      "Model# 13. 3501 nodes still misclassified out of torch.Size([12723]) \n",
      "\n",
      "Model# 14. 3501 nodes still misclassified out of torch.Size([12723]) \n",
      "\n",
      "Model# 15. 3501 nodes still misclassified out of torch.Size([12723]) \n",
      "\n",
      "Model# 16. 3501 nodes still misclassified out of torch.Size([12723]) \n",
      "\n",
      "Model# 17. 3501 nodes still misclassified out of torch.Size([12723]) \n",
      "\n",
      "Model# 18. 3501 nodes still misclassified out of torch.Size([12723]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 157/299 [01:33<01:26,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 3501 nodes still misclassified out of torch.Size([12723]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13198/13198 [00:00<00:00, 3702027.97it/s]\n",
      "100%|██████████| 13198/13198 [00:00<00:00, 4587422.24it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2356085.83it/s]\n",
      "Inferring Phrases: 100%|██████████| 13198/13198 [00:00<00:00, 369089.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4246 nodes still misclassified out of torch.Size([13198]) \n",
      "\n",
      "Model# 1. 4246 nodes still misclassified out of torch.Size([13198]) \n",
      "\n",
      "Model# 2. 4246 nodes still misclassified out of torch.Size([13198]) \n",
      "\n",
      "Model# 3. 4246 nodes still misclassified out of torch.Size([13198]) \n",
      "\n",
      "Model# 4. 4246 nodes still misclassified out of torch.Size([13198]) \n",
      "\n",
      "Model# 5. 4246 nodes still misclassified out of torch.Size([13198]) \n",
      "\n",
      "Model# 6. 4246 nodes still misclassified out of torch.Size([13198]) \n",
      "\n",
      "Model# 7. 4246 nodes still misclassified out of torch.Size([13198]) \n",
      "\n",
      "Model# 8. 4246 nodes still misclassified out of torch.Size([13198]) \n",
      "\n",
      "Model# 9. 4246 nodes still misclassified out of torch.Size([13198]) \n",
      "\n",
      "Model# 10. 4246 nodes still misclassified out of torch.Size([13198]) \n",
      "\n",
      "Model# 11. 4246 nodes still misclassified out of torch.Size([13198]) \n",
      "\n",
      "Model# 12. 4246 nodes still misclassified out of torch.Size([13198]) \n",
      "\n",
      "Model# 13. 4246 nodes still misclassified out of torch.Size([13198]) \n",
      "\n",
      "Model# 14. 4246 nodes still misclassified out of torch.Size([13198]) \n",
      "\n",
      "Model# 15. 4246 nodes still misclassified out of torch.Size([13198]) \n",
      "\n",
      "Model# 16. 4246 nodes still misclassified out of torch.Size([13198]) \n",
      "\n",
      "Model# 17. 4246 nodes still misclassified out of torch.Size([13198]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 158/299 [01:34<01:19,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 18. 4246 nodes still misclassified out of torch.Size([13198]) \n",
      "\n",
      "Model# 19. 4246 nodes still misclassified out of torch.Size([13198]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12954/12954 [00:00<00:00, 2128286.03it/s]\n",
      "100%|██████████| 12954/12954 [00:00<00:00, 2827488.24it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2103427.22it/s]\n",
      "Inferring Phrases: 100%|██████████| 12954/12954 [00:00<00:00, 404760.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4616 nodes still misclassified out of torch.Size([12954]) \n",
      "\n",
      "Model# 1. 4616 nodes still misclassified out of torch.Size([12954]) \n",
      "\n",
      "Model# 2. 4616 nodes still misclassified out of torch.Size([12954]) \n",
      "\n",
      "Model# 3. 4616 nodes still misclassified out of torch.Size([12954]) \n",
      "\n",
      "Model# 4. 4616 nodes still misclassified out of torch.Size([12954]) \n",
      "\n",
      "Model# 5. 4616 nodes still misclassified out of torch.Size([12954]) \n",
      "\n",
      "Model# 6. 4616 nodes still misclassified out of torch.Size([12954]) \n",
      "\n",
      "Model# 7. 4616 nodes still misclassified out of torch.Size([12954]) \n",
      "\n",
      "Model# 8. 4616 nodes still misclassified out of torch.Size([12954]) \n",
      "\n",
      "Model# 9. 4616 nodes still misclassified out of torch.Size([12954]) \n",
      "\n",
      "Model# 10. 4616 nodes still misclassified out of torch.Size([12954]) \n",
      "\n",
      "Model# 11. 4616 nodes still misclassified out of torch.Size([12954]) \n",
      "\n",
      "Model# 12. 4616 nodes still misclassified out of torch.Size([12954]) \n",
      "\n",
      "Model# 13. 4616 nodes still misclassified out of torch.Size([12954]) \n",
      "\n",
      "Model# 14. 4616 nodes still misclassified out of torch.Size([12954]) \n",
      "\n",
      "Model# 15. 4616 nodes still misclassified out of torch.Size([12954]) \n",
      "\n",
      "Model# 16. 4616 nodes still misclassified out of torch.Size([12954]) \n",
      "\n",
      "Model# 17. 4616 nodes still misclassified out of torch.Size([12954]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 159/299 [01:34<01:16,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 18. 4616 nodes still misclassified out of torch.Size([12954]) \n",
      "\n",
      "Model# 19. 4616 nodes still misclassified out of torch.Size([12954]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12677/12677 [00:00<00:00, 3527812.62it/s]\n",
      "100%|██████████| 12677/12677 [00:00<00:00, 4154323.92it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2244503.67it/s]\n",
      "Inferring Phrases: 100%|██████████| 12677/12677 [00:00<00:00, 361575.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4683 nodes still misclassified out of torch.Size([12677]) \n",
      "\n",
      "Model# 1. 4683 nodes still misclassified out of torch.Size([12677]) \n",
      "\n",
      "Model# 2. 4683 nodes still misclassified out of torch.Size([12677]) \n",
      "\n",
      "Model# 3. 4683 nodes still misclassified out of torch.Size([12677]) \n",
      "\n",
      "Model# 4. 4683 nodes still misclassified out of torch.Size([12677]) \n",
      "\n",
      "Model# 5. 4683 nodes still misclassified out of torch.Size([12677]) \n",
      "\n",
      "Model# 6. 4683 nodes still misclassified out of torch.Size([12677]) \n",
      "\n",
      "Model# 7. 4683 nodes still misclassified out of torch.Size([12677]) \n",
      "\n",
      "Model# 8. 4683 nodes still misclassified out of torch.Size([12677]) \n",
      "\n",
      "Model# 9. 4683 nodes still misclassified out of torch.Size([12677]) \n",
      "\n",
      "Model# 10. 4683 nodes still misclassified out of torch.Size([12677]) \n",
      "\n",
      "Model# 11. 4683 nodes still misclassified out of torch.Size([12677]) \n",
      "\n",
      "Model# 12. 4683 nodes still misclassified out of torch.Size([12677]) \n",
      "\n",
      "Model# 13. 4683 nodes still misclassified out of torch.Size([12677]) \n",
      "\n",
      "Model# 14. 4683 nodes still misclassified out of torch.Size([12677]) \n",
      "\n",
      "Model# 15. 4683 nodes still misclassified out of torch.Size([12677]) \n",
      "\n",
      "Model# 16. 4683 nodes still misclassified out of torch.Size([12677]) \n",
      "\n",
      "Model# 17. 4683 nodes still misclassified out of torch.Size([12677]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 160/299 [01:35<01:21,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 18. 4683 nodes still misclassified out of torch.Size([12677]) \n",
      "\n",
      "Model# 19. 4683 nodes still misclassified out of torch.Size([12677]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12683/12683 [00:00<00:00, 2423524.27it/s]\n",
      "100%|██████████| 12683/12683 [00:00<00:00, 2915028.64it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2412645.63it/s]\n",
      "Inferring Phrases: 100%|██████████| 12683/12683 [00:00<00:00, 389528.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4625 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 1. 4625 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 2. 4625 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 3. 4625 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 4. 4625 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 5. 4625 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 6. 4625 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 7. 4625 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 8. 4625 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 9. 4625 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 10. 4625 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 11. 4625 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 12. 4625 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 13. 4625 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 14. 4625 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 15. 4625 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 16. 4625 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 17. 4625 nodes still misclassified out of torch.Size([12683]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 161/299 [01:35<01:16,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 18. 4625 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 19. 4625 nodes still misclassified out of torch.Size([12683]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12561/12561 [00:00<00:00, 3689659.82it/s]\n",
      "100%|██████████| 12561/12561 [00:00<00:00, 4516859.79it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2444993.00it/s]\n",
      "Inferring Phrases: 100%|██████████| 12561/12561 [00:00<00:00, 363861.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4364 nodes still misclassified out of torch.Size([12561]) \n",
      "\n",
      "Model# 1. 4364 nodes still misclassified out of torch.Size([12561]) \n",
      "\n",
      "Model# 2. 4364 nodes still misclassified out of torch.Size([12561]) \n",
      "\n",
      "Model# 3. 4364 nodes still misclassified out of torch.Size([12561]) \n",
      "\n",
      "Model# 4. 4364 nodes still misclassified out of torch.Size([12561]) \n",
      "\n",
      "Model# 5. 4364 nodes still misclassified out of torch.Size([12561]) \n",
      "\n",
      "Model# 6. 4364 nodes still misclassified out of torch.Size([12561]) \n",
      "\n",
      "Model# 7. 4364 nodes still misclassified out of torch.Size([12561]) \n",
      "\n",
      "Model# 8. 4364 nodes still misclassified out of torch.Size([12561]) \n",
      "\n",
      "Model# 9. 4364 nodes still misclassified out of torch.Size([12561]) \n",
      "\n",
      "Model# 10. 4364 nodes still misclassified out of torch.Size([12561]) \n",
      "\n",
      "Model# 11. 4364 nodes still misclassified out of torch.Size([12561]) \n",
      "\n",
      "Model# 12. 4364 nodes still misclassified out of torch.Size([12561]) \n",
      "\n",
      "Model# 13. 4364 nodes still misclassified out of torch.Size([12561]) \n",
      "\n",
      "Model# 14. 4364 nodes still misclassified out of torch.Size([12561]) \n",
      "\n",
      "Model# 15. 4364 nodes still misclassified out of torch.Size([12561]) \n",
      "\n",
      "Model# 16. 4364 nodes still misclassified out of torch.Size([12561]) \n",
      "\n",
      "Model# 17. 4364 nodes still misclassified out of torch.Size([12561]) \n",
      "\n",
      "Model# 18. 4364 nodes still misclassified out of torch.Size([12561]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 162/299 [01:36<01:12,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4364 nodes still misclassified out of torch.Size([12561]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12784/12784 [00:00<00:00, 3985430.53it/s]\n",
      "100%|██████████| 12784/12784 [00:00<00:00, 4946492.84it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2331636.96it/s]\n",
      "Inferring Phrases: 100%|██████████| 12784/12784 [00:00<00:00, 397135.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4645 nodes still misclassified out of torch.Size([12784]) \n",
      "\n",
      "Model# 1. 4645 nodes still misclassified out of torch.Size([12784]) \n",
      "\n",
      "Model# 2. 4645 nodes still misclassified out of torch.Size([12784]) \n",
      "\n",
      "Model# 3. 4645 nodes still misclassified out of torch.Size([12784]) \n",
      "\n",
      "Model# 4. 4645 nodes still misclassified out of torch.Size([12784]) \n",
      "\n",
      "Model# 5. 4645 nodes still misclassified out of torch.Size([12784]) \n",
      "\n",
      "Model# 6. 4645 nodes still misclassified out of torch.Size([12784]) \n",
      "\n",
      "Model# 7. 4645 nodes still misclassified out of torch.Size([12784]) \n",
      "\n",
      "Model# 8. 4645 nodes still misclassified out of torch.Size([12784]) \n",
      "\n",
      "Model# 9. 4645 nodes still misclassified out of torch.Size([12784]) \n",
      "\n",
      "Model# 10. 4645 nodes still misclassified out of torch.Size([12784]) \n",
      "\n",
      "Model# 11. 4645 nodes still misclassified out of torch.Size([12784]) \n",
      "\n",
      "Model# 12. 4645 nodes still misclassified out of torch.Size([12784]) \n",
      "\n",
      "Model# 13. 4645 nodes still misclassified out of torch.Size([12784]) \n",
      "\n",
      "Model# 14. 4645 nodes still misclassified out of torch.Size([12784]) \n",
      "\n",
      "Model# 15. 4645 nodes still misclassified out of torch.Size([12784]) \n",
      "\n",
      "Model# 16. 4645 nodes still misclassified out of torch.Size([12784]) \n",
      "\n",
      "Model# 17. 4645 nodes still misclassified out of torch.Size([12784]) \n",
      "\n",
      "Model# 18. 4645 nodes still misclassified out of torch.Size([12784]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 163/299 [01:36<01:16,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4645 nodes still misclassified out of torch.Size([12784]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12508/12508 [00:00<00:00, 3377477.27it/s]\n",
      "100%|██████████| 12508/12508 [00:00<00:00, 4399358.86it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2319131.54it/s]\n",
      "Inferring Phrases: 100%|██████████| 12508/12508 [00:00<00:00, 351125.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4582 nodes still misclassified out of torch.Size([12508]) \n",
      "\n",
      "Model# 1. 4582 nodes still misclassified out of torch.Size([12508]) \n",
      "\n",
      "Model# 2. 4582 nodes still misclassified out of torch.Size([12508]) \n",
      "\n",
      "Model# 3. 4582 nodes still misclassified out of torch.Size([12508]) \n",
      "\n",
      "Model# 4. 4582 nodes still misclassified out of torch.Size([12508]) \n",
      "\n",
      "Model# 5. 4582 nodes still misclassified out of torch.Size([12508]) \n",
      "\n",
      "Model# 6. 4582 nodes still misclassified out of torch.Size([12508]) \n",
      "\n",
      "Model# 7. 4582 nodes still misclassified out of torch.Size([12508]) \n",
      "\n",
      "Model# 8. 4582 nodes still misclassified out of torch.Size([12508]) \n",
      "\n",
      "Model# 9. 4582 nodes still misclassified out of torch.Size([12508]) \n",
      "\n",
      "Model# 10. 4582 nodes still misclassified out of torch.Size([12508]) \n",
      "\n",
      "Model# 11. 4582 nodes still misclassified out of torch.Size([12508]) \n",
      "\n",
      "Model# 12. 4582 nodes still misclassified out of torch.Size([12508]) \n",
      "\n",
      "Model# 13. 4582 nodes still misclassified out of torch.Size([12508]) \n",
      "\n",
      "Model# 14. 4582 nodes still misclassified out of torch.Size([12508]) \n",
      "\n",
      "Model# 15. 4582 nodes still misclassified out of torch.Size([12508]) \n",
      "\n",
      "Model# 16. 4582 nodes still misclassified out of torch.Size([12508]) \n",
      "\n",
      "Model# 17. 4582 nodes still misclassified out of torch.Size([12508]) \n",
      "\n",
      "Model# 18. 4582 nodes still misclassified out of torch.Size([12508]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 164/299 [01:37<01:10,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4582 nodes still misclassified out of torch.Size([12508]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13121/13121 [00:00<00:00, 3121403.37it/s]\n",
      "100%|██████████| 13121/13121 [00:00<00:00, 4399861.11it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2419976.92it/s]\n",
      "Inferring Phrases: 100%|██████████| 13121/13121 [00:00<00:00, 384191.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4545 nodes still misclassified out of torch.Size([13121]) \n",
      "\n",
      "Model# 1. 4545 nodes still misclassified out of torch.Size([13121]) \n",
      "\n",
      "Model# 2. 4545 nodes still misclassified out of torch.Size([13121]) \n",
      "\n",
      "Model# 3. 4545 nodes still misclassified out of torch.Size([13121]) \n",
      "\n",
      "Model# 4. 4545 nodes still misclassified out of torch.Size([13121]) \n",
      "\n",
      "Model# 5. 4545 nodes still misclassified out of torch.Size([13121]) \n",
      "\n",
      "Model# 6. 4545 nodes still misclassified out of torch.Size([13121]) \n",
      "\n",
      "Model# 7. 4545 nodes still misclassified out of torch.Size([13121]) \n",
      "\n",
      "Model# 8. 4545 nodes still misclassified out of torch.Size([13121]) \n",
      "\n",
      "Model# 9. 4545 nodes still misclassified out of torch.Size([13121]) \n",
      "\n",
      "Model# 10. 4545 nodes still misclassified out of torch.Size([13121]) \n",
      "\n",
      "Model# 11. 4545 nodes still misclassified out of torch.Size([13121]) \n",
      "\n",
      "Model# 12. 4545 nodes still misclassified out of torch.Size([13121]) \n",
      "\n",
      "Model# 13. 4545 nodes still misclassified out of torch.Size([13121]) \n",
      "\n",
      "Model# 14. 4545 nodes still misclassified out of torch.Size([13121]) \n",
      "\n",
      "Model# 15. 4545 nodes still misclassified out of torch.Size([13121]) \n",
      "\n",
      "Model# 16. 4545 nodes still misclassified out of torch.Size([13121]) \n",
      "\n",
      "Model# 17. 4545 nodes still misclassified out of torch.Size([13121]) \n",
      "\n",
      "Model# 18. 4545 nodes still misclassified out of torch.Size([13121]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 165/299 [01:37<01:15,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4545 nodes still misclassified out of torch.Size([13121]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13579/13579 [00:00<00:00, 3296166.10it/s]\n",
      "100%|██████████| 13579/13579 [00:00<00:00, 4247479.60it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2336876.59it/s]\n",
      "Inferring Phrases: 100%|██████████| 13579/13579 [00:00<00:00, 376797.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4922 nodes still misclassified out of torch.Size([13579]) \n",
      "\n",
      "Model# 1. 4922 nodes still misclassified out of torch.Size([13579]) \n",
      "\n",
      "Model# 2. 4922 nodes still misclassified out of torch.Size([13579]) \n",
      "\n",
      "Model# 3. 4922 nodes still misclassified out of torch.Size([13579]) \n",
      "\n",
      "Model# 4. 4922 nodes still misclassified out of torch.Size([13579]) \n",
      "\n",
      "Model# 5. 4922 nodes still misclassified out of torch.Size([13579]) \n",
      "\n",
      "Model# 6. 4922 nodes still misclassified out of torch.Size([13579]) \n",
      "\n",
      "Model# 7. 4922 nodes still misclassified out of torch.Size([13579]) \n",
      "\n",
      "Model# 8. 4922 nodes still misclassified out of torch.Size([13579]) \n",
      "\n",
      "Model# 9. 4922 nodes still misclassified out of torch.Size([13579]) \n",
      "\n",
      "Model# 10. 4922 nodes still misclassified out of torch.Size([13579]) \n",
      "\n",
      "Model# 11. 4922 nodes still misclassified out of torch.Size([13579]) \n",
      "\n",
      "Model# 12. 4922 nodes still misclassified out of torch.Size([13579]) \n",
      "\n",
      "Model# 13. 4922 nodes still misclassified out of torch.Size([13579]) \n",
      "\n",
      "Model# 14. 4922 nodes still misclassified out of torch.Size([13579]) \n",
      "\n",
      "Model# 15. 4922 nodes still misclassified out of torch.Size([13579]) \n",
      "\n",
      "Model# 16. 4922 nodes still misclassified out of torch.Size([13579]) \n",
      "\n",
      "Model# 17. 4922 nodes still misclassified out of torch.Size([13579]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 166/299 [01:38<01:10,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 18. 4922 nodes still misclassified out of torch.Size([13579]) \n",
      "\n",
      "Model# 19. 4922 nodes still misclassified out of torch.Size([13579]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12617/12617 [00:00<00:00, 2539446.88it/s]\n",
      "100%|██████████| 12617/12617 [00:00<00:00, 2938341.68it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1667560.60it/s]\n",
      "Inferring Phrases: 100%|██████████| 12617/12617 [00:00<00:00, 278544.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4562 nodes still misclassified out of torch.Size([12617]) \n",
      "\n",
      "Model# 1. 4562 nodes still misclassified out of torch.Size([12617]) \n",
      "\n",
      "Model# 2. 4562 nodes still misclassified out of torch.Size([12617]) \n",
      "\n",
      "Model# 3. 4562 nodes still misclassified out of torch.Size([12617]) \n",
      "\n",
      "Model# 4. 4562 nodes still misclassified out of torch.Size([12617]) \n",
      "\n",
      "Model# 5. 4562 nodes still misclassified out of torch.Size([12617]) \n",
      "\n",
      "Model# 6. 4562 nodes still misclassified out of torch.Size([12617]) \n",
      "\n",
      "Model# 7. 4562 nodes still misclassified out of torch.Size([12617]) \n",
      "\n",
      "Model# 8. 4562 nodes still misclassified out of torch.Size([12617]) \n",
      "\n",
      "Model# 9. 4562 nodes still misclassified out of torch.Size([12617]) \n",
      "\n",
      "Model# 10. 4562 nodes still misclassified out of torch.Size([12617]) \n",
      "\n",
      "Model# 11. 4562 nodes still misclassified out of torch.Size([12617]) \n",
      "\n",
      "Model# 12. 4562 nodes still misclassified out of torch.Size([12617]) \n",
      "\n",
      "Model# 13. 4562 nodes still misclassified out of torch.Size([12617]) \n",
      "\n",
      "Model# 14. 4562 nodes still misclassified out of torch.Size([12617]) \n",
      "\n",
      "Model# 15. 4562 nodes still misclassified out of torch.Size([12617]) \n",
      "\n",
      "Model# 16. 4562 nodes still misclassified out of torch.Size([12617]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 167/299 [01:38<01:08,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 17. 4562 nodes still misclassified out of torch.Size([12617]) \n",
      "\n",
      "Model# 18. 4562 nodes still misclassified out of torch.Size([12617]) \n",
      "\n",
      "Model# 19. 4562 nodes still misclassified out of torch.Size([12617]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12455/12455 [00:00<00:00, 3584715.32it/s]\n",
      "100%|██████████| 12455/12455 [00:00<00:00, 4785640.92it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2453144.09it/s]\n",
      "Inferring Phrases: 100%|██████████| 12455/12455 [00:00<00:00, 386676.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4456 nodes still misclassified out of torch.Size([12455]) \n",
      "\n",
      "Model# 1. 4456 nodes still misclassified out of torch.Size([12455]) \n",
      "\n",
      "Model# 2. 4456 nodes still misclassified out of torch.Size([12455]) \n",
      "\n",
      "Model# 3. 4456 nodes still misclassified out of torch.Size([12455]) \n",
      "\n",
      "Model# 4. 4456 nodes still misclassified out of torch.Size([12455]) \n",
      "\n",
      "Model# 5. 4456 nodes still misclassified out of torch.Size([12455]) \n",
      "\n",
      "Model# 6. 4456 nodes still misclassified out of torch.Size([12455]) \n",
      "\n",
      "Model# 7. 4456 nodes still misclassified out of torch.Size([12455]) \n",
      "\n",
      "Model# 8. 4456 nodes still misclassified out of torch.Size([12455]) \n",
      "\n",
      "Model# 9. 4456 nodes still misclassified out of torch.Size([12455]) \n",
      "\n",
      "Model# 10. 4456 nodes still misclassified out of torch.Size([12455]) \n",
      "\n",
      "Model# 11. 4456 nodes still misclassified out of torch.Size([12455]) \n",
      "\n",
      "Model# 12. 4456 nodes still misclassified out of torch.Size([12455]) \n",
      "\n",
      "Model# 13. 4456 nodes still misclassified out of torch.Size([12455]) \n",
      "\n",
      "Model# 14. 4456 nodes still misclassified out of torch.Size([12455]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 168/299 [01:39<01:20,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4456 nodes still misclassified out of torch.Size([12455]) \n",
      "\n",
      "Model# 16. 4456 nodes still misclassified out of torch.Size([12455]) \n",
      "\n",
      "Model# 17. 4456 nodes still misclassified out of torch.Size([12455]) \n",
      "\n",
      "Model# 18. 4456 nodes still misclassified out of torch.Size([12455]) \n",
      "\n",
      "Model# 19. 4456 nodes still misclassified out of torch.Size([12455]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12532/12532 [00:00<00:00, 1766824.13it/s]\n",
      "100%|██████████| 12532/12532 [00:00<00:00, 2704415.40it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2350628.06it/s]\n",
      "Inferring Phrases: 100%|██████████| 12532/12532 [00:00<00:00, 366109.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4465 nodes still misclassified out of torch.Size([12532]) \n",
      "\n",
      "Model# 1. 4465 nodes still misclassified out of torch.Size([12532]) \n",
      "\n",
      "Model# 2. 4465 nodes still misclassified out of torch.Size([12532]) \n",
      "\n",
      "Model# 3. 4465 nodes still misclassified out of torch.Size([12532]) \n",
      "\n",
      "Model# 4. 4465 nodes still misclassified out of torch.Size([12532]) \n",
      "\n",
      "Model# 5. 4465 nodes still misclassified out of torch.Size([12532]) \n",
      "\n",
      "Model# 6. 4465 nodes still misclassified out of torch.Size([12532]) \n",
      "\n",
      "Model# 7. 4465 nodes still misclassified out of torch.Size([12532]) \n",
      "\n",
      "Model# 8. 4465 nodes still misclassified out of torch.Size([12532]) \n",
      "\n",
      "Model# 9. 4465 nodes still misclassified out of torch.Size([12532]) \n",
      "\n",
      "Model# 10. 4465 nodes still misclassified out of torch.Size([12532]) \n",
      "\n",
      "Model# 11. 4465 nodes still misclassified out of torch.Size([12532]) \n",
      "\n",
      "Model# 12. 4465 nodes still misclassified out of torch.Size([12532]) \n",
      "\n",
      "Model# 13. 4465 nodes still misclassified out of torch.Size([12532]) \n",
      "\n",
      "Model# 14. 4465 nodes still misclassified out of torch.Size([12532]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 169/299 [01:40<01:18,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4465 nodes still misclassified out of torch.Size([12532]) \n",
      "\n",
      "Model# 16. 4465 nodes still misclassified out of torch.Size([12532]) \n",
      "\n",
      "Model# 17. 4465 nodes still misclassified out of torch.Size([12532]) \n",
      "\n",
      "Model# 18. 4465 nodes still misclassified out of torch.Size([12532]) \n",
      "\n",
      "Model# 19. 4465 nodes still misclassified out of torch.Size([12532]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12528/12528 [00:00<00:00, 2641709.34it/s]\n",
      "100%|██████████| 12528/12528 [00:00<00:00, 2962855.40it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1921348.60it/s]\n",
      "Inferring Phrases: 100%|██████████| 12528/12528 [00:00<00:00, 384531.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4243 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 1. 4243 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 2. 4243 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 3. 4243 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 4. 4243 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 5. 4243 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 6. 4243 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 7. 4243 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 8. 4243 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 9. 4243 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 10. 4243 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 11. 4243 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 12. 4243 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 13. 4243 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 14. 4243 nodes still misclassified out of torch.Size([12528]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 170/299 [01:40<01:14,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4243 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 16. 4243 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 17. 4243 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 18. 4243 nodes still misclassified out of torch.Size([12528]) \n",
      "\n",
      "Model# 19. 4243 nodes still misclassified out of torch.Size([12528]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12579/12579 [00:00<00:00, 4086766.07it/s]\n",
      "100%|██████████| 12579/12579 [00:00<00:00, 5025254.79it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2729304.38it/s]\n",
      "Inferring Phrases: 100%|██████████| 12579/12579 [00:00<00:00, 404317.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4428 nodes still misclassified out of torch.Size([12579]) \n",
      "\n",
      "Model# 1. 4428 nodes still misclassified out of torch.Size([12579]) \n",
      "\n",
      "Model# 2. 4428 nodes still misclassified out of torch.Size([12579]) \n",
      "\n",
      "Model# 3. 4428 nodes still misclassified out of torch.Size([12579]) \n",
      "\n",
      "Model# 4. 4428 nodes still misclassified out of torch.Size([12579]) \n",
      "\n",
      "Model# 5. 4428 nodes still misclassified out of torch.Size([12579]) \n",
      "\n",
      "Model# 6. 4428 nodes still misclassified out of torch.Size([12579]) \n",
      "\n",
      "Model# 7. 4428 nodes still misclassified out of torch.Size([12579]) \n",
      "\n",
      "Model# 8. 4428 nodes still misclassified out of torch.Size([12579]) \n",
      "\n",
      "Model# 9. 4428 nodes still misclassified out of torch.Size([12579]) \n",
      "\n",
      "Model# 10. 4428 nodes still misclassified out of torch.Size([12579]) \n",
      "\n",
      "Model# 11. 4428 nodes still misclassified out of torch.Size([12579]) \n",
      "\n",
      "Model# 12. 4428 nodes still misclassified out of torch.Size([12579]) \n",
      "\n",
      "Model# 13. 4428 nodes still misclassified out of torch.Size([12579]) \n",
      "\n",
      "Model# 14. 4428 nodes still misclassified out of torch.Size([12579]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 171/299 [01:41<01:22,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4428 nodes still misclassified out of torch.Size([12579]) \n",
      "\n",
      "Model# 16. 4428 nodes still misclassified out of torch.Size([12579]) \n",
      "\n",
      "Model# 17. 4428 nodes still misclassified out of torch.Size([12579]) \n",
      "\n",
      "Model# 18. 4428 nodes still misclassified out of torch.Size([12579]) \n",
      "\n",
      "Model# 19. 4428 nodes still misclassified out of torch.Size([12579]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12438/12438 [00:00<00:00, 2465791.61it/s]\n",
      "100%|██████████| 12438/12438 [00:00<00:00, 2905042.50it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1928977.33it/s]\n",
      "Inferring Phrases: 100%|██████████| 12438/12438 [00:00<00:00, 348293.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4367 nodes still misclassified out of torch.Size([12438]) \n",
      "\n",
      "Model# 1. 4367 nodes still misclassified out of torch.Size([12438]) \n",
      "\n",
      "Model# 2. 4367 nodes still misclassified out of torch.Size([12438]) \n",
      "\n",
      "Model# 3. 4367 nodes still misclassified out of torch.Size([12438]) \n",
      "\n",
      "Model# 4. 4367 nodes still misclassified out of torch.Size([12438]) \n",
      "\n",
      "Model# 5. 4367 nodes still misclassified out of torch.Size([12438]) \n",
      "\n",
      "Model# 6. 4367 nodes still misclassified out of torch.Size([12438]) \n",
      "\n",
      "Model# 7. 4367 nodes still misclassified out of torch.Size([12438]) \n",
      "\n",
      "Model# 8. 4367 nodes still misclassified out of torch.Size([12438]) \n",
      "\n",
      "Model# 9. 4367 nodes still misclassified out of torch.Size([12438]) \n",
      "\n",
      "Model# 10. 4367 nodes still misclassified out of torch.Size([12438]) \n",
      "\n",
      "Model# 11. 4367 nodes still misclassified out of torch.Size([12438]) \n",
      "\n",
      "Model# 12. 4367 nodes still misclassified out of torch.Size([12438]) \n",
      "\n",
      "Model# 13. 4367 nodes still misclassified out of torch.Size([12438]) \n",
      "\n",
      "Model# 14. 4367 nodes still misclassified out of torch.Size([12438]) \n",
      "\n",
      "Model# 15. 4367 nodes still misclassified out of torch.Size([12438]) \n",
      "\n",
      "Model# 16. 4367 nodes still misclassified out of torch.Size([12438]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 172/299 [01:42<01:16,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 17. 4367 nodes still misclassified out of torch.Size([12438]) \n",
      "\n",
      "Model# 18. 4367 nodes still misclassified out of torch.Size([12438]) \n",
      "\n",
      "Model# 19. 4367 nodes still misclassified out of torch.Size([12438]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12484/12484 [00:00<00:00, 3938746.14it/s]\n",
      "100%|██████████| 12484/12484 [00:00<00:00, 2127140.52it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1576746.74it/s]\n",
      "Inferring Phrases: 100%|██████████| 12484/12484 [00:00<00:00, 240966.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4440 nodes still misclassified out of torch.Size([12484]) \n",
      "\n",
      "Model# 1. 4440 nodes still misclassified out of torch.Size([12484]) \n",
      "\n",
      "Model# 2. 4440 nodes still misclassified out of torch.Size([12484]) \n",
      "\n",
      "Model# 3. 4440 nodes still misclassified out of torch.Size([12484]) \n",
      "\n",
      "Model# 4. 4440 nodes still misclassified out of torch.Size([12484]) \n",
      "\n",
      "Model# 5. 4440 nodes still misclassified out of torch.Size([12484]) \n",
      "\n",
      "Model# 6. 4440 nodes still misclassified out of torch.Size([12484]) \n",
      "\n",
      "Model# 7. 4440 nodes still misclassified out of torch.Size([12484]) \n",
      "\n",
      "Model# 8. 4440 nodes still misclassified out of torch.Size([12484]) \n",
      "\n",
      "Model# 9. 4440 nodes still misclassified out of torch.Size([12484]) \n",
      "\n",
      "Model# 10. 4440 nodes still misclassified out of torch.Size([12484]) \n",
      "\n",
      "Model# 11. 4440 nodes still misclassified out of torch.Size([12484]) \n",
      "\n",
      "Model# 12. 4440 nodes still misclassified out of torch.Size([12484]) \n",
      "\n",
      "Model# 13. 4440 nodes still misclassified out of torch.Size([12484]) \n",
      "\n",
      "Model# 14. 4440 nodes still misclassified out of torch.Size([12484]) \n",
      "\n",
      "Model# 15. 4440 nodes still misclassified out of torch.Size([12484]) \n",
      "\n",
      "Model# 16. 4440 nodes still misclassified out of torch.Size([12484]) \n",
      "\n",
      "Model# 17. 4440 nodes still misclassified out of torch.Size([12484]) \n",
      "\n",
      "Model# 18. 4440 nodes still misclassified out of torch.Size([12484]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 173/299 [01:42<01:10,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4440 nodes still misclassified out of torch.Size([12484]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12628/12628 [00:00<00:00, 3039811.23it/s]\n",
      "100%|██████████| 12628/12628 [00:00<00:00, 3932413.02it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2696839.13it/s]\n",
      "Inferring Phrases: 100%|██████████| 12628/12628 [00:00<00:00, 394048.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4596 nodes still misclassified out of torch.Size([12628]) \n",
      "\n",
      "Model# 1. 4596 nodes still misclassified out of torch.Size([12628]) \n",
      "\n",
      "Model# 2. 4596 nodes still misclassified out of torch.Size([12628]) \n",
      "\n",
      "Model# 3. 4596 nodes still misclassified out of torch.Size([12628]) \n",
      "\n",
      "Model# 4. 4596 nodes still misclassified out of torch.Size([12628]) \n",
      "\n",
      "Model# 5. 4596 nodes still misclassified out of torch.Size([12628]) \n",
      "\n",
      "Model# 6. 4596 nodes still misclassified out of torch.Size([12628]) \n",
      "\n",
      "Model# 7. 4596 nodes still misclassified out of torch.Size([12628]) \n",
      "\n",
      "Model# 8. 4596 nodes still misclassified out of torch.Size([12628]) \n",
      "\n",
      "Model# 9. 4596 nodes still misclassified out of torch.Size([12628]) \n",
      "\n",
      "Model# 10. 4596 nodes still misclassified out of torch.Size([12628]) \n",
      "\n",
      "Model# 11. 4596 nodes still misclassified out of torch.Size([12628]) \n",
      "\n",
      "Model# 12. 4596 nodes still misclassified out of torch.Size([12628]) \n",
      "\n",
      "Model# 13. 4596 nodes still misclassified out of torch.Size([12628]) \n",
      "\n",
      "Model# 14. 4596 nodes still misclassified out of torch.Size([12628]) \n",
      "\n",
      "Model# 15. 4596 nodes still misclassified out of torch.Size([12628]) \n",
      "\n",
      "Model# 16. 4596 nodes still misclassified out of torch.Size([12628]) \n",
      "\n",
      "Model# 17. 4596 nodes still misclassified out of torch.Size([12628]) \n",
      "\n",
      "Model# 18. 4596 nodes still misclassified out of torch.Size([12628]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 174/299 [01:43<01:11,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4596 nodes still misclassified out of torch.Size([12628]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12834/12834 [00:00<00:00, 3944434.49it/s]\n",
      "100%|██████████| 12834/12834 [00:00<00:00, 4664214.33it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2745742.03it/s]\n",
      "Inferring Phrases: 100%|██████████| 12834/12834 [00:00<00:00, 379579.57it/s]\n",
      " 59%|█████▊    | 175/299 [01:43<01:04,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3361 nodes still misclassified out of torch.Size([12834]) \n",
      "\n",
      "Model# 1. 3361 nodes still misclassified out of torch.Size([12834]) \n",
      "\n",
      "Model# 2. 3361 nodes still misclassified out of torch.Size([12834]) \n",
      "\n",
      "Model# 3. 3361 nodes still misclassified out of torch.Size([12834]) \n",
      "\n",
      "Model# 4. 3361 nodes still misclassified out of torch.Size([12834]) \n",
      "\n",
      "Model# 5. 3361 nodes still misclassified out of torch.Size([12834]) \n",
      "\n",
      "Model# 6. 3361 nodes still misclassified out of torch.Size([12834]) \n",
      "\n",
      "Model# 7. 3361 nodes still misclassified out of torch.Size([12834]) \n",
      "\n",
      "Model# 8. 3361 nodes still misclassified out of torch.Size([12834]) \n",
      "\n",
      "Model# 9. 3361 nodes still misclassified out of torch.Size([12834]) \n",
      "\n",
      "Model# 10. 3361 nodes still misclassified out of torch.Size([12834]) \n",
      "\n",
      "Model# 11. 3361 nodes still misclassified out of torch.Size([12834]) \n",
      "\n",
      "Model# 12. 3361 nodes still misclassified out of torch.Size([12834]) \n",
      "\n",
      "Model# 13. 3361 nodes still misclassified out of torch.Size([12834]) \n",
      "\n",
      "Model# 14. 3361 nodes still misclassified out of torch.Size([12834]) \n",
      "\n",
      "Model# 15. 3361 nodes still misclassified out of torch.Size([12834]) \n",
      "\n",
      "Model# 16. 3361 nodes still misclassified out of torch.Size([12834]) \n",
      "\n",
      "Model# 17. 3361 nodes still misclassified out of torch.Size([12834]) \n",
      "\n",
      "Model# 18. 3361 nodes still misclassified out of torch.Size([12834]) \n",
      "\n",
      "Model# 19. 3361 nodes still misclassified out of torch.Size([12834]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12927/12927 [00:00<00:00, 3692438.56it/s]\n",
      "100%|██████████| 12927/12927 [00:00<00:00, 4851012.60it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2662205.01it/s]\n",
      "Inferring Phrases: 100%|██████████| 12927/12927 [00:00<00:00, 415149.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4329 nodes still misclassified out of torch.Size([12927]) \n",
      "\n",
      "Model# 1. 4329 nodes still misclassified out of torch.Size([12927]) \n",
      "\n",
      "Model# 2. 4329 nodes still misclassified out of torch.Size([12927]) \n",
      "\n",
      "Model# 3. 4329 nodes still misclassified out of torch.Size([12927]) \n",
      "\n",
      "Model# 4. 4329 nodes still misclassified out of torch.Size([12927]) \n",
      "\n",
      "Model# 5. 4329 nodes still misclassified out of torch.Size([12927]) \n",
      "\n",
      "Model# 6. 4329 nodes still misclassified out of torch.Size([12927]) \n",
      "\n",
      "Model# 7. 4329 nodes still misclassified out of torch.Size([12927]) \n",
      "\n",
      "Model# 8. 4329 nodes still misclassified out of torch.Size([12927]) \n",
      "\n",
      "Model# 9. 4329 nodes still misclassified out of torch.Size([12927]) \n",
      "\n",
      "Model# 10. 4329 nodes still misclassified out of torch.Size([12927]) \n",
      "\n",
      "Model# 11. 4329 nodes still misclassified out of torch.Size([12927]) \n",
      "\n",
      "Model# 12. 4329 nodes still misclassified out of torch.Size([12927]) \n",
      "\n",
      "Model# 13. 4329 nodes still misclassified out of torch.Size([12927]) \n",
      "\n",
      "Model# 14. 4329 nodes still misclassified out of torch.Size([12927]) \n",
      "\n",
      "Model# 15. 4329 nodes still misclassified out of torch.Size([12927]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 176/299 [01:44<01:08,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 16. 4329 nodes still misclassified out of torch.Size([12927]) \n",
      "\n",
      "Model# 17. 4329 nodes still misclassified out of torch.Size([12927]) \n",
      "\n",
      "Model# 18. 4329 nodes still misclassified out of torch.Size([12927]) \n",
      "\n",
      "Model# 19. 4329 nodes still misclassified out of torch.Size([12927]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14336/14336 [00:00<00:00, 3912900.51it/s]\n",
      "100%|██████████| 14336/14336 [00:00<00:00, 4754075.12it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2686704.53it/s]\n",
      "Inferring Phrases: 100%|██████████| 14336/14336 [00:00<00:00, 403947.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6227 nodes still misclassified out of torch.Size([14336]) \n",
      "\n",
      "Model# 1. 6227 nodes still misclassified out of torch.Size([14336]) \n",
      "\n",
      "Model# 2. 6227 nodes still misclassified out of torch.Size([14336]) \n",
      "\n",
      "Model# 3. 6227 nodes still misclassified out of torch.Size([14336]) \n",
      "\n",
      "Model# 4. 6227 nodes still misclassified out of torch.Size([14336]) \n",
      "\n",
      "Model# 5. 6227 nodes still misclassified out of torch.Size([14336]) \n",
      "\n",
      "Model# 6. 6227 nodes still misclassified out of torch.Size([14336]) \n",
      "\n",
      "Model# 7. 6227 nodes still misclassified out of torch.Size([14336]) \n",
      "\n",
      "Model# 8. 6227 nodes still misclassified out of torch.Size([14336]) \n",
      "\n",
      "Model# 9. 6227 nodes still misclassified out of torch.Size([14336]) \n",
      "\n",
      "Model# 10. 6227 nodes still misclassified out of torch.Size([14336]) \n",
      "\n",
      "Model# 11. 6227 nodes still misclassified out of torch.Size([14336]) \n",
      "\n",
      "Model# 12. 6227 nodes still misclassified out of torch.Size([14336]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 177/299 [01:44<01:06,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 13. 6227 nodes still misclassified out of torch.Size([14336]) \n",
      "\n",
      "Model# 14. 6227 nodes still misclassified out of torch.Size([14336]) \n",
      "\n",
      "Model# 15. 6227 nodes still misclassified out of torch.Size([14336]) \n",
      "\n",
      "Model# 16. 6227 nodes still misclassified out of torch.Size([14336]) \n",
      "\n",
      "Model# 17. 6227 nodes still misclassified out of torch.Size([14336]) \n",
      "\n",
      "Model# 18. 6227 nodes still misclassified out of torch.Size([14336]) \n",
      "\n",
      "Model# 19. 6227 nodes still misclassified out of torch.Size([14336]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15270/15270 [00:00<00:00, 3767250.28it/s]\n",
      "100%|██████████| 15270/15270 [00:00<00:00, 4579694.11it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2605265.64it/s]\n",
      "Inferring Phrases: 100%|██████████| 15270/15270 [00:00<00:00, 414659.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6838 nodes still misclassified out of torch.Size([15270]) \n",
      "\n",
      "Model# 1. 6838 nodes still misclassified out of torch.Size([15270]) \n",
      "\n",
      "Model# 2. 6838 nodes still misclassified out of torch.Size([15270]) \n",
      "\n",
      "Model# 3. 6838 nodes still misclassified out of torch.Size([15270]) \n",
      "\n",
      "Model# 4. 6838 nodes still misclassified out of torch.Size([15270]) \n",
      "\n",
      "Model# 5. 6838 nodes still misclassified out of torch.Size([15270]) \n",
      "\n",
      "Model# 6. 6838 nodes still misclassified out of torch.Size([15270]) \n",
      "\n",
      "Model# 7. 6838 nodes still misclassified out of torch.Size([15270]) \n",
      "\n",
      "Model# 8. 6838 nodes still misclassified out of torch.Size([15270]) \n",
      "\n",
      "Model# 9. 6838 nodes still misclassified out of torch.Size([15270]) \n",
      "\n",
      "Model# 10. 6838 nodes still misclassified out of torch.Size([15270]) \n",
      "\n",
      "Model# 11. 6838 nodes still misclassified out of torch.Size([15270]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 178/299 [01:45<01:05,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 12. 6838 nodes still misclassified out of torch.Size([15270]) \n",
      "\n",
      "Model# 13. 6838 nodes still misclassified out of torch.Size([15270]) \n",
      "\n",
      "Model# 14. 6838 nodes still misclassified out of torch.Size([15270]) \n",
      "\n",
      "Model# 15. 6838 nodes still misclassified out of torch.Size([15270]) \n",
      "\n",
      "Model# 16. 6838 nodes still misclassified out of torch.Size([15270]) \n",
      "\n",
      "Model# 17. 6838 nodes still misclassified out of torch.Size([15270]) \n",
      "\n",
      "Model# 18. 6838 nodes still misclassified out of torch.Size([15270]) \n",
      "\n",
      "Model# 19. 6838 nodes still misclassified out of torch.Size([15270]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14674/14674 [00:00<00:00, 4413885.32it/s]\n",
      "100%|██████████| 14674/14674 [00:00<00:00, 5039483.90it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2567050.62it/s]\n",
      "Inferring Phrases: 100%|██████████| 14674/14674 [00:00<00:00, 444560.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6114 nodes still misclassified out of torch.Size([14674]) \n",
      "\n",
      "Model# 1. 6114 nodes still misclassified out of torch.Size([14674]) \n",
      "\n",
      "Model# 2. 6114 nodes still misclassified out of torch.Size([14674]) \n",
      "\n",
      "Model# 3. 6114 nodes still misclassified out of torch.Size([14674]) \n",
      "\n",
      "Model# 4. 6114 nodes still misclassified out of torch.Size([14674]) \n",
      "\n",
      "Model# 5. 6114 nodes still misclassified out of torch.Size([14674]) \n",
      "\n",
      "Model# 6. 6114 nodes still misclassified out of torch.Size([14674]) \n",
      "\n",
      "Model# 7. 6114 nodes still misclassified out of torch.Size([14674]) \n",
      "\n",
      "Model# 8. 6114 nodes still misclassified out of torch.Size([14674]) \n",
      "\n",
      "Model# 9. 6114 nodes still misclassified out of torch.Size([14674]) \n",
      "\n",
      "Model# 10. 6114 nodes still misclassified out of torch.Size([14674]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 179/299 [01:46<01:12,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 6114 nodes still misclassified out of torch.Size([14674]) \n",
      "\n",
      "Model# 12. 6114 nodes still misclassified out of torch.Size([14674]) \n",
      "\n",
      "Model# 13. 6114 nodes still misclassified out of torch.Size([14674]) \n",
      "\n",
      "Model# 14. 6114 nodes still misclassified out of torch.Size([14674]) \n",
      "\n",
      "Model# 15. 6114 nodes still misclassified out of torch.Size([14674]) \n",
      "\n",
      "Model# 16. 6114 nodes still misclassified out of torch.Size([14674]) \n",
      "\n",
      "Model# 17. 6114 nodes still misclassified out of torch.Size([14674]) \n",
      "\n",
      "Model# 18. 6114 nodes still misclassified out of torch.Size([14674]) \n",
      "\n",
      "Model# 19. 6114 nodes still misclassified out of torch.Size([14674]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13181/13181 [00:00<00:00, 4023662.37it/s]\n",
      "100%|██████████| 13181/13181 [00:00<00:00, 4725627.92it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2728712.51it/s]\n",
      "Inferring Phrases: 100%|██████████| 13181/13181 [00:00<00:00, 382540.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3753 nodes still misclassified out of torch.Size([13181]) \n",
      "\n",
      "Model# 1. 3753 nodes still misclassified out of torch.Size([13181]) \n",
      "\n",
      "Model# 2. 3753 nodes still misclassified out of torch.Size([13181]) \n",
      "\n",
      "Model# 3. 3753 nodes still misclassified out of torch.Size([13181]) \n",
      "\n",
      "Model# 4. 3753 nodes still misclassified out of torch.Size([13181]) \n",
      "\n",
      "Model# 5. 3753 nodes still misclassified out of torch.Size([13181]) \n",
      "\n",
      "Model# 6. 3753 nodes still misclassified out of torch.Size([13181]) \n",
      "\n",
      "Model# 7. 3753 nodes still misclassified out of torch.Size([13181]) \n",
      "\n",
      "Model# 8. 3753 nodes still misclassified out of torch.Size([13181]) \n",
      "\n",
      "Model# 9. 3753 nodes still misclassified out of torch.Size([13181]) \n",
      "\n",
      "Model# 10. 3753 nodes still misclassified out of torch.Size([13181]) \n",
      "\n",
      "Model# 11. 3753 nodes still misclassified out of torch.Size([13181]) \n",
      "\n",
      "Model# 12. 3753 nodes still misclassified out of torch.Size([13181]) \n",
      "\n",
      "Model# 13. 3753 nodes still misclassified out of torch.Size([13181]) \n",
      "\n",
      "Model# 14. 3753 nodes still misclassified out of torch.Size([13181]) \n",
      "\n",
      "Model# 15. 3753 nodes still misclassified out of torch.Size([13181]) \n",
      "\n",
      "Model# 16. 3753 nodes still misclassified out of torch.Size([13181]) \n",
      "\n",
      "Model# 17. 3753 nodes still misclassified out of torch.Size([13181]) \n",
      "\n",
      "Model# 18. 3753 nodes still misclassified out of torch.Size([13181]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 180/299 [01:46<01:05,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 3753 nodes still misclassified out of torch.Size([13181]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13022/13022 [00:00<00:00, 3842835.90it/s]\n",
      "100%|██████████| 13022/13022 [00:00<00:00, 4506826.20it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2704839.21it/s]\n",
      "Inferring Phrases: 100%|██████████| 13022/13022 [00:00<00:00, 375272.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4808 nodes still misclassified out of torch.Size([13022]) \n",
      "\n",
      "Model# 1. 4808 nodes still misclassified out of torch.Size([13022]) \n",
      "\n",
      "Model# 2. 4808 nodes still misclassified out of torch.Size([13022]) \n",
      "\n",
      "Model# 3. 4808 nodes still misclassified out of torch.Size([13022]) \n",
      "\n",
      "Model# 4. 4808 nodes still misclassified out of torch.Size([13022]) \n",
      "\n",
      "Model# 5. 4808 nodes still misclassified out of torch.Size([13022]) \n",
      "\n",
      "Model# 6. 4808 nodes still misclassified out of torch.Size([13022]) \n",
      "\n",
      "Model# 7. 4808 nodes still misclassified out of torch.Size([13022]) \n",
      "\n",
      "Model# 8. 4808 nodes still misclassified out of torch.Size([13022]) \n",
      "\n",
      "Model# 9. 4808 nodes still misclassified out of torch.Size([13022]) \n",
      "\n",
      "Model# 10. 4808 nodes still misclassified out of torch.Size([13022]) \n",
      "\n",
      "Model# 11. 4808 nodes still misclassified out of torch.Size([13022]) \n",
      "\n",
      "Model# 12. 4808 nodes still misclassified out of torch.Size([13022]) \n",
      "\n",
      "Model# 13. 4808 nodes still misclassified out of torch.Size([13022]) \n",
      "\n",
      "Model# 14. 4808 nodes still misclassified out of torch.Size([13022]) \n",
      "\n",
      "Model# 15. 4808 nodes still misclassified out of torch.Size([13022]) \n",
      "\n",
      "Model# 16. 4808 nodes still misclassified out of torch.Size([13022]) \n",
      "\n",
      "Model# 17. 4808 nodes still misclassified out of torch.Size([13022]) \n",
      "\n",
      "Model# 18. 4808 nodes still misclassified out of torch.Size([13022]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 181/299 [01:46<01:00,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4808 nodes still misclassified out of torch.Size([13022]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12341/12341 [00:00<00:00, 4183456.37it/s]\n",
      "100%|██████████| 12341/12341 [00:00<00:00, 4739667.22it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2731259.39it/s]\n",
      "Inferring Phrases: 100%|██████████| 12341/12341 [00:00<00:00, 384735.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4204 nodes still misclassified out of torch.Size([12341]) \n",
      "\n",
      "Model# 1. 4204 nodes still misclassified out of torch.Size([12341]) \n",
      "\n",
      "Model# 2. 4204 nodes still misclassified out of torch.Size([12341]) \n",
      "\n",
      "Model# 3. 4204 nodes still misclassified out of torch.Size([12341]) \n",
      "\n",
      "Model# 4. 4204 nodes still misclassified out of torch.Size([12341]) \n",
      "\n",
      "Model# 5. 4204 nodes still misclassified out of torch.Size([12341]) \n",
      "\n",
      "Model# 6. 4204 nodes still misclassified out of torch.Size([12341]) \n",
      "\n",
      "Model# 7. 4204 nodes still misclassified out of torch.Size([12341]) \n",
      "\n",
      "Model# 8. 4204 nodes still misclassified out of torch.Size([12341]) \n",
      "\n",
      "Model# 9. 4204 nodes still misclassified out of torch.Size([12341]) \n",
      "\n",
      "Model# 10. 4204 nodes still misclassified out of torch.Size([12341]) \n",
      "\n",
      "Model# 11. 4204 nodes still misclassified out of torch.Size([12341]) \n",
      "\n",
      "Model# 12. 4204 nodes still misclassified out of torch.Size([12341]) \n",
      "\n",
      "Model# 13. 4204 nodes still misclassified out of torch.Size([12341]) \n",
      "\n",
      "Model# 14. 4204 nodes still misclassified out of torch.Size([12341]) \n",
      "\n",
      "Model# 15. 4204 nodes still misclassified out of torch.Size([12341]) \n",
      "\n",
      "Model# 16. 4204 nodes still misclassified out of torch.Size([12341]) \n",
      "\n",
      "Model# 17. 4204 nodes still misclassified out of torch.Size([12341]) \n",
      "\n",
      "Model# 18. 4204 nodes still misclassified out of torch.Size([12341]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 182/299 [01:47<01:05,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4204 nodes still misclassified out of torch.Size([12341]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11900/11900 [00:00<00:00, 3932882.96it/s]\n",
      "100%|██████████| 11900/11900 [00:00<00:00, 4571971.93it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2717280.76it/s]\n",
      "Inferring Phrases: 100%|██████████| 11900/11900 [00:00<00:00, 355378.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3779 nodes still misclassified out of torch.Size([11900]) \n",
      "\n",
      "Model# 1. 3779 nodes still misclassified out of torch.Size([11900]) \n",
      "\n",
      "Model# 2. 3779 nodes still misclassified out of torch.Size([11900]) \n",
      "\n",
      "Model# 3. 3779 nodes still misclassified out of torch.Size([11900]) \n",
      "\n",
      "Model# 4. 3779 nodes still misclassified out of torch.Size([11900]) \n",
      "\n",
      "Model# 5. 3779 nodes still misclassified out of torch.Size([11900]) \n",
      "\n",
      "Model# 6. 3779 nodes still misclassified out of torch.Size([11900]) \n",
      "\n",
      "Model# 7. 3779 nodes still misclassified out of torch.Size([11900]) \n",
      "\n",
      "Model# 8. 3779 nodes still misclassified out of torch.Size([11900]) \n",
      "\n",
      "Model# 9. 3779 nodes still misclassified out of torch.Size([11900]) \n",
      "\n",
      "Model# 10. 3779 nodes still misclassified out of torch.Size([11900]) \n",
      "\n",
      "Model# 11. 3779 nodes still misclassified out of torch.Size([11900]) \n",
      "\n",
      "Model# 12. 3779 nodes still misclassified out of torch.Size([11900]) \n",
      "\n",
      "Model# 13. 3779 nodes still misclassified out of torch.Size([11900]) \n",
      "\n",
      "Model# 14. 3779 nodes still misclassified out of torch.Size([11900]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 183/299 [01:48<01:01,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 3779 nodes still misclassified out of torch.Size([11900]) \n",
      "\n",
      "Model# 16. 3779 nodes still misclassified out of torch.Size([11900]) \n",
      "\n",
      "Model# 17. 3779 nodes still misclassified out of torch.Size([11900]) \n",
      "\n",
      "Model# 18. 3779 nodes still misclassified out of torch.Size([11900]) \n",
      "\n",
      "Model# 19. 3779 nodes still misclassified out of torch.Size([11900]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12000/12000 [00:00<00:00, 2651127.10it/s]\n",
      "100%|██████████| 12000/12000 [00:00<00:00, 2953561.88it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1942766.80it/s]\n",
      "Inferring Phrases: 100%|██████████| 12000/12000 [00:00<00:00, 347086.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4053 nodes still misclassified out of torch.Size([12000]) \n",
      "\n",
      "Model# 1. 4053 nodes still misclassified out of torch.Size([12000]) \n",
      "\n",
      "Model# 2. 4053 nodes still misclassified out of torch.Size([12000]) \n",
      "\n",
      "Model# 3. 4053 nodes still misclassified out of torch.Size([12000]) \n",
      "\n",
      "Model# 4. 4053 nodes still misclassified out of torch.Size([12000]) \n",
      "\n",
      "Model# 5. 4053 nodes still misclassified out of torch.Size([12000]) \n",
      "\n",
      "Model# 6. 4053 nodes still misclassified out of torch.Size([12000]) \n",
      "\n",
      "Model# 7. 4053 nodes still misclassified out of torch.Size([12000]) \n",
      "\n",
      "Model# 8. 4053 nodes still misclassified out of torch.Size([12000]) \n",
      "\n",
      "Model# 9. 4053 nodes still misclassified out of torch.Size([12000]) \n",
      "\n",
      "Model# 10. 4053 nodes still misclassified out of torch.Size([12000]) \n",
      "\n",
      "Model# 11. 4053 nodes still misclassified out of torch.Size([12000]) \n",
      "\n",
      "Model# 12. 4053 nodes still misclassified out of torch.Size([12000]) \n",
      "\n",
      "Model# 13. 4053 nodes still misclassified out of torch.Size([12000]) \n",
      "\n",
      "Model# 14. 4053 nodes still misclassified out of torch.Size([12000]) \n",
      "\n",
      "Model# 15. 4053 nodes still misclassified out of torch.Size([12000]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 184/299 [01:48<01:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 16. 4053 nodes still misclassified out of torch.Size([12000]) \n",
      "\n",
      "Model# 17. 4053 nodes still misclassified out of torch.Size([12000]) \n",
      "\n",
      "Model# 18. 4053 nodes still misclassified out of torch.Size([12000]) \n",
      "\n",
      "Model# 19. 4053 nodes still misclassified out of torch.Size([12000]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11496/11496 [00:00<00:00, 4382632.14it/s]\n",
      "100%|██████████| 11496/11496 [00:00<00:00, 5048975.79it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2799437.57it/s]\n",
      "Inferring Phrases: 100%|██████████| 11496/11496 [00:00<00:00, 384667.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3389 nodes still misclassified out of torch.Size([11496]) \n",
      "\n",
      "Model# 1. 3389 nodes still misclassified out of torch.Size([11496]) \n",
      "\n",
      "Model# 2. 3389 nodes still misclassified out of torch.Size([11496]) \n",
      "\n",
      "Model# 3. 3389 nodes still misclassified out of torch.Size([11496]) \n",
      "\n",
      "Model# 4. 3389 nodes still misclassified out of torch.Size([11496]) \n",
      "\n",
      "Model# 5. 3389 nodes still misclassified out of torch.Size([11496]) \n",
      "\n",
      "Model# 6. 3389 nodes still misclassified out of torch.Size([11496]) \n",
      "\n",
      "Model# 7. 3389 nodes still misclassified out of torch.Size([11496]) \n",
      "\n",
      "Model# 8. 3389 nodes still misclassified out of torch.Size([11496]) \n",
      "\n",
      "Model# 9. 3389 nodes still misclassified out of torch.Size([11496]) \n",
      "\n",
      "Model# 10. 3389 nodes still misclassified out of torch.Size([11496]) \n",
      "\n",
      "Model# 11. 3389 nodes still misclassified out of torch.Size([11496]) \n",
      "\n",
      "Model# 12. 3389 nodes still misclassified out of torch.Size([11496]) \n",
      "\n",
      "Model# 13. 3389 nodes still misclassified out of torch.Size([11496]) \n",
      "\n",
      "Model# 14. 3389 nodes still misclassified out of torch.Size([11496]) \n",
      "\n",
      "Model# 15. 3389 nodes still misclassified out of torch.Size([11496]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 185/299 [01:49<01:03,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 16. 3389 nodes still misclassified out of torch.Size([11496]) \n",
      "\n",
      "Model# 17. 3389 nodes still misclassified out of torch.Size([11496]) \n",
      "\n",
      "Model# 18. 3389 nodes still misclassified out of torch.Size([11496]) \n",
      "\n",
      "Model# 19. 3389 nodes still misclassified out of torch.Size([11496]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11753/11753 [00:00<00:00, 2672285.73it/s]\n",
      "100%|██████████| 11753/11753 [00:00<00:00, 2989427.22it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1989990.99it/s]\n",
      "Inferring Phrases: 100%|██████████| 11753/11753 [00:00<00:00, 337324.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3778 nodes still misclassified out of torch.Size([11753]) \n",
      "\n",
      "Model# 1. 3778 nodes still misclassified out of torch.Size([11753]) \n",
      "\n",
      "Model# 2. 3778 nodes still misclassified out of torch.Size([11753]) \n",
      "\n",
      "Model# 3. 3778 nodes still misclassified out of torch.Size([11753]) \n",
      "\n",
      "Model# 4. 3778 nodes still misclassified out of torch.Size([11753]) \n",
      "\n",
      "Model# 5. 3778 nodes still misclassified out of torch.Size([11753]) \n",
      "\n",
      "Model# 6. 3778 nodes still misclassified out of torch.Size([11753]) \n",
      "\n",
      "Model# 7. 3778 nodes still misclassified out of torch.Size([11753]) \n",
      "\n",
      "Model# 8. 3778 nodes still misclassified out of torch.Size([11753]) \n",
      "\n",
      "Model# 9. 3778 nodes still misclassified out of torch.Size([11753]) \n",
      "\n",
      "Model# 10. 3778 nodes still misclassified out of torch.Size([11753]) \n",
      "\n",
      "Model# 11. 3778 nodes still misclassified out of torch.Size([11753]) \n",
      "\n",
      "Model# 12. 3778 nodes still misclassified out of torch.Size([11753]) \n",
      "\n",
      "Model# 13. 3778 nodes still misclassified out of torch.Size([11753]) \n",
      "\n",
      "Model# 14. 3778 nodes still misclassified out of torch.Size([11753]) \n",
      "\n",
      "Model# 15. 3778 nodes still misclassified out of torch.Size([11753]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 186/299 [01:49<01:01,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 16. 3778 nodes still misclassified out of torch.Size([11753]) \n",
      "\n",
      "Model# 17. 3778 nodes still misclassified out of torch.Size([11753]) \n",
      "\n",
      "Model# 18. 3778 nodes still misclassified out of torch.Size([11753]) \n",
      "\n",
      "Model# 19. 3778 nodes still misclassified out of torch.Size([11753]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12018/12018 [00:00<00:00, 3774685.15it/s]\n",
      "100%|██████████| 12018/12018 [00:00<00:00, 4669922.69it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2607317.03it/s]\n",
      "Inferring Phrases: 100%|██████████| 12018/12018 [00:00<00:00, 378591.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4000 nodes still misclassified out of torch.Size([12018]) \n",
      "\n",
      "Model# 1. 4000 nodes still misclassified out of torch.Size([12018]) \n",
      "\n",
      "Model# 2. 4000 nodes still misclassified out of torch.Size([12018]) \n",
      "\n",
      "Model# 3. 4000 nodes still misclassified out of torch.Size([12018]) \n",
      "\n",
      "Model# 4. 4000 nodes still misclassified out of torch.Size([12018]) \n",
      "\n",
      "Model# 5. 4000 nodes still misclassified out of torch.Size([12018]) \n",
      "\n",
      "Model# 6. 4000 nodes still misclassified out of torch.Size([12018]) \n",
      "\n",
      "Model# 7. 4000 nodes still misclassified out of torch.Size([12018]) \n",
      "\n",
      "Model# 8. 4000 nodes still misclassified out of torch.Size([12018]) \n",
      "\n",
      "Model# 9. 4000 nodes still misclassified out of torch.Size([12018]) \n",
      "\n",
      "Model# 10. 4000 nodes still misclassified out of torch.Size([12018]) \n",
      "\n",
      "Model# 11. 4000 nodes still misclassified out of torch.Size([12018]) \n",
      "\n",
      "Model# 12. 4000 nodes still misclassified out of torch.Size([12018]) \n",
      "\n",
      "Model# 13. 4000 nodes still misclassified out of torch.Size([12018]) \n",
      "\n",
      "Model# 14. 4000 nodes still misclassified out of torch.Size([12018]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 187/299 [01:50<01:05,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4000 nodes still misclassified out of torch.Size([12018]) \n",
      "\n",
      "Model# 16. 4000 nodes still misclassified out of torch.Size([12018]) \n",
      "\n",
      "Model# 17. 4000 nodes still misclassified out of torch.Size([12018]) \n",
      "\n",
      "Model# 18. 4000 nodes still misclassified out of torch.Size([12018]) \n",
      "\n",
      "Model# 19. 4000 nodes still misclassified out of torch.Size([12018]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12065/12065 [00:00<00:00, 2657229.46it/s]\n",
      "100%|██████████| 12065/12065 [00:00<00:00, 3006968.79it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1972490.59it/s]\n",
      "Inferring Phrases: 100%|██████████| 12065/12065 [00:00<00:00, 343832.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3897 nodes still misclassified out of torch.Size([12065]) \n",
      "\n",
      "Model# 1. 3897 nodes still misclassified out of torch.Size([12065]) \n",
      "\n",
      "Model# 2. 3897 nodes still misclassified out of torch.Size([12065]) \n",
      "\n",
      "Model# 3. 3897 nodes still misclassified out of torch.Size([12065]) \n",
      "\n",
      "Model# 4. 3897 nodes still misclassified out of torch.Size([12065]) \n",
      "\n",
      "Model# 5. 3897 nodes still misclassified out of torch.Size([12065]) \n",
      "\n",
      "Model# 6. 3897 nodes still misclassified out of torch.Size([12065]) \n",
      "\n",
      "Model# 7. 3897 nodes still misclassified out of torch.Size([12065]) \n",
      "\n",
      "Model# 8. 3897 nodes still misclassified out of torch.Size([12065]) \n",
      "\n",
      "Model# 9. 3897 nodes still misclassified out of torch.Size([12065]) \n",
      "\n",
      "Model# 10. 3897 nodes still misclassified out of torch.Size([12065]) \n",
      "\n",
      "Model# 11. 3897 nodes still misclassified out of torch.Size([12065]) \n",
      "\n",
      "Model# 12. 3897 nodes still misclassified out of torch.Size([12065]) \n",
      "\n",
      "Model# 13. 3897 nodes still misclassified out of torch.Size([12065]) \n",
      "\n",
      "Model# 14. 3897 nodes still misclassified out of torch.Size([12065]) \n",
      "\n",
      "Model# 15. 3897 nodes still misclassified out of torch.Size([12065]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 188/299 [01:50<01:02,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 16. 3897 nodes still misclassified out of torch.Size([12065]) \n",
      "\n",
      "Model# 17. 3897 nodes still misclassified out of torch.Size([12065]) \n",
      "\n",
      "Model# 18. 3897 nodes still misclassified out of torch.Size([12065]) \n",
      "\n",
      "Model# 19. 3897 nodes still misclassified out of torch.Size([12065]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14208/14208 [00:00<00:00, 2635094.90it/s]\n",
      "100%|██████████| 14208/14208 [00:00<00:00, 2990399.00it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1919297.13it/s]\n",
      "Inferring Phrases: 100%|██████████| 14208/14208 [00:00<00:00, 410607.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5779 nodes still misclassified out of torch.Size([14208]) \n",
      "\n",
      "Model# 1. 5779 nodes still misclassified out of torch.Size([14208]) \n",
      "\n",
      "Model# 2. 5779 nodes still misclassified out of torch.Size([14208]) \n",
      "\n",
      "Model# 3. 5779 nodes still misclassified out of torch.Size([14208]) \n",
      "\n",
      "Model# 4. 5779 nodes still misclassified out of torch.Size([14208]) \n",
      "\n",
      "Model# 5. 5779 nodes still misclassified out of torch.Size([14208]) \n",
      "\n",
      "Model# 6. 5779 nodes still misclassified out of torch.Size([14208]) \n",
      "\n",
      "Model# 7. 5779 nodes still misclassified out of torch.Size([14208]) \n",
      "\n",
      "Model# 8. 5779 nodes still misclassified out of torch.Size([14208]) \n",
      "\n",
      "Model# 9. 5779 nodes still misclassified out of torch.Size([14208]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 189/299 [01:51<01:04,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 5779 nodes still misclassified out of torch.Size([14208]) \n",
      "\n",
      "Model# 11. 5779 nodes still misclassified out of torch.Size([14208]) \n",
      "\n",
      "Model# 12. 5779 nodes still misclassified out of torch.Size([14208]) \n",
      "\n",
      "Model# 13. 5779 nodes still misclassified out of torch.Size([14208]) \n",
      "\n",
      "Model# 14. 5779 nodes still misclassified out of torch.Size([14208]) \n",
      "\n",
      "Model# 15. 5779 nodes still misclassified out of torch.Size([14208]) \n",
      "\n",
      "Model# 16. 5779 nodes still misclassified out of torch.Size([14208]) \n",
      "\n",
      "Model# 17. 5779 nodes still misclassified out of torch.Size([14208]) \n",
      "\n",
      "Model# 18. 5779 nodes still misclassified out of torch.Size([14208]) \n",
      "\n",
      "Model# 19. 5779 nodes still misclassified out of torch.Size([14208]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14889/14889 [00:00<00:00, 3994179.23it/s]\n",
      "100%|██████████| 14889/14889 [00:00<00:00, 4942931.16it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2785555.65it/s]\n",
      "Inferring Phrases: 100%|██████████| 14889/14889 [00:00<00:00, 468509.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6287 nodes still misclassified out of torch.Size([14889]) \n",
      "\n",
      "Model# 1. 6287 nodes still misclassified out of torch.Size([14889]) \n",
      "\n",
      "Model# 2. 6287 nodes still misclassified out of torch.Size([14889]) \n",
      "\n",
      "Model# 3. 6287 nodes still misclassified out of torch.Size([14889]) \n",
      "\n",
      "Model# 4. 6287 nodes still misclassified out of torch.Size([14889]) \n",
      "\n",
      "Model# 5. 6287 nodes still misclassified out of torch.Size([14889]) \n",
      "\n",
      "Model# 6. 6287 nodes still misclassified out of torch.Size([14889]) \n",
      "\n",
      "Model# 7. 6287 nodes still misclassified out of torch.Size([14889]) \n",
      "\n",
      "Model# 8. 6287 nodes still misclassified out of torch.Size([14889]) \n",
      "\n",
      "Model# 9. 6287 nodes still misclassified out of torch.Size([14889]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 190/299 [01:52<01:10,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 6287 nodes still misclassified out of torch.Size([14889]) \n",
      "\n",
      "Model# 11. 6287 nodes still misclassified out of torch.Size([14889]) \n",
      "\n",
      "Model# 12. 6287 nodes still misclassified out of torch.Size([14889]) \n",
      "\n",
      "Model# 13. 6287 nodes still misclassified out of torch.Size([14889]) \n",
      "\n",
      "Model# 14. 6287 nodes still misclassified out of torch.Size([14889]) \n",
      "\n",
      "Model# 15. 6287 nodes still misclassified out of torch.Size([14889]) \n",
      "\n",
      "Model# 16. 6287 nodes still misclassified out of torch.Size([14889]) \n",
      "\n",
      "Model# 17. 6287 nodes still misclassified out of torch.Size([14889]) \n",
      "\n",
      "Model# 18. 6287 nodes still misclassified out of torch.Size([14889]) \n",
      "\n",
      "Model# 19. 6287 nodes still misclassified out of torch.Size([14889]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13499/13499 [00:00<00:00, 3792037.35it/s]\n",
      "100%|██████████| 13499/13499 [00:00<00:00, 4381251.23it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2581904.59it/s]\n",
      "Inferring Phrases: 100%|██████████| 13499/13499 [00:00<00:00, 386174.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5158 nodes still misclassified out of torch.Size([13499]) \n",
      "\n",
      "Model# 1. 5158 nodes still misclassified out of torch.Size([13499]) \n",
      "\n",
      "Model# 2. 5158 nodes still misclassified out of torch.Size([13499]) \n",
      "\n",
      "Model# 3. 5158 nodes still misclassified out of torch.Size([13499]) \n",
      "\n",
      "Model# 4. 5158 nodes still misclassified out of torch.Size([13499]) \n",
      "\n",
      "Model# 5. 5158 nodes still misclassified out of torch.Size([13499]) \n",
      "\n",
      "Model# 6. 5158 nodes still misclassified out of torch.Size([13499]) \n",
      "\n",
      "Model# 7. 5158 nodes still misclassified out of torch.Size([13499]) \n",
      "\n",
      "Model# 8. 5158 nodes still misclassified out of torch.Size([13499]) \n",
      "\n",
      "Model# 9. 5158 nodes still misclassified out of torch.Size([13499]) \n",
      "\n",
      "Model# 10. 5158 nodes still misclassified out of torch.Size([13499]) \n",
      "\n",
      "Model# 11. 5158 nodes still misclassified out of torch.Size([13499]) \n",
      "\n",
      "Model# 12. 5158 nodes still misclassified out of torch.Size([13499]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 191/299 [01:52<01:05,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 13. 5158 nodes still misclassified out of torch.Size([13499]) \n",
      "\n",
      "Model# 14. 5158 nodes still misclassified out of torch.Size([13499]) \n",
      "\n",
      "Model# 15. 5158 nodes still misclassified out of torch.Size([13499]) \n",
      "\n",
      "Model# 16. 5158 nodes still misclassified out of torch.Size([13499]) \n",
      "\n",
      "Model# 17. 5158 nodes still misclassified out of torch.Size([13499]) \n",
      "\n",
      "Model# 18. 5158 nodes still misclassified out of torch.Size([13499]) \n",
      "\n",
      "Model# 19. 5158 nodes still misclassified out of torch.Size([13499]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12987/12987 [00:00<00:00, 4021218.52it/s]\n",
      "100%|██████████| 12987/12987 [00:00<00:00, 4704735.36it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2748741.07it/s]\n",
      "Inferring Phrases: 100%|██████████| 12987/12987 [00:00<00:00, 390846.01it/s]\n",
      " 64%|██████▍   | 192/299 [01:53<00:59,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3384 nodes still misclassified out of torch.Size([12987]) \n",
      "\n",
      "Model# 1. 3384 nodes still misclassified out of torch.Size([12987]) \n",
      "\n",
      "Model# 2. 3384 nodes still misclassified out of torch.Size([12987]) \n",
      "\n",
      "Model# 3. 3384 nodes still misclassified out of torch.Size([12987]) \n",
      "\n",
      "Model# 4. 3384 nodes still misclassified out of torch.Size([12987]) \n",
      "\n",
      "Model# 5. 3384 nodes still misclassified out of torch.Size([12987]) \n",
      "\n",
      "Model# 6. 3384 nodes still misclassified out of torch.Size([12987]) \n",
      "\n",
      "Model# 7. 3384 nodes still misclassified out of torch.Size([12987]) \n",
      "\n",
      "Model# 8. 3384 nodes still misclassified out of torch.Size([12987]) \n",
      "\n",
      "Model# 9. 3384 nodes still misclassified out of torch.Size([12987]) \n",
      "\n",
      "Model# 10. 3384 nodes still misclassified out of torch.Size([12987]) \n",
      "\n",
      "Model# 11. 3384 nodes still misclassified out of torch.Size([12987]) \n",
      "\n",
      "Model# 12. 3384 nodes still misclassified out of torch.Size([12987]) \n",
      "\n",
      "Model# 13. 3384 nodes still misclassified out of torch.Size([12987]) \n",
      "\n",
      "Model# 14. 3384 nodes still misclassified out of torch.Size([12987]) \n",
      "\n",
      "Model# 15. 3384 nodes still misclassified out of torch.Size([12987]) \n",
      "\n",
      "Model# 16. 3384 nodes still misclassified out of torch.Size([12987]) \n",
      "\n",
      "Model# 17. 3384 nodes still misclassified out of torch.Size([12987]) \n",
      "\n",
      "Model# 18. 3384 nodes still misclassified out of torch.Size([12987]) \n",
      "\n",
      "Model# 19. 3384 nodes still misclassified out of torch.Size([12987]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12580/12580 [00:00<00:00, 4359968.96it/s]\n",
      "100%|██████████| 12580/12580 [00:00<00:00, 5120763.23it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2753613.45it/s]\n",
      "Inferring Phrases: 100%|██████████| 12580/12580 [00:00<00:00, 416227.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4474 nodes still misclassified out of torch.Size([12580]) \n",
      "\n",
      "Model# 1. 4474 nodes still misclassified out of torch.Size([12580]) \n",
      "\n",
      "Model# 2. 4474 nodes still misclassified out of torch.Size([12580]) \n",
      "\n",
      "Model# 3. 4474 nodes still misclassified out of torch.Size([12580]) \n",
      "\n",
      "Model# 4. 4474 nodes still misclassified out of torch.Size([12580]) \n",
      "\n",
      "Model# 5. 4474 nodes still misclassified out of torch.Size([12580]) \n",
      "\n",
      "Model# 6. 4474 nodes still misclassified out of torch.Size([12580]) \n",
      "\n",
      "Model# 7. 4474 nodes still misclassified out of torch.Size([12580]) \n",
      "\n",
      "Model# 8. 4474 nodes still misclassified out of torch.Size([12580]) \n",
      "\n",
      "Model# 9. 4474 nodes still misclassified out of torch.Size([12580]) \n",
      "\n",
      "Model# 10. 4474 nodes still misclassified out of torch.Size([12580]) \n",
      "\n",
      "Model# 11. 4474 nodes still misclassified out of torch.Size([12580]) \n",
      "\n",
      "Model# 12. 4474 nodes still misclassified out of torch.Size([12580]) \n",
      "\n",
      "Model# 13. 4474 nodes still misclassified out of torch.Size([12580]) \n",
      "\n",
      "Model# 14. 4474 nodes still misclassified out of torch.Size([12580]) \n",
      "\n",
      "Model# 15. 4474 nodes still misclassified out of torch.Size([12580]) \n",
      "\n",
      "Model# 16. 4474 nodes still misclassified out of torch.Size([12580]) \n",
      "\n",
      "Model# 17. 4474 nodes still misclassified out of torch.Size([12580]) \n",
      "\n",
      "Model# 18. 4474 nodes still misclassified out of torch.Size([12580]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 193/299 [01:53<00:58,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4474 nodes still misclassified out of torch.Size([12580]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12689/12689 [00:00<00:00, 4082031.25it/s]\n",
      "100%|██████████| 12689/12689 [00:00<00:00, 4562887.81it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2774010.58it/s]\n",
      "Inferring Phrases: 100%|██████████| 12689/12689 [00:00<00:00, 375550.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4631 nodes still misclassified out of torch.Size([12689]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 1. 4631 nodes still misclassified out of torch.Size([12689]) \n",
      "\n",
      "Model# 2. 4631 nodes still misclassified out of torch.Size([12689]) \n",
      "\n",
      "Model# 3. 4631 nodes still misclassified out of torch.Size([12689]) \n",
      "\n",
      "Model# 4. 4631 nodes still misclassified out of torch.Size([12689]) \n",
      "\n",
      "Model# 5. 4631 nodes still misclassified out of torch.Size([12689]) \n",
      "\n",
      "Model# 6. 4631 nodes still misclassified out of torch.Size([12689]) \n",
      "\n",
      "Model# 7. 4631 nodes still misclassified out of torch.Size([12689]) \n",
      "\n",
      "Model# 8. 4631 nodes still misclassified out of torch.Size([12689]) \n",
      "\n",
      "Model# 9. 4631 nodes still misclassified out of torch.Size([12689]) \n",
      "\n",
      "Model# 10. 4631 nodes still misclassified out of torch.Size([12689]) \n",
      "\n",
      "Model# 11. 4631 nodes still misclassified out of torch.Size([12689]) \n",
      "\n",
      "Model# 12. 4631 nodes still misclassified out of torch.Size([12689]) \n",
      "\n",
      "Model# 13. 4631 nodes still misclassified out of torch.Size([12689]) \n",
      "\n",
      "Model# 14. 4631 nodes still misclassified out of torch.Size([12689]) \n",
      "\n",
      "Model# 15. 4631 nodes still misclassified out of torch.Size([12689]) \n",
      "\n",
      "Model# 16. 4631 nodes still misclassified out of torch.Size([12689]) \n",
      "\n",
      "Model# 17. 4631 nodes still misclassified out of torch.Size([12689]) \n",
      "\n",
      "Model# 18. 4631 nodes still misclassified out of torch.Size([12689]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 194/299 [01:54<00:53,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4631 nodes still misclassified out of torch.Size([12689]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12533/12533 [00:00<00:00, 4055173.34it/s]\n",
      "100%|██████████| 12533/12533 [00:00<00:00, 4844904.33it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2765718.30it/s]\n",
      "Inferring Phrases: 100%|██████████| 12533/12533 [00:00<00:00, 367109.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4418 nodes still misclassified out of torch.Size([12533]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 1. 4418 nodes still misclassified out of torch.Size([12533]) \n",
      "\n",
      "Model# 2. 4418 nodes still misclassified out of torch.Size([12533]) \n",
      "\n",
      "Model# 3. 4418 nodes still misclassified out of torch.Size([12533]) \n",
      "\n",
      "Model# 4. 4418 nodes still misclassified out of torch.Size([12533]) \n",
      "\n",
      "Model# 5. 4418 nodes still misclassified out of torch.Size([12533]) \n",
      "\n",
      "Model# 6. 4418 nodes still misclassified out of torch.Size([12533]) \n",
      "\n",
      "Model# 7. 4418 nodes still misclassified out of torch.Size([12533]) \n",
      "\n",
      "Model# 8. 4418 nodes still misclassified out of torch.Size([12533]) \n",
      "\n",
      "Model# 9. 4418 nodes still misclassified out of torch.Size([12533]) \n",
      "\n",
      "Model# 10. 4418 nodes still misclassified out of torch.Size([12533]) \n",
      "\n",
      "Model# 11. 4418 nodes still misclassified out of torch.Size([12533]) \n",
      "\n",
      "Model# 12. 4418 nodes still misclassified out of torch.Size([12533]) \n",
      "\n",
      "Model# 13. 4418 nodes still misclassified out of torch.Size([12533]) \n",
      "\n",
      "Model# 14. 4418 nodes still misclassified out of torch.Size([12533]) \n",
      "\n",
      "Model# 15. 4418 nodes still misclassified out of torch.Size([12533]) \n",
      "\n",
      "Model# 16. 4418 nodes still misclassified out of torch.Size([12533]) \n",
      "\n",
      "Model# 17. 4418 nodes still misclassified out of torch.Size([12533]) \n",
      "\n",
      "Model# 18. 4418 nodes still misclassified out of torch.Size([12533]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 195/299 [01:54<00:49,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4418 nodes still misclassified out of torch.Size([12533]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12415/12415 [00:00<00:00, 4197346.78it/s]\n",
      "100%|██████████| 12415/12415 [00:00<00:00, 5004063.44it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2796140.53it/s]\n",
      "Inferring Phrases: 100%|██████████| 12415/12415 [00:00<00:00, 394233.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4456 nodes still misclassified out of torch.Size([12415]) \n",
      "\n",
      "Model# 1. 4456 nodes still misclassified out of torch.Size([12415]) \n",
      "\n",
      "Model# 2. 4456 nodes still misclassified out of torch.Size([12415]) \n",
      "\n",
      "Model# 3. 4456 nodes still misclassified out of torch.Size([12415]) \n",
      "\n",
      "Model# 4. 4456 nodes still misclassified out of torch.Size([12415]) \n",
      "\n",
      "Model# 5. 4456 nodes still misclassified out of torch.Size([12415]) \n",
      "\n",
      "Model# 6. 4456 nodes still misclassified out of torch.Size([12415]) \n",
      "\n",
      "Model# 7. 4456 nodes still misclassified out of torch.Size([12415]) \n",
      "\n",
      "Model# 8. 4456 nodes still misclassified out of torch.Size([12415]) \n",
      "\n",
      "Model# 9. 4456 nodes still misclassified out of torch.Size([12415]) \n",
      "\n",
      "Model# 10. 4456 nodes still misclassified out of torch.Size([12415]) \n",
      "\n",
      "Model# 11. 4456 nodes still misclassified out of torch.Size([12415]) \n",
      "\n",
      "Model# 12. 4456 nodes still misclassified out of torch.Size([12415]) \n",
      "\n",
      "Model# 13. 4456 nodes still misclassified out of torch.Size([12415]) \n",
      "\n",
      "Model# 14. 4456 nodes still misclassified out of torch.Size([12415]) \n",
      "\n",
      "Model# 15. 4456 nodes still misclassified out of torch.Size([12415]) \n",
      "\n",
      "Model# 16. 4456 nodes still misclassified out of torch.Size([12415]) \n",
      "\n",
      "Model# 17. 4456 nodes still misclassified out of torch.Size([12415]) \n",
      "\n",
      "Model# 18. 4456 nodes still misclassified out of torch.Size([12415]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 196/299 [01:55<00:50,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4456 nodes still misclassified out of torch.Size([12415]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12391/12391 [00:00<00:00, 3988918.63it/s]\n",
      "100%|██████████| 12391/12391 [00:00<00:00, 4711415.18it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2721688.87it/s]\n",
      "Inferring Phrases: 100%|██████████| 12391/12391 [00:00<00:00, 229878.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4470 nodes still misclassified out of torch.Size([12391]) \n",
      "\n",
      "Model# 1. 4470 nodes still misclassified out of torch.Size([12391]) \n",
      "\n",
      "Model# 2. 4470 nodes still misclassified out of torch.Size([12391]) \n",
      "\n",
      "Model# 3. 4470 nodes still misclassified out of torch.Size([12391]) \n",
      "\n",
      "Model# 4. 4470 nodes still misclassified out of torch.Size([12391]) \n",
      "\n",
      "Model# 5. 4470 nodes still misclassified out of torch.Size([12391]) \n",
      "\n",
      "Model# 6. 4470 nodes still misclassified out of torch.Size([12391]) \n",
      "\n",
      "Model# 7. 4470 nodes still misclassified out of torch.Size([12391]) \n",
      "\n",
      "Model# 8. 4470 nodes still misclassified out of torch.Size([12391]) \n",
      "\n",
      "Model# 9. 4470 nodes still misclassified out of torch.Size([12391]) \n",
      "\n",
      "Model# 10. 4470 nodes still misclassified out of torch.Size([12391]) \n",
      "\n",
      "Model# 11. 4470 nodes still misclassified out of torch.Size([12391]) \n",
      "\n",
      "Model# 12. 4470 nodes still misclassified out of torch.Size([12391]) \n",
      "\n",
      "Model# 13. 4470 nodes still misclassified out of torch.Size([12391]) \n",
      "\n",
      "Model# 14. 4470 nodes still misclassified out of torch.Size([12391]) \n",
      "\n",
      "Model# 15. 4470 nodes still misclassified out of torch.Size([12391]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 197/299 [01:55<00:50,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 16. 4470 nodes still misclassified out of torch.Size([12391]) \n",
      "\n",
      "Model# 17. 4470 nodes still misclassified out of torch.Size([12391]) \n",
      "\n",
      "Model# 18. 4470 nodes still misclassified out of torch.Size([12391]) \n",
      "\n",
      "Model# 19. 4470 nodes still misclassified out of torch.Size([12391]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12328/12328 [00:00<00:00, 4078190.69it/s]\n",
      "100%|██████████| 12328/12328 [00:00<00:00, 4862000.91it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2695741.37it/s]\n",
      "Inferring Phrases: 100%|██████████| 12328/12328 [00:00<00:00, 384358.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4340 nodes still misclassified out of torch.Size([12328]) \n",
      "\n",
      "Model# 1. 4340 nodes still misclassified out of torch.Size([12328]) \n",
      "\n",
      "Model# 2. 4340 nodes still misclassified out of torch.Size([12328]) \n",
      "\n",
      "Model# 3. 4340 nodes still misclassified out of torch.Size([12328]) \n",
      "\n",
      "Model# 4. 4340 nodes still misclassified out of torch.Size([12328]) \n",
      "\n",
      "Model# 5. 4340 nodes still misclassified out of torch.Size([12328]) \n",
      "\n",
      "Model# 6. 4340 nodes still misclassified out of torch.Size([12328]) \n",
      "\n",
      "Model# 7. 4340 nodes still misclassified out of torch.Size([12328]) \n",
      "\n",
      "Model# 8. 4340 nodes still misclassified out of torch.Size([12328]) \n",
      "\n",
      "Model# 9. 4340 nodes still misclassified out of torch.Size([12328]) \n",
      "\n",
      "Model# 10. 4340 nodes still misclassified out of torch.Size([12328]) \n",
      "\n",
      "Model# 11. 4340 nodes still misclassified out of torch.Size([12328]) \n",
      "\n",
      "Model# 12. 4340 nodes still misclassified out of torch.Size([12328]) \n",
      "\n",
      "Model# 13. 4340 nodes still misclassified out of torch.Size([12328]) \n",
      "\n",
      "Model# 14. 4340 nodes still misclassified out of torch.Size([12328]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 198/299 [01:56<00:55,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4340 nodes still misclassified out of torch.Size([12328]) \n",
      "\n",
      "Model# 16. 4340 nodes still misclassified out of torch.Size([12328]) \n",
      "\n",
      "Model# 17. 4340 nodes still misclassified out of torch.Size([12328]) \n",
      "\n",
      "Model# 18. 4340 nodes still misclassified out of torch.Size([12328]) \n",
      "\n",
      "Model# 19. 4340 nodes still misclassified out of torch.Size([12328]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12377/12377 [00:00<00:00, 2607247.28it/s]\n",
      "100%|██████████| 12377/12377 [00:00<00:00, 2972396.26it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1929302.67it/s]\n",
      "Inferring Phrases: 100%|██████████| 12377/12377 [00:00<00:00, 355962.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4255 nodes still misclassified out of torch.Size([12377]) \n",
      "\n",
      "Model# 1. 4255 nodes still misclassified out of torch.Size([12377]) \n",
      "\n",
      "Model# 2. 4255 nodes still misclassified out of torch.Size([12377]) \n",
      "\n",
      "Model# 3. 4255 nodes still misclassified out of torch.Size([12377]) \n",
      "\n",
      "Model# 4. 4255 nodes still misclassified out of torch.Size([12377]) \n",
      "\n",
      "Model# 5. 4255 nodes still misclassified out of torch.Size([12377]) \n",
      "\n",
      "Model# 6. 4255 nodes still misclassified out of torch.Size([12377]) \n",
      "\n",
      "Model# 7. 4255 nodes still misclassified out of torch.Size([12377]) \n",
      "\n",
      "Model# 8. 4255 nodes still misclassified out of torch.Size([12377]) \n",
      "\n",
      "Model# 9. 4255 nodes still misclassified out of torch.Size([12377]) \n",
      "\n",
      "Model# 10. 4255 nodes still misclassified out of torch.Size([12377]) \n",
      "\n",
      "Model# 11. 4255 nodes still misclassified out of torch.Size([12377]) \n",
      "\n",
      "Model# 12. 4255 nodes still misclassified out of torch.Size([12377]) \n",
      "\n",
      "Model# 13. 4255 nodes still misclassified out of torch.Size([12377]) \n",
      "\n",
      "Model# 14. 4255 nodes still misclassified out of torch.Size([12377]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 199/299 [01:56<00:53,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4255 nodes still misclassified out of torch.Size([12377]) \n",
      "\n",
      "Model# 16. 4255 nodes still misclassified out of torch.Size([12377]) \n",
      "\n",
      "Model# 17. 4255 nodes still misclassified out of torch.Size([12377]) \n",
      "\n",
      "Model# 18. 4255 nodes still misclassified out of torch.Size([12377]) \n",
      "\n",
      "Model# 19. 4255 nodes still misclassified out of torch.Size([12377]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12292/12292 [00:00<00:00, 1987218.04it/s]\n",
      "100%|██████████| 12292/12292 [00:00<00:00, 2937853.14it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1821287.63it/s]\n",
      "Inferring Phrases: 100%|██████████| 12292/12292 [00:00<00:00, 351524.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4322 nodes still misclassified out of torch.Size([12292]) \n",
      "\n",
      "Model# 1. 4322 nodes still misclassified out of torch.Size([12292]) \n",
      "\n",
      "Model# 2. 4322 nodes still misclassified out of torch.Size([12292]) \n",
      "\n",
      "Model# 3. 4322 nodes still misclassified out of torch.Size([12292]) \n",
      "\n",
      "Model# 4. 4322 nodes still misclassified out of torch.Size([12292]) \n",
      "\n",
      "Model# 5. 4322 nodes still misclassified out of torch.Size([12292]) \n",
      "\n",
      "Model# 6. 4322 nodes still misclassified out of torch.Size([12292]) \n",
      "\n",
      "Model# 7. 4322 nodes still misclassified out of torch.Size([12292]) \n",
      "\n",
      "Model# 8. 4322 nodes still misclassified out of torch.Size([12292]) \n",
      "\n",
      "Model# 9. 4322 nodes still misclassified out of torch.Size([12292]) \n",
      "\n",
      "Model# 10. 4322 nodes still misclassified out of torch.Size([12292]) \n",
      "\n",
      "Model# 11. 4322 nodes still misclassified out of torch.Size([12292]) \n",
      "\n",
      "Model# 12. 4322 nodes still misclassified out of torch.Size([12292]) \n",
      "\n",
      "Model# 13. 4322 nodes still misclassified out of torch.Size([12292]) \n",
      "\n",
      "Model# 14. 4322 nodes still misclassified out of torch.Size([12292]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 200/299 [01:57<00:53,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4322 nodes still misclassified out of torch.Size([12292]) \n",
      "\n",
      "Model# 16. 4322 nodes still misclassified out of torch.Size([12292]) \n",
      "\n",
      "Model# 17. 4322 nodes still misclassified out of torch.Size([12292]) \n",
      "\n",
      "Model# 18. 4322 nodes still misclassified out of torch.Size([12292]) \n",
      "\n",
      "Model# 19. 4322 nodes still misclassified out of torch.Size([12292]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15045/15045 [00:00<00:00, 3699771.56it/s]\n",
      "100%|██████████| 15045/15045 [00:00<00:00, 4719415.43it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2700195.71it/s]\n",
      "Inferring Phrases: 100%|██████████| 15045/15045 [00:00<00:00, 471433.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6321 nodes still misclassified out of torch.Size([15045]) \n",
      "\n",
      "Model# 1. 6321 nodes still misclassified out of torch.Size([15045]) \n",
      "\n",
      "Model# 2. 6321 nodes still misclassified out of torch.Size([15045]) \n",
      "\n",
      "Model# 3. 6321 nodes still misclassified out of torch.Size([15045]) \n",
      "\n",
      "Model# 4. 6321 nodes still misclassified out of torch.Size([15045]) \n",
      "\n",
      "Model# 5. 6321 nodes still misclassified out of torch.Size([15045]) \n",
      "\n",
      "Model# 6. 6321 nodes still misclassified out of torch.Size([15045]) \n",
      "\n",
      "Model# 7. 6321 nodes still misclassified out of torch.Size([15045]) \n",
      "\n",
      "Model# 8. 6321 nodes still misclassified out of torch.Size([15045]) \n",
      "\n",
      "Model# 9. 6321 nodes still misclassified out of torch.Size([15045]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 201/299 [01:58<01:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 6321 nodes still misclassified out of torch.Size([15045]) \n",
      "\n",
      "Model# 11. 6321 nodes still misclassified out of torch.Size([15045]) \n",
      "\n",
      "Model# 12. 6321 nodes still misclassified out of torch.Size([15045]) \n",
      "\n",
      "Model# 13. 6321 nodes still misclassified out of torch.Size([15045]) \n",
      "\n",
      "Model# 14. 6321 nodes still misclassified out of torch.Size([15045]) \n",
      "\n",
      "Model# 15. 6321 nodes still misclassified out of torch.Size([15045]) \n",
      "\n",
      "Model# 16. 6321 nodes still misclassified out of torch.Size([15045]) \n",
      "\n",
      "Model# 17. 6321 nodes still misclassified out of torch.Size([15045]) \n",
      "\n",
      "Model# 18. 6321 nodes still misclassified out of torch.Size([15045]) \n",
      "\n",
      "Model# 19. 6321 nodes still misclassified out of torch.Size([15045]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14070/14070 [00:00<00:00, 2595498.85it/s]\n",
      "100%|██████████| 14070/14070 [00:00<00:00, 2936889.48it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1924463.48it/s]\n",
      "Inferring Phrases: 100%|██████████| 14070/14070 [00:00<00:00, 438676.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5641 nodes still misclassified out of torch.Size([14070]) \n",
      "\n",
      "Model# 1. 5641 nodes still misclassified out of torch.Size([14070]) \n",
      "\n",
      "Model# 2. 5641 nodes still misclassified out of torch.Size([14070]) \n",
      "\n",
      "Model# 3. 5641 nodes still misclassified out of torch.Size([14070]) \n",
      "\n",
      "Model# 4. 5641 nodes still misclassified out of torch.Size([14070]) \n",
      "\n",
      "Model# 5. 5641 nodes still misclassified out of torch.Size([14070]) \n",
      "\n",
      "Model# 6. 5641 nodes still misclassified out of torch.Size([14070]) \n",
      "\n",
      "Model# 7. 5641 nodes still misclassified out of torch.Size([14070]) \n",
      "\n",
      "Model# 8. 5641 nodes still misclassified out of torch.Size([14070]) \n",
      "\n",
      "Model# 9. 5641 nodes still misclassified out of torch.Size([14070]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 202/299 [01:58<01:01,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 5641 nodes still misclassified out of torch.Size([14070]) \n",
      "\n",
      "Model# 11. 5641 nodes still misclassified out of torch.Size([14070]) \n",
      "\n",
      "Model# 12. 5641 nodes still misclassified out of torch.Size([14070]) \n",
      "\n",
      "Model# 13. 5641 nodes still misclassified out of torch.Size([14070]) \n",
      "\n",
      "Model# 14. 5641 nodes still misclassified out of torch.Size([14070]) \n",
      "\n",
      "Model# 15. 5641 nodes still misclassified out of torch.Size([14070]) \n",
      "\n",
      "Model# 16. 5641 nodes still misclassified out of torch.Size([14070]) \n",
      "\n",
      "Model# 17. 5641 nodes still misclassified out of torch.Size([14070]) \n",
      "\n",
      "Model# 18. 5641 nodes still misclassified out of torch.Size([14070]) \n",
      "\n",
      "Model# 19. 5641 nodes still misclassified out of torch.Size([14070]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13474/13474 [00:00<00:00, 3844754.89it/s]\n",
      "100%|██████████| 13474/13474 [00:00<00:00, 4528732.44it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2524408.07it/s]\n",
      "Inferring Phrases: 100%|██████████| 13474/13474 [00:00<00:00, 381495.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5192 nodes still misclassified out of torch.Size([13474]) \n",
      "\n",
      "Model# 1. 5192 nodes still misclassified out of torch.Size([13474]) \n",
      "\n",
      "Model# 2. 5192 nodes still misclassified out of torch.Size([13474]) \n",
      "\n",
      "Model# 3. 5192 nodes still misclassified out of torch.Size([13474]) \n",
      "\n",
      "Model# 4. 5192 nodes still misclassified out of torch.Size([13474]) \n",
      "\n",
      "Model# 5. 5192 nodes still misclassified out of torch.Size([13474]) \n",
      "\n",
      "Model# 6. 5192 nodes still misclassified out of torch.Size([13474]) \n",
      "\n",
      "Model# 7. 5192 nodes still misclassified out of torch.Size([13474]) \n",
      "\n",
      "Model# 8. 5192 nodes still misclassified out of torch.Size([13474]) \n",
      "\n",
      "Model# 9. 5192 nodes still misclassified out of torch.Size([13474]) \n",
      "\n",
      "Model# 10. 5192 nodes still misclassified out of torch.Size([13474]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 203/299 [01:59<00:58,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 5192 nodes still misclassified out of torch.Size([13474]) \n",
      "\n",
      "Model# 12. 5192 nodes still misclassified out of torch.Size([13474]) \n",
      "\n",
      "Model# 13. 5192 nodes still misclassified out of torch.Size([13474]) \n",
      "\n",
      "Model# 14. 5192 nodes still misclassified out of torch.Size([13474]) \n",
      "\n",
      "Model# 15. 5192 nodes still misclassified out of torch.Size([13474]) \n",
      "\n",
      "Model# 16. 5192 nodes still misclassified out of torch.Size([13474]) \n",
      "\n",
      "Model# 17. 5192 nodes still misclassified out of torch.Size([13474]) \n",
      "\n",
      "Model# 18. 5192 nodes still misclassified out of torch.Size([13474]) \n",
      "\n",
      "Model# 19. 5192 nodes still misclassified out of torch.Size([13474]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12962/12962 [00:00<00:00, 4098806.43it/s]\n",
      "100%|██████████| 12962/12962 [00:00<00:00, 4994173.11it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2793099.22it/s]\n",
      "Inferring Phrases: 100%|██████████| 12962/12962 [00:00<00:00, 420296.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4835 nodes still misclassified out of torch.Size([12962]) \n",
      "\n",
      "Model# 1. 4835 nodes still misclassified out of torch.Size([12962]) \n",
      "\n",
      "Model# 2. 4835 nodes still misclassified out of torch.Size([12962]) \n",
      "\n",
      "Model# 3. 4835 nodes still misclassified out of torch.Size([12962]) \n",
      "\n",
      "Model# 4. 4835 nodes still misclassified out of torch.Size([12962]) \n",
      "\n",
      "Model# 5. 4835 nodes still misclassified out of torch.Size([12962]) \n",
      "\n",
      "Model# 6. 4835 nodes still misclassified out of torch.Size([12962]) \n",
      "\n",
      "Model# 7. 4835 nodes still misclassified out of torch.Size([12962]) \n",
      "\n",
      "Model# 8. 4835 nodes still misclassified out of torch.Size([12962]) \n",
      "\n",
      "Model# 9. 4835 nodes still misclassified out of torch.Size([12962]) \n",
      "\n",
      "Model# 10. 4835 nodes still misclassified out of torch.Size([12962]) \n",
      "\n",
      "Model# 11. 4835 nodes still misclassified out of torch.Size([12962]) \n",
      "\n",
      "Model# 12. 4835 nodes still misclassified out of torch.Size([12962]) \n",
      "\n",
      "Model# 13. 4835 nodes still misclassified out of torch.Size([12962]) \n",
      "\n",
      "Model# 14. 4835 nodes still misclassified out of torch.Size([12962]) \n",
      "\n",
      "Model# 15. 4835 nodes still misclassified out of torch.Size([12962]) \n",
      "\n",
      "Model# 16. 4835 nodes still misclassified out of torch.Size([12962]) \n",
      "\n",
      "Model# 17. 4835 nodes still misclassified out of torch.Size([12962]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 204/299 [01:59<00:57,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 18. 4835 nodes still misclassified out of torch.Size([12962]) \n",
      "\n",
      "Model# 19. 4835 nodes still misclassified out of torch.Size([12962]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12602/12602 [00:00<00:00, 3781685.56it/s]\n",
      "100%|██████████| 12602/12602 [00:00<00:00, 2942855.02it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2092548.39it/s]\n",
      "Inferring Phrases: 100%|██████████| 12602/12602 [00:00<00:00, 237135.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4572 nodes still misclassified out of torch.Size([12602]) \n",
      "\n",
      "Model# 1. 4572 nodes still misclassified out of torch.Size([12602]) \n",
      "\n",
      "Model# 2. 4572 nodes still misclassified out of torch.Size([12602]) \n",
      "\n",
      "Model# 3. 4572 nodes still misclassified out of torch.Size([12602]) \n",
      "\n",
      "Model# 4. 4572 nodes still misclassified out of torch.Size([12602]) \n",
      "\n",
      "Model# 5. 4572 nodes still misclassified out of torch.Size([12602]) \n",
      "\n",
      "Model# 6. 4572 nodes still misclassified out of torch.Size([12602]) \n",
      "\n",
      "Model# 7. 4572 nodes still misclassified out of torch.Size([12602]) \n",
      "\n",
      "Model# 8. 4572 nodes still misclassified out of torch.Size([12602]) \n",
      "\n",
      "Model# 9. 4572 nodes still misclassified out of torch.Size([12602]) \n",
      "\n",
      "Model# 10. 4572 nodes still misclassified out of torch.Size([12602]) \n",
      "\n",
      "Model# 11. 4572 nodes still misclassified out of torch.Size([12602]) \n",
      "\n",
      "Model# 12. 4572 nodes still misclassified out of torch.Size([12602]) \n",
      "\n",
      "Model# 13. 4572 nodes still misclassified out of torch.Size([12602]) \n",
      "\n",
      "Model# 14. 4572 nodes still misclassified out of torch.Size([12602]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 205/299 [02:00<00:53,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4572 nodes still misclassified out of torch.Size([12602]) \n",
      "\n",
      "Model# 16. 4572 nodes still misclassified out of torch.Size([12602]) \n",
      "\n",
      "Model# 17. 4572 nodes still misclassified out of torch.Size([12602]) \n",
      "\n",
      "Model# 18. 4572 nodes still misclassified out of torch.Size([12602]) \n",
      "\n",
      "Model# 19. 4572 nodes still misclassified out of torch.Size([12602]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12363/12363 [00:00<00:00, 3981432.77it/s]\n",
      "100%|██████████| 12363/12363 [00:00<00:00, 4673231.83it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2824003.41it/s]\n",
      "Inferring Phrases: 100%|██████████| 12363/12363 [00:00<00:00, 364067.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4337 nodes still misclassified out of torch.Size([12363]) \n",
      "\n",
      "Model# 1. 4337 nodes still misclassified out of torch.Size([12363]) \n",
      "\n",
      "Model# 2. 4337 nodes still misclassified out of torch.Size([12363]) \n",
      "\n",
      "Model# 3. 4337 nodes still misclassified out of torch.Size([12363]) \n",
      "\n",
      "Model# 4. 4337 nodes still misclassified out of torch.Size([12363]) \n",
      "\n",
      "Model# 5. 4337 nodes still misclassified out of torch.Size([12363]) \n",
      "\n",
      "Model# 6. 4337 nodes still misclassified out of torch.Size([12363]) \n",
      "\n",
      "Model# 7. 4337 nodes still misclassified out of torch.Size([12363]) \n",
      "\n",
      "Model# 8. 4337 nodes still misclassified out of torch.Size([12363]) \n",
      "\n",
      "Model# 9. 4337 nodes still misclassified out of torch.Size([12363]) \n",
      "\n",
      "Model# 10. 4337 nodes still misclassified out of torch.Size([12363]) \n",
      "\n",
      "Model# 11. 4337 nodes still misclassified out of torch.Size([12363]) \n",
      "\n",
      "Model# 12. 4337 nodes still misclassified out of torch.Size([12363]) \n",
      "\n",
      "Model# 13. 4337 nodes still misclassified out of torch.Size([12363]) \n",
      "\n",
      "Model# 14. 4337 nodes still misclassified out of torch.Size([12363]) \n",
      "\n",
      "Model# 15. 4337 nodes still misclassified out of torch.Size([12363]) \n",
      "\n",
      "Model# 16. 4337 nodes still misclassified out of torch.Size([12363]) \n",
      "\n",
      "Model# 17. 4337 nodes still misclassified out of torch.Size([12363]) \n",
      "\n",
      "Model# 18. 4337 nodes still misclassified out of torch.Size([12363]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 206/299 [02:00<00:48,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4337 nodes still misclassified out of torch.Size([12363]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12642/12642 [00:00<00:00, 4285491.89it/s]\n",
      "100%|██████████| 12642/12642 [00:00<00:00, 5111770.09it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2725875.09it/s]\n",
      "Inferring Phrases: 100%|██████████| 12642/12642 [00:00<00:00, 400259.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4561 nodes still misclassified out of torch.Size([12642]) \n",
      "\n",
      "Model# 1. 4561 nodes still misclassified out of torch.Size([12642]) \n",
      "\n",
      "Model# 2. 4561 nodes still misclassified out of torch.Size([12642]) \n",
      "\n",
      "Model# 3. 4561 nodes still misclassified out of torch.Size([12642]) \n",
      "\n",
      "Model# 4. 4561 nodes still misclassified out of torch.Size([12642]) \n",
      "\n",
      "Model# 5. 4561 nodes still misclassified out of torch.Size([12642]) \n",
      "\n",
      "Model# 6. 4561 nodes still misclassified out of torch.Size([12642]) \n",
      "\n",
      "Model# 7. 4561 nodes still misclassified out of torch.Size([12642]) \n",
      "\n",
      "Model# 8. 4561 nodes still misclassified out of torch.Size([12642]) \n",
      "\n",
      "Model# 9. 4561 nodes still misclassified out of torch.Size([12642]) \n",
      "\n",
      "Model# 10. 4561 nodes still misclassified out of torch.Size([12642]) \n",
      "\n",
      "Model# 11. 4561 nodes still misclassified out of torch.Size([12642]) \n",
      "\n",
      "Model# 12. 4561 nodes still misclassified out of torch.Size([12642]) \n",
      "\n",
      "Model# 13. 4561 nodes still misclassified out of torch.Size([12642]) \n",
      "\n",
      "Model# 14. 4561 nodes still misclassified out of torch.Size([12642]) \n",
      "\n",
      "Model# 15. 4561 nodes still misclassified out of torch.Size([12642]) \n",
      "\n",
      "Model# 16. 4561 nodes still misclassified out of torch.Size([12642]) \n",
      "\n",
      "Model# 17. 4561 nodes still misclassified out of torch.Size([12642]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 207/299 [02:01<00:49,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 18. 4561 nodes still misclassified out of torch.Size([12642]) \n",
      "\n",
      "Model# 19. 4561 nodes still misclassified out of torch.Size([12642]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12925/12925 [00:00<00:00, 3848873.21it/s]\n",
      "100%|██████████| 12925/12925 [00:00<00:00, 4580211.15it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2732386.27it/s]\n",
      "Inferring Phrases: 100%|██████████| 12925/12925 [00:00<00:00, 368774.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4859 nodes still misclassified out of torch.Size([12925]) \n",
      "\n",
      "Model# 1. 4859 nodes still misclassified out of torch.Size([12925]) \n",
      "\n",
      "Model# 2. 4859 nodes still misclassified out of torch.Size([12925]) \n",
      "\n",
      "Model# 3. 4859 nodes still misclassified out of torch.Size([12925]) \n",
      "\n",
      "Model# 4. 4859 nodes still misclassified out of torch.Size([12925]) \n",
      "\n",
      "Model# 5. 4859 nodes still misclassified out of torch.Size([12925]) \n",
      "\n",
      "Model# 6. 4859 nodes still misclassified out of torch.Size([12925]) \n",
      "\n",
      "Model# 7. 4859 nodes still misclassified out of torch.Size([12925]) \n",
      "\n",
      "Model# 8. 4859 nodes still misclassified out of torch.Size([12925]) \n",
      "\n",
      "Model# 9. 4859 nodes still misclassified out of torch.Size([12925]) \n",
      "\n",
      "Model# 10. 4859 nodes still misclassified out of torch.Size([12925]) \n",
      "\n",
      "Model# 11. 4859 nodes still misclassified out of torch.Size([12925]) \n",
      "\n",
      "Model# 12. 4859 nodes still misclassified out of torch.Size([12925]) \n",
      "\n",
      "Model# 13. 4859 nodes still misclassified out of torch.Size([12925]) \n",
      "\n",
      "Model# 14. 4859 nodes still misclassified out of torch.Size([12925]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 208/299 [02:01<00:47,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4859 nodes still misclassified out of torch.Size([12925]) \n",
      "\n",
      "Model# 16. 4859 nodes still misclassified out of torch.Size([12925]) \n",
      "\n",
      "Model# 17. 4859 nodes still misclassified out of torch.Size([12925]) \n",
      "\n",
      "Model# 18. 4859 nodes still misclassified out of torch.Size([12925]) \n",
      "\n",
      "Model# 19. 4859 nodes still misclassified out of torch.Size([12925]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12440/12440 [00:00<00:00, 3976310.15it/s]\n",
      "100%|██████████| 12440/12440 [00:00<00:00, 4978734.90it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2707341.70it/s]\n",
      "Inferring Phrases: 100%|██████████| 12440/12440 [00:00<00:00, 394611.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4293 nodes still misclassified out of torch.Size([12440]) \n",
      "\n",
      "Model# 1. 4293 nodes still misclassified out of torch.Size([12440]) \n",
      "\n",
      "Model# 2. 4293 nodes still misclassified out of torch.Size([12440]) \n",
      "\n",
      "Model# 3. 4293 nodes still misclassified out of torch.Size([12440]) \n",
      "\n",
      "Model# 4. 4293 nodes still misclassified out of torch.Size([12440]) \n",
      "\n",
      "Model# 5. 4293 nodes still misclassified out of torch.Size([12440]) \n",
      "\n",
      "Model# 6. 4293 nodes still misclassified out of torch.Size([12440]) \n",
      "\n",
      "Model# 7. 4293 nodes still misclassified out of torch.Size([12440]) \n",
      "\n",
      "Model# 8. 4293 nodes still misclassified out of torch.Size([12440]) \n",
      "\n",
      "Model# 9. 4293 nodes still misclassified out of torch.Size([12440]) \n",
      "\n",
      "Model# 10. 4293 nodes still misclassified out of torch.Size([12440]) \n",
      "\n",
      "Model# 11. 4293 nodes still misclassified out of torch.Size([12440]) \n",
      "\n",
      "Model# 12. 4293 nodes still misclassified out of torch.Size([12440]) \n",
      "\n",
      "Model# 13. 4293 nodes still misclassified out of torch.Size([12440]) \n",
      "\n",
      "Model# 14. 4293 nodes still misclassified out of torch.Size([12440]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 209/299 [02:02<00:50,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4293 nodes still misclassified out of torch.Size([12440]) \n",
      "\n",
      "Model# 16. 4293 nodes still misclassified out of torch.Size([12440]) \n",
      "\n",
      "Model# 17. 4293 nodes still misclassified out of torch.Size([12440]) \n",
      "\n",
      "Model# 18. 4293 nodes still misclassified out of torch.Size([12440]) \n",
      "\n",
      "Model# 19. 4293 nodes still misclassified out of torch.Size([12440]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12605/12605 [00:00<00:00, 3786107.27it/s]\n",
      "100%|██████████| 12605/12605 [00:00<00:00, 4596122.92it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2693375.57it/s]\n",
      "Inferring Phrases: 100%|██████████| 12605/12605 [00:00<00:00, 371155.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4734 nodes still misclassified out of torch.Size([12605]) \n",
      "\n",
      "Model# 1. 4734 nodes still misclassified out of torch.Size([12605]) \n",
      "\n",
      "Model# 2. 4734 nodes still misclassified out of torch.Size([12605]) \n",
      "\n",
      "Model# 3. 4734 nodes still misclassified out of torch.Size([12605]) \n",
      "\n",
      "Model# 4. 4734 nodes still misclassified out of torch.Size([12605]) \n",
      "\n",
      "Model# 5. 4734 nodes still misclassified out of torch.Size([12605]) \n",
      "\n",
      "Model# 6. 4734 nodes still misclassified out of torch.Size([12605]) \n",
      "\n",
      "Model# 7. 4734 nodes still misclassified out of torch.Size([12605]) \n",
      "\n",
      "Model# 8. 4734 nodes still misclassified out of torch.Size([12605]) \n",
      "\n",
      "Model# 9. 4734 nodes still misclassified out of torch.Size([12605]) \n",
      "\n",
      "Model# 10. 4734 nodes still misclassified out of torch.Size([12605]) \n",
      "\n",
      "Model# 11. 4734 nodes still misclassified out of torch.Size([12605]) \n",
      "\n",
      "Model# 12. 4734 nodes still misclassified out of torch.Size([12605]) \n",
      "\n",
      "Model# 13. 4734 nodes still misclassified out of torch.Size([12605]) \n",
      "\n",
      "Model# 14. 4734 nodes still misclassified out of torch.Size([12605]) \n",
      "\n",
      "Model# 15. 4734 nodes still misclassified out of torch.Size([12605]) \n",
      "\n",
      "Model# 16. 4734 nodes still misclassified out of torch.Size([12605]) \n",
      "\n",
      "Model# 17. 4734 nodes still misclassified out of torch.Size([12605]) \n",
      "\n",
      "Model# 18. 4734 nodes still misclassified out of torch.Size([12605]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 210/299 [02:02<00:46,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4734 nodes still misclassified out of torch.Size([12605]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12636/12636 [00:00<00:00, 4041115.16it/s]\n",
      "100%|██████████| 12636/12636 [00:00<00:00, 4763119.02it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2789569.69it/s]\n",
      "Inferring Phrases: 100%|██████████| 12636/12636 [00:00<00:00, 361414.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4532 nodes still misclassified out of torch.Size([12636]) \n",
      "\n",
      "Model# 1. 4532 nodes still misclassified out of torch.Size([12636]) \n",
      "\n",
      "Model# 2. 4532 nodes still misclassified out of torch.Size([12636]) \n",
      "\n",
      "Model# 3. 4532 nodes still misclassified out of torch.Size([12636]) \n",
      "\n",
      "Model# 4. 4532 nodes still misclassified out of torch.Size([12636]) \n",
      "\n",
      "Model# 5. 4532 nodes still misclassified out of torch.Size([12636]) \n",
      "\n",
      "Model# 6. 4532 nodes still misclassified out of torch.Size([12636]) \n",
      "\n",
      "Model# 7. 4532 nodes still misclassified out of torch.Size([12636]) \n",
      "\n",
      "Model# 8. 4532 nodes still misclassified out of torch.Size([12636]) \n",
      "\n",
      "Model# 9. 4532 nodes still misclassified out of torch.Size([12636]) \n",
      "\n",
      "Model# 10. 4532 nodes still misclassified out of torch.Size([12636]) \n",
      "\n",
      "Model# 11. 4532 nodes still misclassified out of torch.Size([12636]) \n",
      "\n",
      "Model# 12. 4532 nodes still misclassified out of torch.Size([12636]) \n",
      "\n",
      "Model# 13. 4532 nodes still misclassified out of torch.Size([12636]) \n",
      "\n",
      "Model# 14. 4532 nodes still misclassified out of torch.Size([12636]) \n",
      "\n",
      "Model# 15. 4532 nodes still misclassified out of torch.Size([12636]) \n",
      "\n",
      "Model# 16. 4532 nodes still misclassified out of torch.Size([12636]) \n",
      "\n",
      "Model# 17. 4532 nodes still misclassified out of torch.Size([12636]) \n",
      "\n",
      "Model# 18. 4532 nodes still misclassified out of torch.Size([12636]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 211/299 [02:03<00:42,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4532 nodes still misclassified out of torch.Size([12636]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12917/12917 [00:00<00:00, 4121240.28it/s]\n",
      "100%|██████████| 12917/12917 [00:00<00:00, 4891461.25it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2585034.10it/s]\n",
      "Inferring Phrases: 100%|██████████| 12917/12917 [00:00<00:00, 407367.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3654 nodes still misclassified out of torch.Size([12917]) \n",
      "\n",
      "Model# 1. 3654 nodes still misclassified out of torch.Size([12917]) \n",
      "\n",
      "Model# 2. 3654 nodes still misclassified out of torch.Size([12917]) \n",
      "\n",
      "Model# 3. 3654 nodes still misclassified out of torch.Size([12917]) \n",
      "\n",
      "Model# 4. 3654 nodes still misclassified out of torch.Size([12917]) \n",
      "\n",
      "Model# 5. 3654 nodes still misclassified out of torch.Size([12917]) \n",
      "\n",
      "Model# 6. 3654 nodes still misclassified out of torch.Size([12917]) \n",
      "\n",
      "Model# 7. 3654 nodes still misclassified out of torch.Size([12917]) \n",
      "\n",
      "Model# 8. 3654 nodes still misclassified out of torch.Size([12917]) \n",
      "\n",
      "Model# 9. 3654 nodes still misclassified out of torch.Size([12917]) \n",
      "\n",
      "Model# 10. 3654 nodes still misclassified out of torch.Size([12917]) \n",
      "\n",
      "Model# 11. 3654 nodes still misclassified out of torch.Size([12917]) \n",
      "\n",
      "Model# 12. 3654 nodes still misclassified out of torch.Size([12917]) \n",
      "\n",
      "Model# 13. 3654 nodes still misclassified out of torch.Size([12917]) \n",
      "\n",
      "Model# 14. 3654 nodes still misclassified out of torch.Size([12917]) \n",
      "\n",
      "Model# 15. 3654 nodes still misclassified out of torch.Size([12917]) \n",
      "\n",
      "Model# 16. 3654 nodes still misclassified out of torch.Size([12917]) \n",
      "\n",
      "Model# 17. 3654 nodes still misclassified out of torch.Size([12917]) \n",
      "\n",
      "Model# 18. 3654 nodes still misclassified out of torch.Size([12917]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 212/299 [02:03<00:44,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 3654 nodes still misclassified out of torch.Size([12917]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12032/12032 [00:00<00:00, 3932200.85it/s]\n",
      "100%|██████████| 12032/12032 [00:00<00:00, 2786937.58it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1870175.08it/s]\n",
      "Inferring Phrases: 100%|██████████| 12032/12032 [00:00<00:00, 229983.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4145 nodes still misclassified out of torch.Size([12032]) \n",
      "\n",
      "Model# 1. 4145 nodes still misclassified out of torch.Size([12032]) \n",
      "\n",
      "Model# 2. 4145 nodes still misclassified out of torch.Size([12032]) \n",
      "\n",
      "Model# 3. 4145 nodes still misclassified out of torch.Size([12032]) \n",
      "\n",
      "Model# 4. 4145 nodes still misclassified out of torch.Size([12032]) \n",
      "\n",
      "Model# 5. 4145 nodes still misclassified out of torch.Size([12032]) \n",
      "\n",
      "Model# 6. 4145 nodes still misclassified out of torch.Size([12032]) \n",
      "\n",
      "Model# 7. 4145 nodes still misclassified out of torch.Size([12032]) \n",
      "\n",
      "Model# 8. 4145 nodes still misclassified out of torch.Size([12032]) \n",
      "\n",
      "Model# 9. 4145 nodes still misclassified out of torch.Size([12032]) \n",
      "\n",
      "Model# 10. 4145 nodes still misclassified out of torch.Size([12032]) \n",
      "\n",
      "Model# 11. 4145 nodes still misclassified out of torch.Size([12032]) \n",
      "\n",
      "Model# 12. 4145 nodes still misclassified out of torch.Size([12032]) \n",
      "\n",
      "Model# 13. 4145 nodes still misclassified out of torch.Size([12032]) \n",
      "\n",
      "Model# 14. 4145 nodes still misclassified out of torch.Size([12032]) \n",
      "\n",
      "Model# 15. 4145 nodes still misclassified out of torch.Size([12032]) \n",
      "\n",
      "Model# 16. 4145 nodes still misclassified out of torch.Size([12032]) \n",
      "\n",
      "Model# 17. 4145 nodes still misclassified out of torch.Size([12032]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 213/299 [02:04<00:42,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 18. 4145 nodes still misclassified out of torch.Size([12032]) \n",
      "\n",
      "Model# 19. 4145 nodes still misclassified out of torch.Size([12032]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13411/13411 [00:00<00:00, 3503569.66it/s]\n",
      "100%|██████████| 13411/13411 [00:00<00:00, 4719735.77it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2667453.57it/s]\n",
      "Inferring Phrases: 100%|██████████| 13411/13411 [00:00<00:00, 409262.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5076 nodes still misclassified out of torch.Size([13411]) \n",
      "\n",
      "Model# 1. 5076 nodes still misclassified out of torch.Size([13411]) \n",
      "\n",
      "Model# 2. 5076 nodes still misclassified out of torch.Size([13411]) \n",
      "\n",
      "Model# 3. 5076 nodes still misclassified out of torch.Size([13411]) \n",
      "\n",
      "Model# 4. 5076 nodes still misclassified out of torch.Size([13411]) \n",
      "\n",
      "Model# 5. 5076 nodes still misclassified out of torch.Size([13411]) \n",
      "\n",
      "Model# 6. 5076 nodes still misclassified out of torch.Size([13411]) \n",
      "\n",
      "Model# 7. 5076 nodes still misclassified out of torch.Size([13411]) \n",
      "\n",
      "Model# 8. 5076 nodes still misclassified out of torch.Size([13411]) \n",
      "\n",
      "Model# 9. 5076 nodes still misclassified out of torch.Size([13411]) \n",
      "\n",
      "Model# 10. 5076 nodes still misclassified out of torch.Size([13411]) \n",
      "\n",
      "Model# 11. 5076 nodes still misclassified out of torch.Size([13411]) \n",
      "\n",
      "Model# 12. 5076 nodes still misclassified out of torch.Size([13411]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 214/299 [02:05<00:46,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 13. 5076 nodes still misclassified out of torch.Size([13411]) \n",
      "\n",
      "Model# 14. 5076 nodes still misclassified out of torch.Size([13411]) \n",
      "\n",
      "Model# 15. 5076 nodes still misclassified out of torch.Size([13411]) \n",
      "\n",
      "Model# 16. 5076 nodes still misclassified out of torch.Size([13411]) \n",
      "\n",
      "Model# 17. 5076 nodes still misclassified out of torch.Size([13411]) \n",
      "\n",
      "Model# 18. 5076 nodes still misclassified out of torch.Size([13411]) \n",
      "\n",
      "Model# 19. 5076 nodes still misclassified out of torch.Size([13411]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13864/13864 [00:00<00:00, 3983137.93it/s]\n",
      "100%|██████████| 13864/13864 [00:00<00:00, 4629763.59it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2704722.93it/s]\n",
      "Inferring Phrases: 100%|██████████| 13864/13864 [00:00<00:00, 390146.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5453 nodes still misclassified out of torch.Size([13864]) \n",
      "\n",
      "Model# 1. 5453 nodes still misclassified out of torch.Size([13864]) \n",
      "\n",
      "Model# 2. 5453 nodes still misclassified out of torch.Size([13864]) \n",
      "\n",
      "Model# 3. 5453 nodes still misclassified out of torch.Size([13864]) \n",
      "\n",
      "Model# 4. 5453 nodes still misclassified out of torch.Size([13864]) \n",
      "\n",
      "Model# 5. 5453 nodes still misclassified out of torch.Size([13864]) \n",
      "\n",
      "Model# 6. 5453 nodes still misclassified out of torch.Size([13864]) \n",
      "\n",
      "Model# 7. 5453 nodes still misclassified out of torch.Size([13864]) \n",
      "\n",
      "Model# 8. 5453 nodes still misclassified out of torch.Size([13864]) \n",
      "\n",
      "Model# 9. 5453 nodes still misclassified out of torch.Size([13864]) \n",
      "\n",
      "Model# 10. 5453 nodes still misclassified out of torch.Size([13864]) \n",
      "\n",
      "Model# 11. 5453 nodes still misclassified out of torch.Size([13864]) \n",
      "\n",
      "Model# 12. 5453 nodes still misclassified out of torch.Size([13864]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 215/299 [02:05<00:46,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 13. 5453 nodes still misclassified out of torch.Size([13864]) \n",
      "\n",
      "Model# 14. 5453 nodes still misclassified out of torch.Size([13864]) \n",
      "\n",
      "Model# 15. 5453 nodes still misclassified out of torch.Size([13864]) \n",
      "\n",
      "Model# 16. 5453 nodes still misclassified out of torch.Size([13864]) \n",
      "\n",
      "Model# 17. 5453 nodes still misclassified out of torch.Size([13864]) \n",
      "\n",
      "Model# 18. 5453 nodes still misclassified out of torch.Size([13864]) \n",
      "\n",
      "Model# 19. 5453 nodes still misclassified out of torch.Size([13864]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13215/13215 [00:00<00:00, 3996519.39it/s]\n",
      "100%|██████████| 13215/13215 [00:00<00:00, 4625530.11it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2710549.31it/s]\n",
      "Inferring Phrases: 100%|██████████| 13215/13215 [00:00<00:00, 384394.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4988 nodes still misclassified out of torch.Size([13215]) \n",
      "\n",
      "Model# 1. 4988 nodes still misclassified out of torch.Size([13215]) \n",
      "\n",
      "Model# 2. 4988 nodes still misclassified out of torch.Size([13215]) \n",
      "\n",
      "Model# 3. 4988 nodes still misclassified out of torch.Size([13215]) \n",
      "\n",
      "Model# 4. 4988 nodes still misclassified out of torch.Size([13215]) \n",
      "\n",
      "Model# 5. 4988 nodes still misclassified out of torch.Size([13215]) \n",
      "\n",
      "Model# 6. 4988 nodes still misclassified out of torch.Size([13215]) \n",
      "\n",
      "Model# 7. 4988 nodes still misclassified out of torch.Size([13215]) \n",
      "\n",
      "Model# 8. 4988 nodes still misclassified out of torch.Size([13215]) \n",
      "\n",
      "Model# 9. 4988 nodes still misclassified out of torch.Size([13215]) \n",
      "\n",
      "Model# 10. 4988 nodes still misclassified out of torch.Size([13215]) \n",
      "\n",
      "Model# 11. 4988 nodes still misclassified out of torch.Size([13215]) \n",
      "\n",
      "Model# 12. 4988 nodes still misclassified out of torch.Size([13215]) \n",
      "\n",
      "Model# 13. 4988 nodes still misclassified out of torch.Size([13215]) \n",
      "\n",
      "Model# 14. 4988 nodes still misclassified out of torch.Size([13215]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 216/299 [02:06<00:44,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4988 nodes still misclassified out of torch.Size([13215]) \n",
      "\n",
      "Model# 16. 4988 nodes still misclassified out of torch.Size([13215]) \n",
      "\n",
      "Model# 17. 4988 nodes still misclassified out of torch.Size([13215]) \n",
      "\n",
      "Model# 18. 4988 nodes still misclassified out of torch.Size([13215]) \n",
      "\n",
      "Model# 19. 4988 nodes still misclassified out of torch.Size([13215]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13537/13537 [00:00<00:00, 2551604.05it/s]\n",
      "100%|██████████| 13537/13537 [00:00<00:00, 3357675.53it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2588597.17it/s]\n",
      "Inferring Phrases: 100%|██████████| 13537/13537 [00:00<00:00, 415006.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5175 nodes still misclassified out of torch.Size([13537]) \n",
      "\n",
      "Model# 1. 5175 nodes still misclassified out of torch.Size([13537]) \n",
      "\n",
      "Model# 2. 5175 nodes still misclassified out of torch.Size([13537]) \n",
      "\n",
      "Model# 3. 5175 nodes still misclassified out of torch.Size([13537]) \n",
      "\n",
      "Model# 4. 5175 nodes still misclassified out of torch.Size([13537]) \n",
      "\n",
      "Model# 5. 5175 nodes still misclassified out of torch.Size([13537]) \n",
      "\n",
      "Model# 6. 5175 nodes still misclassified out of torch.Size([13537]) \n",
      "\n",
      "Model# 7. 5175 nodes still misclassified out of torch.Size([13537]) \n",
      "\n",
      "Model# 8. 5175 nodes still misclassified out of torch.Size([13537]) \n",
      "\n",
      "Model# 9. 5175 nodes still misclassified out of torch.Size([13537]) \n",
      "\n",
      "Model# 10. 5175 nodes still misclassified out of torch.Size([13537]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 217/299 [02:06<00:49,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 5175 nodes still misclassified out of torch.Size([13537]) \n",
      "\n",
      "Model# 12. 5175 nodes still misclassified out of torch.Size([13537]) \n",
      "\n",
      "Model# 13. 5175 nodes still misclassified out of torch.Size([13537]) \n",
      "\n",
      "Model# 14. 5175 nodes still misclassified out of torch.Size([13537]) \n",
      "\n",
      "Model# 15. 5175 nodes still misclassified out of torch.Size([13537]) \n",
      "\n",
      "Model# 16. 5175 nodes still misclassified out of torch.Size([13537]) \n",
      "\n",
      "Model# 17. 5175 nodes still misclassified out of torch.Size([13537]) \n",
      "\n",
      "Model# 18. 5175 nodes still misclassified out of torch.Size([13537]) \n",
      "\n",
      "Model# 19. 5175 nodes still misclassified out of torch.Size([13537]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13366/13366 [00:00<00:00, 4079838.97it/s]\n",
      "100%|██████████| 13366/13366 [00:00<00:00, 4767908.43it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2731733.75it/s]\n",
      "Inferring Phrases: 100%|██████████| 13366/13366 [00:00<00:00, 383885.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5209 nodes still misclassified out of torch.Size([13366]) \n",
      "\n",
      "Model# 1. 5209 nodes still misclassified out of torch.Size([13366]) \n",
      "\n",
      "Model# 2. 5209 nodes still misclassified out of torch.Size([13366]) \n",
      "\n",
      "Model# 3. 5209 nodes still misclassified out of torch.Size([13366]) \n",
      "\n",
      "Model# 4. 5209 nodes still misclassified out of torch.Size([13366]) \n",
      "\n",
      "Model# 5. 5209 nodes still misclassified out of torch.Size([13366]) \n",
      "\n",
      "Model# 6. 5209 nodes still misclassified out of torch.Size([13366]) \n",
      "\n",
      "Model# 7. 5209 nodes still misclassified out of torch.Size([13366]) \n",
      "\n",
      "Model# 8. 5209 nodes still misclassified out of torch.Size([13366]) \n",
      "\n",
      "Model# 9. 5209 nodes still misclassified out of torch.Size([13366]) \n",
      "\n",
      "Model# 10. 5209 nodes still misclassified out of torch.Size([13366]) \n",
      "\n",
      "Model# 11. 5209 nodes still misclassified out of torch.Size([13366]) \n",
      "\n",
      "Model# 12. 5209 nodes still misclassified out of torch.Size([13366]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 218/299 [02:07<00:46,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 13. 5209 nodes still misclassified out of torch.Size([13366]) \n",
      "\n",
      "Model# 14. 5209 nodes still misclassified out of torch.Size([13366]) \n",
      "\n",
      "Model# 15. 5209 nodes still misclassified out of torch.Size([13366]) \n",
      "\n",
      "Model# 16. 5209 nodes still misclassified out of torch.Size([13366]) \n",
      "\n",
      "Model# 17. 5209 nodes still misclassified out of torch.Size([13366]) \n",
      "\n",
      "Model# 18. 5209 nodes still misclassified out of torch.Size([13366]) \n",
      "\n",
      "Model# 19. 5209 nodes still misclassified out of torch.Size([13366]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13806/13806 [00:00<00:00, 4014876.31it/s]\n",
      "100%|██████████| 13806/13806 [00:00<00:00, 4761661.13it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2653447.21it/s]\n",
      "Inferring Phrases: 100%|██████████| 13806/13806 [00:00<00:00, 396156.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5720 nodes still misclassified out of torch.Size([13806]) \n",
      "\n",
      "Model# 1. 5720 nodes still misclassified out of torch.Size([13806]) \n",
      "\n",
      "Model# 2. 5720 nodes still misclassified out of torch.Size([13806]) \n",
      "\n",
      "Model# 3. 5720 nodes still misclassified out of torch.Size([13806]) \n",
      "\n",
      "Model# 4. 5720 nodes still misclassified out of torch.Size([13806]) \n",
      "\n",
      "Model# 5. 5720 nodes still misclassified out of torch.Size([13806]) \n",
      "\n",
      "Model# 6. 5720 nodes still misclassified out of torch.Size([13806]) \n",
      "\n",
      "Model# 7. 5720 nodes still misclassified out of torch.Size([13806]) \n",
      "\n",
      "Model# 8. 5720 nodes still misclassified out of torch.Size([13806]) \n",
      "\n",
      "Model# 9. 5720 nodes still misclassified out of torch.Size([13806]) \n",
      "\n",
      "Model# 10. 5720 nodes still misclassified out of torch.Size([13806]) \n",
      "\n",
      "Model# 11. 5720 nodes still misclassified out of torch.Size([13806]) \n",
      "\n",
      "Model# 12. 5720 nodes still misclassified out of torch.Size([13806]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 219/299 [02:07<00:44,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 13. 5720 nodes still misclassified out of torch.Size([13806]) \n",
      "\n",
      "Model# 14. 5720 nodes still misclassified out of torch.Size([13806]) \n",
      "\n",
      "Model# 15. 5720 nodes still misclassified out of torch.Size([13806]) \n",
      "\n",
      "Model# 16. 5720 nodes still misclassified out of torch.Size([13806]) \n",
      "\n",
      "Model# 17. 5720 nodes still misclassified out of torch.Size([13806]) \n",
      "\n",
      "Model# 18. 5720 nodes still misclassified out of torch.Size([13806]) \n",
      "\n",
      "Model# 19. 5720 nodes still misclassified out of torch.Size([13806]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13009/13009 [00:00<00:00, 4088393.58it/s]\n",
      "100%|██████████| 13009/13009 [00:00<00:00, 5000339.14it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2507755.10it/s]\n",
      "Inferring Phrases: 100%|██████████| 13009/13009 [00:00<00:00, 405973.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4790 nodes still misclassified out of torch.Size([13009]) \n",
      "\n",
      "Model# 1. 4790 nodes still misclassified out of torch.Size([13009]) \n",
      "\n",
      "Model# 2. 4790 nodes still misclassified out of torch.Size([13009]) \n",
      "\n",
      "Model# 3. 4790 nodes still misclassified out of torch.Size([13009]) \n",
      "\n",
      "Model# 4. 4790 nodes still misclassified out of torch.Size([13009]) \n",
      "\n",
      "Model# 5. 4790 nodes still misclassified out of torch.Size([13009]) \n",
      "\n",
      "Model# 6. 4790 nodes still misclassified out of torch.Size([13009]) \n",
      "\n",
      "Model# 7. 4790 nodes still misclassified out of torch.Size([13009]) \n",
      "\n",
      "Model# 8. 4790 nodes still misclassified out of torch.Size([13009]) \n",
      "\n",
      "Model# 9. 4790 nodes still misclassified out of torch.Size([13009]) \n",
      "\n",
      "Model# 10. 4790 nodes still misclassified out of torch.Size([13009]) \n",
      "\n",
      "Model# 11. 4790 nodes still misclassified out of torch.Size([13009]) \n",
      "\n",
      "Model# 12. 4790 nodes still misclassified out of torch.Size([13009]) \n",
      "\n",
      "Model# 13. 4790 nodes still misclassified out of torch.Size([13009]) \n",
      "\n",
      "Model# 14. 4790 nodes still misclassified out of torch.Size([13009]) \n",
      "\n",
      "Model# 15. 4790 nodes still misclassified out of torch.Size([13009]) \n",
      "\n",
      "Model# 16. 4790 nodes still misclassified out of torch.Size([13009]) \n",
      "\n",
      "Model# 17. 4790 nodes still misclassified out of torch.Size([13009]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 220/299 [02:08<00:44,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 18. 4790 nodes still misclassified out of torch.Size([13009]) \n",
      "\n",
      "Model# 19. 4790 nodes still misclassified out of torch.Size([13009]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12901/12901 [00:00<00:00, 3843363.58it/s]\n",
      "100%|██████████| 12901/12901 [00:00<00:00, 4552857.88it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2767543.22it/s]\n",
      "Inferring Phrases: 100%|██████████| 12901/12901 [00:00<00:00, 368852.87it/s]\n",
      " 74%|███████▍  | 221/299 [02:08<00:40,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3477 nodes still misclassified out of torch.Size([12901]) \n",
      "\n",
      "Model# 1. 3477 nodes still misclassified out of torch.Size([12901]) \n",
      "\n",
      "Model# 2. 3477 nodes still misclassified out of torch.Size([12901]) \n",
      "\n",
      "Model# 3. 3477 nodes still misclassified out of torch.Size([12901]) \n",
      "\n",
      "Model# 4. 3477 nodes still misclassified out of torch.Size([12901]) \n",
      "\n",
      "Model# 5. 3477 nodes still misclassified out of torch.Size([12901]) \n",
      "\n",
      "Model# 6. 3477 nodes still misclassified out of torch.Size([12901]) \n",
      "\n",
      "Model# 7. 3477 nodes still misclassified out of torch.Size([12901]) \n",
      "\n",
      "Model# 8. 3477 nodes still misclassified out of torch.Size([12901]) \n",
      "\n",
      "Model# 9. 3477 nodes still misclassified out of torch.Size([12901]) \n",
      "\n",
      "Model# 10. 3477 nodes still misclassified out of torch.Size([12901]) \n",
      "\n",
      "Model# 11. 3477 nodes still misclassified out of torch.Size([12901]) \n",
      "\n",
      "Model# 12. 3477 nodes still misclassified out of torch.Size([12901]) \n",
      "\n",
      "Model# 13. 3477 nodes still misclassified out of torch.Size([12901]) \n",
      "\n",
      "Model# 14. 3477 nodes still misclassified out of torch.Size([12901]) \n",
      "\n",
      "Model# 15. 3477 nodes still misclassified out of torch.Size([12901]) \n",
      "\n",
      "Model# 16. 3477 nodes still misclassified out of torch.Size([12901]) \n",
      "\n",
      "Model# 17. 3477 nodes still misclassified out of torch.Size([12901]) \n",
      "\n",
      "Model# 18. 3477 nodes still misclassified out of torch.Size([12901]) \n",
      "\n",
      "Model# 19. 3477 nodes still misclassified out of torch.Size([12901]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12767/12767 [00:00<00:00, 3983091.28it/s]\n",
      "100%|██████████| 12767/12767 [00:00<00:00, 4604357.62it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2760863.61it/s]\n",
      "Inferring Phrases: 100%|██████████| 12767/12767 [00:00<00:00, 376480.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4746 nodes still misclassified out of torch.Size([12767]) \n",
      "\n",
      "Model# 1. 4746 nodes still misclassified out of torch.Size([12767]) \n",
      "\n",
      "Model# 2. 4746 nodes still misclassified out of torch.Size([12767]) \n",
      "\n",
      "Model# 3. 4746 nodes still misclassified out of torch.Size([12767]) \n",
      "\n",
      "Model# 4. 4746 nodes still misclassified out of torch.Size([12767]) \n",
      "\n",
      "Model# 5. 4746 nodes still misclassified out of torch.Size([12767]) \n",
      "\n",
      "Model# 6. 4746 nodes still misclassified out of torch.Size([12767]) \n",
      "\n",
      "Model# 7. 4746 nodes still misclassified out of torch.Size([12767]) \n",
      "\n",
      "Model# 8. 4746 nodes still misclassified out of torch.Size([12767]) \n",
      "\n",
      "Model# 9. 4746 nodes still misclassified out of torch.Size([12767]) \n",
      "\n",
      "Model# 10. 4746 nodes still misclassified out of torch.Size([12767]) \n",
      "\n",
      "Model# 11. 4746 nodes still misclassified out of torch.Size([12767]) \n",
      "\n",
      "Model# 12. 4746 nodes still misclassified out of torch.Size([12767]) \n",
      "\n",
      "Model# 13. 4746 nodes still misclassified out of torch.Size([12767]) \n",
      "\n",
      "Model# 14. 4746 nodes still misclassified out of torch.Size([12767]) \n",
      "\n",
      "Model# 15. 4746 nodes still misclassified out of torch.Size([12767]) \n",
      "\n",
      "Model# 16. 4746 nodes still misclassified out of torch.Size([12767]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 222/299 [02:09<00:37,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 17. 4746 nodes still misclassified out of torch.Size([12767]) \n",
      "\n",
      "Model# 18. 4746 nodes still misclassified out of torch.Size([12767]) \n",
      "\n",
      "Model# 19. 4746 nodes still misclassified out of torch.Size([12767]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12650/12650 [00:00<00:00, 4170894.24it/s]\n",
      "100%|██████████| 12650/12650 [00:00<00:00, 4954981.85it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2675621.33it/s]\n",
      "Inferring Phrases: 100%|██████████| 12650/12650 [00:00<00:00, 402921.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4599 nodes still misclassified out of torch.Size([12650]) \n",
      "\n",
      "Model# 1. 4599 nodes still misclassified out of torch.Size([12650]) \n",
      "\n",
      "Model# 2. 4599 nodes still misclassified out of torch.Size([12650]) \n",
      "\n",
      "Model# 3. 4599 nodes still misclassified out of torch.Size([12650]) \n",
      "\n",
      "Model# 4. 4599 nodes still misclassified out of torch.Size([12650]) \n",
      "\n",
      "Model# 5. 4599 nodes still misclassified out of torch.Size([12650]) \n",
      "\n",
      "Model# 6. 4599 nodes still misclassified out of torch.Size([12650]) \n",
      "\n",
      "Model# 7. 4599 nodes still misclassified out of torch.Size([12650]) \n",
      "\n",
      "Model# 8. 4599 nodes still misclassified out of torch.Size([12650]) \n",
      "\n",
      "Model# 9. 4599 nodes still misclassified out of torch.Size([12650]) \n",
      "\n",
      "Model# 10. 4599 nodes still misclassified out of torch.Size([12650]) \n",
      "\n",
      "Model# 11. 4599 nodes still misclassified out of torch.Size([12650]) \n",
      "\n",
      "Model# 12. 4599 nodes still misclassified out of torch.Size([12650]) \n",
      "\n",
      "Model# 13. 4599 nodes still misclassified out of torch.Size([12650]) \n",
      "\n",
      "Model# 14. 4599 nodes still misclassified out of torch.Size([12650]) \n",
      "\n",
      "Model# 15. 4599 nodes still misclassified out of torch.Size([12650]) \n",
      "\n",
      "Model# 16. 4599 nodes still misclassified out of torch.Size([12650]) \n",
      "\n",
      "Model# 17. 4599 nodes still misclassified out of torch.Size([12650]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 223/299 [02:09<00:39,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 18. 4599 nodes still misclassified out of torch.Size([12650]) \n",
      "\n",
      "Model# 19. 4599 nodes still misclassified out of torch.Size([12650]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14044/14044 [00:00<00:00, 3807187.52it/s]\n",
      "100%|██████████| 14044/14044 [00:00<00:00, 4560960.54it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2582752.52it/s]\n",
      "Inferring Phrases: 100%|██████████| 14044/14044 [00:00<00:00, 402253.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5524 nodes still misclassified out of torch.Size([14044]) \n",
      "\n",
      "Model# 1. 5524 nodes still misclassified out of torch.Size([14044]) \n",
      "\n",
      "Model# 2. 5524 nodes still misclassified out of torch.Size([14044]) \n",
      "\n",
      "Model# 3. 5524 nodes still misclassified out of torch.Size([14044]) \n",
      "\n",
      "Model# 4. 5524 nodes still misclassified out of torch.Size([14044]) \n",
      "\n",
      "Model# 5. 5524 nodes still misclassified out of torch.Size([14044]) \n",
      "\n",
      "Model# 6. 5524 nodes still misclassified out of torch.Size([14044]) \n",
      "\n",
      "Model# 7. 5524 nodes still misclassified out of torch.Size([14044]) \n",
      "\n",
      "Model# 8. 5524 nodes still misclassified out of torch.Size([14044]) \n",
      "\n",
      "Model# 9. 5524 nodes still misclassified out of torch.Size([14044]) \n",
      "\n",
      "Model# 10. 5524 nodes still misclassified out of torch.Size([14044]) \n",
      "\n",
      "Model# 11. 5524 nodes still misclassified out of torch.Size([14044]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 224/299 [02:10<00:40,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 12. 5524 nodes still misclassified out of torch.Size([14044]) \n",
      "\n",
      "Model# 13. 5524 nodes still misclassified out of torch.Size([14044]) \n",
      "\n",
      "Model# 14. 5524 nodes still misclassified out of torch.Size([14044]) \n",
      "\n",
      "Model# 15. 5524 nodes still misclassified out of torch.Size([14044]) \n",
      "\n",
      "Model# 16. 5524 nodes still misclassified out of torch.Size([14044]) \n",
      "\n",
      "Model# 17. 5524 nodes still misclassified out of torch.Size([14044]) \n",
      "\n",
      "Model# 18. 5524 nodes still misclassified out of torch.Size([14044]) \n",
      "\n",
      "Model# 19. 5524 nodes still misclassified out of torch.Size([14044]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14590/14590 [00:00<00:00, 4079115.81it/s]\n",
      "100%|██████████| 14590/14590 [00:00<00:00, 5039520.33it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2745562.30it/s]\n",
      "Inferring Phrases: 100%|██████████| 14590/14590 [00:00<00:00, 455061.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6252 nodes still misclassified out of torch.Size([14590]) \n",
      "\n",
      "Model# 1. 6252 nodes still misclassified out of torch.Size([14590]) \n",
      "\n",
      "Model# 2. 6252 nodes still misclassified out of torch.Size([14590]) \n",
      "\n",
      "Model# 3. 6252 nodes still misclassified out of torch.Size([14590]) \n",
      "\n",
      "Model# 4. 6252 nodes still misclassified out of torch.Size([14590]) \n",
      "\n",
      "Model# 5. 6252 nodes still misclassified out of torch.Size([14590]) \n",
      "\n",
      "Model# 6. 6252 nodes still misclassified out of torch.Size([14590]) \n",
      "\n",
      "Model# 7. 6252 nodes still misclassified out of torch.Size([14590]) \n",
      "\n",
      "Model# 8. 6252 nodes still misclassified out of torch.Size([14590]) \n",
      "\n",
      "Model# 9. 6252 nodes still misclassified out of torch.Size([14590]) \n",
      "\n",
      "Model# 10. 6252 nodes still misclassified out of torch.Size([14590]) \n",
      "\n",
      "Model# 11. 6252 nodes still misclassified out of torch.Size([14590]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 225/299 [02:11<00:43,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 12. 6252 nodes still misclassified out of torch.Size([14590]) \n",
      "\n",
      "Model# 13. 6252 nodes still misclassified out of torch.Size([14590]) \n",
      "\n",
      "Model# 14. 6252 nodes still misclassified out of torch.Size([14590]) \n",
      "\n",
      "Model# 15. 6252 nodes still misclassified out of torch.Size([14590]) \n",
      "\n",
      "Model# 16. 6252 nodes still misclassified out of torch.Size([14590]) \n",
      "\n",
      "Model# 17. 6252 nodes still misclassified out of torch.Size([14590]) \n",
      "\n",
      "Model# 18. 6252 nodes still misclassified out of torch.Size([14590]) \n",
      "\n",
      "Model# 19. 6252 nodes still misclassified out of torch.Size([14590]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13656/13656 [00:00<00:00, 3941468.17it/s]\n",
      "100%|██████████| 13656/13656 [00:00<00:00, 4625487.80it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2735653.54it/s]\n",
      "Inferring Phrases: 100%|██████████| 13656/13656 [00:00<00:00, 386270.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4345 nodes still misclassified out of torch.Size([13656]) \n",
      "\n",
      "Model# 1. 4345 nodes still misclassified out of torch.Size([13656]) \n",
      "\n",
      "Model# 2. 4345 nodes still misclassified out of torch.Size([13656]) \n",
      "\n",
      "Model# 3. 4345 nodes still misclassified out of torch.Size([13656]) \n",
      "\n",
      "Model# 4. 4345 nodes still misclassified out of torch.Size([13656]) \n",
      "\n",
      "Model# 5. 4345 nodes still misclassified out of torch.Size([13656]) \n",
      "\n",
      "Model# 6. 4345 nodes still misclassified out of torch.Size([13656]) \n",
      "\n",
      "Model# 7. 4345 nodes still misclassified out of torch.Size([13656]) \n",
      "\n",
      "Model# 8. 4345 nodes still misclassified out of torch.Size([13656]) \n",
      "\n",
      "Model# 9. 4345 nodes still misclassified out of torch.Size([13656]) \n",
      "\n",
      "Model# 10. 4345 nodes still misclassified out of torch.Size([13656]) \n",
      "\n",
      "Model# 11. 4345 nodes still misclassified out of torch.Size([13656]) \n",
      "\n",
      "Model# 12. 4345 nodes still misclassified out of torch.Size([13656]) \n",
      "\n",
      "Model# 13. 4345 nodes still misclassified out of torch.Size([13656]) \n",
      "\n",
      "Model# 14. 4345 nodes still misclassified out of torch.Size([13656]) \n",
      "\n",
      "Model# 15. 4345 nodes still misclassified out of torch.Size([13656]) \n",
      "\n",
      "Model# 16. 4345 nodes still misclassified out of torch.Size([13656]) \n",
      "\n",
      "Model# 17. 4345 nodes still misclassified out of torch.Size([13656]) \n",
      "\n",
      "Model# 18. 4345 nodes still misclassified out of torch.Size([13656]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 226/299 [02:11<00:38,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4345 nodes still misclassified out of torch.Size([13656]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14164/14164 [00:00<00:00, 3939269.40it/s]\n",
      "100%|██████████| 14164/14164 [00:00<00:00, 4563536.78it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2721041.45it/s]\n",
      "Inferring Phrases: 100%|██████████| 14164/14164 [00:00<00:00, 396665.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5793 nodes still misclassified out of torch.Size([14164]) \n",
      "\n",
      "Model# 1. 5793 nodes still misclassified out of torch.Size([14164]) \n",
      "\n",
      "Model# 2. 5793 nodes still misclassified out of torch.Size([14164]) \n",
      "\n",
      "Model# 3. 5793 nodes still misclassified out of torch.Size([14164]) \n",
      "\n",
      "Model# 4. 5793 nodes still misclassified out of torch.Size([14164]) \n",
      "\n",
      "Model# 5. 5793 nodes still misclassified out of torch.Size([14164]) \n",
      "\n",
      "Model# 6. 5793 nodes still misclassified out of torch.Size([14164]) \n",
      "\n",
      "Model# 7. 5793 nodes still misclassified out of torch.Size([14164]) \n",
      "\n",
      "Model# 8. 5793 nodes still misclassified out of torch.Size([14164]) \n",
      "\n",
      "Model# 9. 5793 nodes still misclassified out of torch.Size([14164]) \n",
      "\n",
      "Model# 10. 5793 nodes still misclassified out of torch.Size([14164]) \n",
      "\n",
      "Model# 11. 5793 nodes still misclassified out of torch.Size([14164]) \n",
      "\n",
      "Model# 12. 5793 nodes still misclassified out of torch.Size([14164]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 227/299 [02:12<00:38,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 13. 5793 nodes still misclassified out of torch.Size([14164]) \n",
      "\n",
      "Model# 14. 5793 nodes still misclassified out of torch.Size([14164]) \n",
      "\n",
      "Model# 15. 5793 nodes still misclassified out of torch.Size([14164]) \n",
      "\n",
      "Model# 16. 5793 nodes still misclassified out of torch.Size([14164]) \n",
      "\n",
      "Model# 17. 5793 nodes still misclassified out of torch.Size([14164]) \n",
      "\n",
      "Model# 18. 5793 nodes still misclassified out of torch.Size([14164]) \n",
      "\n",
      "Model# 19. 5793 nodes still misclassified out of torch.Size([14164]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14086/14086 [00:00<00:00, 4147779.15it/s]\n",
      "100%|██████████| 14086/14086 [00:00<00:00, 4928342.19it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2745083.12it/s]\n",
      "Inferring Phrases: 100%|██████████| 14086/14086 [00:00<00:00, 420074.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5743 nodes still misclassified out of torch.Size([14086]) \n",
      "\n",
      "Model# 1. 5743 nodes still misclassified out of torch.Size([14086]) \n",
      "\n",
      "Model# 2. 5743 nodes still misclassified out of torch.Size([14086]) \n",
      "\n",
      "Model# 3. 5743 nodes still misclassified out of torch.Size([14086]) \n",
      "\n",
      "Model# 4. 5743 nodes still misclassified out of torch.Size([14086]) \n",
      "\n",
      "Model# 5. 5743 nodes still misclassified out of torch.Size([14086]) \n",
      "\n",
      "Model# 6. 5743 nodes still misclassified out of torch.Size([14086]) \n",
      "\n",
      "Model# 7. 5743 nodes still misclassified out of torch.Size([14086]) \n",
      "\n",
      "Model# 8. 5743 nodes still misclassified out of torch.Size([14086]) \n",
      "\n",
      "Model# 9. 5743 nodes still misclassified out of torch.Size([14086]) \n",
      "\n",
      "Model# 10. 5743 nodes still misclassified out of torch.Size([14086]) \n",
      "\n",
      "Model# 11. 5743 nodes still misclassified out of torch.Size([14086]) \n",
      "\n",
      "Model# 12. 5743 nodes still misclassified out of torch.Size([14086]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 228/299 [02:12<00:40,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 13. 5743 nodes still misclassified out of torch.Size([14086]) \n",
      "\n",
      "Model# 14. 5743 nodes still misclassified out of torch.Size([14086]) \n",
      "\n",
      "Model# 15. 5743 nodes still misclassified out of torch.Size([14086]) \n",
      "\n",
      "Model# 16. 5743 nodes still misclassified out of torch.Size([14086]) \n",
      "\n",
      "Model# 17. 5743 nodes still misclassified out of torch.Size([14086]) \n",
      "\n",
      "Model# 18. 5743 nodes still misclassified out of torch.Size([14086]) \n",
      "\n",
      "Model# 19. 5743 nodes still misclassified out of torch.Size([14086]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13509/13509 [00:00<00:00, 3933961.86it/s]\n",
      "100%|██████████| 13509/13509 [00:00<00:00, 4753427.24it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2658885.98it/s]\n",
      "Inferring Phrases: 100%|██████████| 13509/13509 [00:00<00:00, 387710.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5078 nodes still misclassified out of torch.Size([13509]) \n",
      "\n",
      "Model# 1. 5078 nodes still misclassified out of torch.Size([13509]) \n",
      "\n",
      "Model# 2. 5078 nodes still misclassified out of torch.Size([13509]) \n",
      "\n",
      "Model# 3. 5078 nodes still misclassified out of torch.Size([13509]) \n",
      "\n",
      "Model# 4. 5078 nodes still misclassified out of torch.Size([13509]) \n",
      "\n",
      "Model# 5. 5078 nodes still misclassified out of torch.Size([13509]) \n",
      "\n",
      "Model# 6. 5078 nodes still misclassified out of torch.Size([13509]) \n",
      "\n",
      "Model# 7. 5078 nodes still misclassified out of torch.Size([13509]) \n",
      "\n",
      "Model# 8. 5078 nodes still misclassified out of torch.Size([13509]) \n",
      "\n",
      "Model# 9. 5078 nodes still misclassified out of torch.Size([13509]) \n",
      "\n",
      "Model# 10. 5078 nodes still misclassified out of torch.Size([13509]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 229/299 [02:13<00:40,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 5078 nodes still misclassified out of torch.Size([13509]) \n",
      "\n",
      "Model# 12. 5078 nodes still misclassified out of torch.Size([13509]) \n",
      "\n",
      "Model# 13. 5078 nodes still misclassified out of torch.Size([13509]) \n",
      "\n",
      "Model# 14. 5078 nodes still misclassified out of torch.Size([13509]) \n",
      "\n",
      "Model# 15. 5078 nodes still misclassified out of torch.Size([13509]) \n",
      "\n",
      "Model# 16. 5078 nodes still misclassified out of torch.Size([13509]) \n",
      "\n",
      "Model# 17. 5078 nodes still misclassified out of torch.Size([13509]) \n",
      "\n",
      "Model# 18. 5078 nodes still misclassified out of torch.Size([13509]) \n",
      "\n",
      "Model# 19. 5078 nodes still misclassified out of torch.Size([13509]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13242/13242 [00:00<00:00, 2716737.11it/s]\n",
      "100%|██████████| 13242/13242 [00:00<00:00, 3399496.48it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2270341.19it/s]\n",
      "Inferring Phrases: 100%|██████████| 13242/13242 [00:00<00:00, 363845.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4912 nodes still misclassified out of torch.Size([13242]) \n",
      "\n",
      "Model# 1. 4912 nodes still misclassified out of torch.Size([13242]) \n",
      "\n",
      "Model# 2. 4912 nodes still misclassified out of torch.Size([13242]) \n",
      "\n",
      "Model# 3. 4912 nodes still misclassified out of torch.Size([13242]) \n",
      "\n",
      "Model# 4. 4912 nodes still misclassified out of torch.Size([13242]) \n",
      "\n",
      "Model# 5. 4912 nodes still misclassified out of torch.Size([13242]) \n",
      "\n",
      "Model# 6. 4912 nodes still misclassified out of torch.Size([13242]) \n",
      "\n",
      "Model# 7. 4912 nodes still misclassified out of torch.Size([13242]) \n",
      "\n",
      "Model# 8. 4912 nodes still misclassified out of torch.Size([13242]) \n",
      "\n",
      "Model# 9. 4912 nodes still misclassified out of torch.Size([13242]) \n",
      "\n",
      "Model# 10. 4912 nodes still misclassified out of torch.Size([13242]) \n",
      "\n",
      "Model# 11. 4912 nodes still misclassified out of torch.Size([13242]) \n",
      "\n",
      "Model# 12. 4912 nodes still misclassified out of torch.Size([13242]) \n",
      "\n",
      "Model# 13. 4912 nodes still misclassified out of torch.Size([13242]) \n",
      "\n",
      "Model# 14. 4912 nodes still misclassified out of torch.Size([13242]) \n",
      "\n",
      "Model# 15. 4912 nodes still misclassified out of torch.Size([13242]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 230/299 [02:13<00:38,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 16. 4912 nodes still misclassified out of torch.Size([13242]) \n",
      "\n",
      "Model# 17. 4912 nodes still misclassified out of torch.Size([13242]) \n",
      "\n",
      "Model# 18. 4912 nodes still misclassified out of torch.Size([13242]) \n",
      "\n",
      "Model# 19. 4912 nodes still misclassified out of torch.Size([13242]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12851/12851 [00:00<00:00, 3725789.78it/s]\n",
      "100%|██████████| 12851/12851 [00:00<00:00, 4954136.09it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2671701.38it/s]\n",
      "Inferring Phrases: 100%|██████████| 12851/12851 [00:00<00:00, 396803.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4946 nodes still misclassified out of torch.Size([12851]) \n",
      "\n",
      "Model# 1. 4946 nodes still misclassified out of torch.Size([12851]) \n",
      "\n",
      "Model# 2. 4946 nodes still misclassified out of torch.Size([12851]) \n",
      "\n",
      "Model# 3. 4946 nodes still misclassified out of torch.Size([12851]) \n",
      "\n",
      "Model# 4. 4946 nodes still misclassified out of torch.Size([12851]) \n",
      "\n",
      "Model# 5. 4946 nodes still misclassified out of torch.Size([12851]) \n",
      "\n",
      "Model# 6. 4946 nodes still misclassified out of torch.Size([12851]) \n",
      "\n",
      "Model# 7. 4946 nodes still misclassified out of torch.Size([12851]) \n",
      "\n",
      "Model# 8. 4946 nodes still misclassified out of torch.Size([12851]) \n",
      "\n",
      "Model# 9. 4946 nodes still misclassified out of torch.Size([12851]) \n",
      "\n",
      "Model# 10. 4946 nodes still misclassified out of torch.Size([12851]) \n",
      "\n",
      "Model# 11. 4946 nodes still misclassified out of torch.Size([12851]) \n",
      "\n",
      "Model# 12. 4946 nodes still misclassified out of torch.Size([12851]) \n",
      "\n",
      "Model# 13. 4946 nodes still misclassified out of torch.Size([12851]) \n",
      "\n",
      "Model# 14. 4946 nodes still misclassified out of torch.Size([12851]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 231/299 [02:14<00:40,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4946 nodes still misclassified out of torch.Size([12851]) \n",
      "\n",
      "Model# 16. 4946 nodes still misclassified out of torch.Size([12851]) \n",
      "\n",
      "Model# 17. 4946 nodes still misclassified out of torch.Size([12851]) \n",
      "\n",
      "Model# 18. 4946 nodes still misclassified out of torch.Size([12851]) \n",
      "\n",
      "Model# 19. 4946 nodes still misclassified out of torch.Size([12851]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13072/13072 [00:00<00:00, 2608122.06it/s]\n",
      "100%|██████████| 13072/13072 [00:00<00:00, 2976867.30it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1881669.48it/s]\n",
      "Inferring Phrases: 100%|██████████| 13072/13072 [00:00<00:00, 366729.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4820 nodes still misclassified out of torch.Size([13072]) \n",
      "\n",
      "Model# 1. 4820 nodes still misclassified out of torch.Size([13072]) \n",
      "\n",
      "Model# 2. 4820 nodes still misclassified out of torch.Size([13072]) \n",
      "\n",
      "Model# 3. 4820 nodes still misclassified out of torch.Size([13072]) \n",
      "\n",
      "Model# 4. 4820 nodes still misclassified out of torch.Size([13072]) \n",
      "\n",
      "Model# 5. 4820 nodes still misclassified out of torch.Size([13072]) \n",
      "\n",
      "Model# 6. 4820 nodes still misclassified out of torch.Size([13072]) \n",
      "\n",
      "Model# 7. 4820 nodes still misclassified out of torch.Size([13072]) \n",
      "\n",
      "Model# 8. 4820 nodes still misclassified out of torch.Size([13072]) \n",
      "\n",
      "Model# 9. 4820 nodes still misclassified out of torch.Size([13072]) \n",
      "\n",
      "Model# 10. 4820 nodes still misclassified out of torch.Size([13072]) \n",
      "\n",
      "Model# 11. 4820 nodes still misclassified out of torch.Size([13072]) \n",
      "\n",
      "Model# 12. 4820 nodes still misclassified out of torch.Size([13072]) \n",
      "\n",
      "Model# 13. 4820 nodes still misclassified out of torch.Size([13072]) \n",
      "\n",
      "Model# 14. 4820 nodes still misclassified out of torch.Size([13072]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 232/299 [02:15<00:38,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4820 nodes still misclassified out of torch.Size([13072]) \n",
      "\n",
      "Model# 16. 4820 nodes still misclassified out of torch.Size([13072]) \n",
      "\n",
      "Model# 17. 4820 nodes still misclassified out of torch.Size([13072]) \n",
      "\n",
      "Model# 18. 4820 nodes still misclassified out of torch.Size([13072]) \n",
      "\n",
      "Model# 19. 4820 nodes still misclassified out of torch.Size([13072]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13230/13230 [00:00<00:00, 4139239.29it/s]\n",
      "100%|██████████| 13230/13230 [00:00<00:00, 4950543.48it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2675393.77it/s]\n",
      "Inferring Phrases: 100%|██████████| 13230/13230 [00:00<00:00, 414338.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5032 nodes still misclassified out of torch.Size([13230]) \n",
      "\n",
      "Model# 1. 5032 nodes still misclassified out of torch.Size([13230]) \n",
      "\n",
      "Model# 2. 5032 nodes still misclassified out of torch.Size([13230]) \n",
      "\n",
      "Model# 3. 5032 nodes still misclassified out of torch.Size([13230]) \n",
      "\n",
      "Model# 4. 5032 nodes still misclassified out of torch.Size([13230]) \n",
      "\n",
      "Model# 5. 5032 nodes still misclassified out of torch.Size([13230]) \n",
      "\n",
      "Model# 6. 5032 nodes still misclassified out of torch.Size([13230]) \n",
      "\n",
      "Model# 7. 5032 nodes still misclassified out of torch.Size([13230]) \n",
      "\n",
      "Model# 8. 5032 nodes still misclassified out of torch.Size([13230]) \n",
      "\n",
      "Model# 9. 5032 nodes still misclassified out of torch.Size([13230]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 233/299 [02:15<00:42,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 5032 nodes still misclassified out of torch.Size([13230]) \n",
      "\n",
      "Model# 11. 5032 nodes still misclassified out of torch.Size([13230]) \n",
      "\n",
      "Model# 12. 5032 nodes still misclassified out of torch.Size([13230]) \n",
      "\n",
      "Model# 13. 5032 nodes still misclassified out of torch.Size([13230]) \n",
      "\n",
      "Model# 14. 5032 nodes still misclassified out of torch.Size([13230]) \n",
      "\n",
      "Model# 15. 5032 nodes still misclassified out of torch.Size([13230]) \n",
      "\n",
      "Model# 16. 5032 nodes still misclassified out of torch.Size([13230]) \n",
      "\n",
      "Model# 17. 5032 nodes still misclassified out of torch.Size([13230]) \n",
      "\n",
      "Model# 18. 5032 nodes still misclassified out of torch.Size([13230]) \n",
      "\n",
      "Model# 19. 5032 nodes still misclassified out of torch.Size([13230]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13125/13125 [00:00<00:00, 2622688.90it/s]\n",
      "100%|██████████| 13125/13125 [00:00<00:00, 2982944.46it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1912354.78it/s]\n",
      "Inferring Phrases: 100%|██████████| 13125/13125 [00:00<00:00, 405595.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4158 nodes still misclassified out of torch.Size([13125]) \n",
      "\n",
      "Model# 1. 4158 nodes still misclassified out of torch.Size([13125]) \n",
      "\n",
      "Model# 2. 4158 nodes still misclassified out of torch.Size([13125]) \n",
      "\n",
      "Model# 3. 4158 nodes still misclassified out of torch.Size([13125]) \n",
      "\n",
      "Model# 4. 4158 nodes still misclassified out of torch.Size([13125]) \n",
      "\n",
      "Model# 5. 4158 nodes still misclassified out of torch.Size([13125]) \n",
      "\n",
      "Model# 6. 4158 nodes still misclassified out of torch.Size([13125]) \n",
      "\n",
      "Model# 7. 4158 nodes still misclassified out of torch.Size([13125]) \n",
      "\n",
      "Model# 8. 4158 nodes still misclassified out of torch.Size([13125]) \n",
      "\n",
      "Model# 9. 4158 nodes still misclassified out of torch.Size([13125]) \n",
      "\n",
      "Model# 10. 4158 nodes still misclassified out of torch.Size([13125]) \n",
      "\n",
      "Model# 11. 4158 nodes still misclassified out of torch.Size([13125]) \n",
      "\n",
      "Model# 12. 4158 nodes still misclassified out of torch.Size([13125]) \n",
      "\n",
      "Model# 13. 4158 nodes still misclassified out of torch.Size([13125]) \n",
      "\n",
      "Model# 14. 4158 nodes still misclassified out of torch.Size([13125]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 234/299 [02:16<00:39,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4158 nodes still misclassified out of torch.Size([13125]) \n",
      "\n",
      "Model# 16. 4158 nodes still misclassified out of torch.Size([13125]) \n",
      "\n",
      "Model# 17. 4158 nodes still misclassified out of torch.Size([13125]) \n",
      "\n",
      "Model# 18. 4158 nodes still misclassified out of torch.Size([13125]) \n",
      "\n",
      "Model# 19. 4158 nodes still misclassified out of torch.Size([13125]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13004/13004 [00:00<00:00, 2558289.36it/s]\n",
      "100%|██████████| 13004/13004 [00:00<00:00, 2891979.28it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1910119.47it/s]\n",
      "Inferring Phrases: 100%|██████████| 13004/13004 [00:00<00:00, 387644.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3992 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 1. 3992 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 2. 3992 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 3. 3992 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 4. 3992 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 5. 3992 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 6. 3992 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 7. 3992 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 8. 3992 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 9. 3992 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 10. 3992 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 11. 3992 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 12. 3992 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 13. 3992 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 14. 3992 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 15. 3992 nodes still misclassified out of torch.Size([13004]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 235/299 [02:16<00:37,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 16. 3992 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 17. 3992 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 18. 3992 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 19. 3992 nodes still misclassified out of torch.Size([13004]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14361/14361 [00:00<00:00, 4076778.32it/s]\n",
      "100%|██████████| 14361/14361 [00:00<00:00, 5165457.49it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2737200.78it/s]\n",
      "Inferring Phrases: 100%|██████████| 14361/14361 [00:00<00:00, 450755.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5448 nodes still misclassified out of torch.Size([14361]) \n",
      "\n",
      "Model# 1. 5448 nodes still misclassified out of torch.Size([14361]) \n",
      "\n",
      "Model# 2. 5448 nodes still misclassified out of torch.Size([14361]) \n",
      "\n",
      "Model# 3. 5448 nodes still misclassified out of torch.Size([14361]) \n",
      "\n",
      "Model# 4. 5448 nodes still misclassified out of torch.Size([14361]) \n",
      "\n",
      "Model# 5. 5448 nodes still misclassified out of torch.Size([14361]) \n",
      "\n",
      "Model# 6. 5448 nodes still misclassified out of torch.Size([14361]) \n",
      "\n",
      "Model# 7. 5448 nodes still misclassified out of torch.Size([14361]) \n",
      "\n",
      "Model# 8. 5448 nodes still misclassified out of torch.Size([14361]) \n",
      "\n",
      "Model# 9. 5448 nodes still misclassified out of torch.Size([14361]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 236/299 [02:17<00:40,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 5448 nodes still misclassified out of torch.Size([14361]) \n",
      "\n",
      "Model# 11. 5448 nodes still misclassified out of torch.Size([14361]) \n",
      "\n",
      "Model# 12. 5448 nodes still misclassified out of torch.Size([14361]) \n",
      "\n",
      "Model# 13. 5448 nodes still misclassified out of torch.Size([14361]) \n",
      "\n",
      "Model# 14. 5448 nodes still misclassified out of torch.Size([14361]) \n",
      "\n",
      "Model# 15. 5448 nodes still misclassified out of torch.Size([14361]) \n",
      "\n",
      "Model# 16. 5448 nodes still misclassified out of torch.Size([14361]) \n",
      "\n",
      "Model# 17. 5448 nodes still misclassified out of torch.Size([14361]) \n",
      "\n",
      "Model# 18. 5448 nodes still misclassified out of torch.Size([14361]) \n",
      "\n",
      "Model# 19. 5448 nodes still misclassified out of torch.Size([14361]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13037/13037 [00:00<00:00, 2447788.23it/s]\n",
      "100%|██████████| 13037/13037 [00:00<00:00, 2952864.31it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1901977.42it/s]\n",
      "Inferring Phrases: 100%|██████████| 13037/13037 [00:00<00:00, 386024.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4501 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 1. 4501 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 2. 4501 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 3. 4501 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 4. 4501 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 5. 4501 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 6. 4501 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 7. 4501 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 8. 4501 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 9. 4501 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 10. 4501 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 11. 4501 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 12. 4501 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 13. 4501 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 14. 4501 nodes still misclassified out of torch.Size([13037]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 237/299 [02:18<00:37,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4501 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 16. 4501 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 17. 4501 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 18. 4501 nodes still misclassified out of torch.Size([13037]) \n",
      "\n",
      "Model# 19. 4501 nodes still misclassified out of torch.Size([13037]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12597/12597 [00:00<00:00, 2586179.51it/s]\n",
      "100%|██████████| 12597/12597 [00:00<00:00, 2929292.43it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1918419.27it/s]\n",
      "Inferring Phrases: 100%|██████████| 12597/12597 [00:00<00:00, 372338.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4655 nodes still misclassified out of torch.Size([12597]) \n",
      "\n",
      "Model# 1. 4655 nodes still misclassified out of torch.Size([12597]) \n",
      "\n",
      "Model# 2. 4655 nodes still misclassified out of torch.Size([12597]) \n",
      "\n",
      "Model# 3. 4655 nodes still misclassified out of torch.Size([12597]) \n",
      "\n",
      "Model# 4. 4655 nodes still misclassified out of torch.Size([12597]) \n",
      "\n",
      "Model# 5. 4655 nodes still misclassified out of torch.Size([12597]) \n",
      "\n",
      "Model# 6. 4655 nodes still misclassified out of torch.Size([12597]) \n",
      "\n",
      "Model# 7. 4655 nodes still misclassified out of torch.Size([12597]) \n",
      "\n",
      "Model# 8. 4655 nodes still misclassified out of torch.Size([12597]) \n",
      "\n",
      "Model# 9. 4655 nodes still misclassified out of torch.Size([12597]) \n",
      "\n",
      "Model# 10. 4655 nodes still misclassified out of torch.Size([12597]) \n",
      "\n",
      "Model# 11. 4655 nodes still misclassified out of torch.Size([12597]) \n",
      "\n",
      "Model# 12. 4655 nodes still misclassified out of torch.Size([12597]) \n",
      "\n",
      "Model# 13. 4655 nodes still misclassified out of torch.Size([12597]) \n",
      "\n",
      "Model# 14. 4655 nodes still misclassified out of torch.Size([12597]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 238/299 [02:18<00:35,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4655 nodes still misclassified out of torch.Size([12597]) \n",
      "\n",
      "Model# 16. 4655 nodes still misclassified out of torch.Size([12597]) \n",
      "\n",
      "Model# 17. 4655 nodes still misclassified out of torch.Size([12597]) \n",
      "\n",
      "Model# 18. 4655 nodes still misclassified out of torch.Size([12597]) \n",
      "\n",
      "Model# 19. 4655 nodes still misclassified out of torch.Size([12597]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12180/12180 [00:00<00:00, 4363394.49it/s]\n",
      "100%|██████████| 12180/12180 [00:00<00:00, 5246110.36it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2798628.14it/s]\n",
      "Inferring Phrases: 100%|██████████| 12180/12180 [00:00<00:00, 404691.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4210 nodes still misclassified out of torch.Size([12180]) \n",
      "\n",
      "Model# 1. 4210 nodes still misclassified out of torch.Size([12180]) \n",
      "\n",
      "Model# 2. 4210 nodes still misclassified out of torch.Size([12180]) \n",
      "\n",
      "Model# 3. 4210 nodes still misclassified out of torch.Size([12180]) \n",
      "\n",
      "Model# 4. 4210 nodes still misclassified out of torch.Size([12180]) \n",
      "\n",
      "Model# 5. 4210 nodes still misclassified out of torch.Size([12180]) \n",
      "\n",
      "Model# 6. 4210 nodes still misclassified out of torch.Size([12180]) \n",
      "\n",
      "Model# 7. 4210 nodes still misclassified out of torch.Size([12180]) \n",
      "\n",
      "Model# 8. 4210 nodes still misclassified out of torch.Size([12180]) \n",
      "\n",
      "Model# 9. 4210 nodes still misclassified out of torch.Size([12180]) \n",
      "\n",
      "Model# 10. 4210 nodes still misclassified out of torch.Size([12180]) \n",
      "\n",
      "Model# 11. 4210 nodes still misclassified out of torch.Size([12180]) \n",
      "\n",
      "Model# 12. 4210 nodes still misclassified out of torch.Size([12180]) \n",
      "\n",
      "Model# 13. 4210 nodes still misclassified out of torch.Size([12180]) \n",
      "\n",
      "Model# 14. 4210 nodes still misclassified out of torch.Size([12180]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 239/299 [02:19<00:36,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4210 nodes still misclassified out of torch.Size([12180]) \n",
      "\n",
      "Model# 16. 4210 nodes still misclassified out of torch.Size([12180]) \n",
      "\n",
      "Model# 17. 4210 nodes still misclassified out of torch.Size([12180]) \n",
      "\n",
      "Model# 18. 4210 nodes still misclassified out of torch.Size([12180]) \n",
      "\n",
      "Model# 19. 4210 nodes still misclassified out of torch.Size([12180]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12402/12402 [00:00<00:00, 2565357.71it/s]\n",
      "100%|██████████| 12402/12402 [00:00<00:00, 3007328.33it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1920146.50it/s]\n",
      "Inferring Phrases: 100%|██████████| 12402/12402 [00:00<00:00, 365786.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4226 nodes still misclassified out of torch.Size([12402]) \n",
      "\n",
      "Model# 1. 4226 nodes still misclassified out of torch.Size([12402]) \n",
      "\n",
      "Model# 2. 4226 nodes still misclassified out of torch.Size([12402]) \n",
      "\n",
      "Model# 3. 4226 nodes still misclassified out of torch.Size([12402]) \n",
      "\n",
      "Model# 4. 4226 nodes still misclassified out of torch.Size([12402]) \n",
      "\n",
      "Model# 5. 4226 nodes still misclassified out of torch.Size([12402]) \n",
      "\n",
      "Model# 6. 4226 nodes still misclassified out of torch.Size([12402]) \n",
      "\n",
      "Model# 7. 4226 nodes still misclassified out of torch.Size([12402]) \n",
      "\n",
      "Model# 8. 4226 nodes still misclassified out of torch.Size([12402]) \n",
      "\n",
      "Model# 9. 4226 nodes still misclassified out of torch.Size([12402]) \n",
      "\n",
      "Model# 10. 4226 nodes still misclassified out of torch.Size([12402]) \n",
      "\n",
      "Model# 11. 4226 nodes still misclassified out of torch.Size([12402]) \n",
      "\n",
      "Model# 12. 4226 nodes still misclassified out of torch.Size([12402]) \n",
      "\n",
      "Model# 13. 4226 nodes still misclassified out of torch.Size([12402]) \n",
      "\n",
      "Model# 14. 4226 nodes still misclassified out of torch.Size([12402]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 240/299 [02:19<00:34,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4226 nodes still misclassified out of torch.Size([12402]) \n",
      "\n",
      "Model# 16. 4226 nodes still misclassified out of torch.Size([12402]) \n",
      "\n",
      "Model# 17. 4226 nodes still misclassified out of torch.Size([12402]) \n",
      "\n",
      "Model# 18. 4226 nodes still misclassified out of torch.Size([12402]) \n",
      "\n",
      "Model# 19. 4226 nodes still misclassified out of torch.Size([12402]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12943/12943 [00:00<00:00, 3861910.56it/s]\n",
      "100%|██████████| 12943/12943 [00:00<00:00, 4823785.03it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2686417.73it/s]\n",
      "Inferring Phrases: 100%|██████████| 12943/12943 [00:00<00:00, 400913.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4862 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 1. 4862 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 2. 4862 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 3. 4862 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 4. 4862 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 5. 4862 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 6. 4862 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 7. 4862 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 8. 4862 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 9. 4862 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 10. 4862 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 11. 4862 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 12. 4862 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 13. 4862 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 14. 4862 nodes still misclassified out of torch.Size([12943]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 241/299 [02:20<00:35,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4862 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 16. 4862 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 17. 4862 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 18. 4862 nodes still misclassified out of torch.Size([12943]) \n",
      "\n",
      "Model# 19. 4862 nodes still misclassified out of torch.Size([12943]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12568/12568 [00:00<00:00, 2587317.79it/s]\n",
      "100%|██████████| 12568/12568 [00:00<00:00, 2946233.66it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1896673.60it/s]\n",
      "Inferring Phrases: 100%|██████████| 12568/12568 [00:00<00:00, 408176.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4322 nodes still misclassified out of torch.Size([12568]) \n",
      "\n",
      "Model# 1. 4322 nodes still misclassified out of torch.Size([12568]) \n",
      "\n",
      "Model# 2. 4322 nodes still misclassified out of torch.Size([12568]) \n",
      "\n",
      "Model# 3. 4322 nodes still misclassified out of torch.Size([12568]) \n",
      "\n",
      "Model# 4. 4322 nodes still misclassified out of torch.Size([12568]) \n",
      "\n",
      "Model# 5. 4322 nodes still misclassified out of torch.Size([12568]) \n",
      "\n",
      "Model# 6. 4322 nodes still misclassified out of torch.Size([12568]) \n",
      "\n",
      "Model# 7. 4322 nodes still misclassified out of torch.Size([12568]) \n",
      "\n",
      "Model# 8. 4322 nodes still misclassified out of torch.Size([12568]) \n",
      "\n",
      "Model# 9. 4322 nodes still misclassified out of torch.Size([12568]) \n",
      "\n",
      "Model# 10. 4322 nodes still misclassified out of torch.Size([12568]) \n",
      "\n",
      "Model# 11. 4322 nodes still misclassified out of torch.Size([12568]) \n",
      "\n",
      "Model# 12. 4322 nodes still misclassified out of torch.Size([12568]) \n",
      "\n",
      "Model# 13. 4322 nodes still misclassified out of torch.Size([12568]) \n",
      "\n",
      "Model# 14. 4322 nodes still misclassified out of torch.Size([12568]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 242/299 [02:21<00:34,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4322 nodes still misclassified out of torch.Size([12568]) \n",
      "\n",
      "Model# 16. 4322 nodes still misclassified out of torch.Size([12568]) \n",
      "\n",
      "Model# 17. 4322 nodes still misclassified out of torch.Size([12568]) \n",
      "\n",
      "Model# 18. 4322 nodes still misclassified out of torch.Size([12568]) \n",
      "\n",
      "Model# 19. 4322 nodes still misclassified out of torch.Size([12568]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12708/12708 [00:00<00:00, 2613957.88it/s]\n",
      "100%|██████████| 12708/12708 [00:00<00:00, 2984724.79it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1899020.83it/s]\n",
      "Inferring Phrases: 100%|██████████| 12708/12708 [00:00<00:00, 366047.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4845 nodes still misclassified out of torch.Size([12708]) \n",
      "\n",
      "Model# 1. 4845 nodes still misclassified out of torch.Size([12708]) \n",
      "\n",
      "Model# 2. 4845 nodes still misclassified out of torch.Size([12708]) \n",
      "\n",
      "Model# 3. 4845 nodes still misclassified out of torch.Size([12708]) \n",
      "\n",
      "Model# 4. 4845 nodes still misclassified out of torch.Size([12708]) \n",
      "\n",
      "Model# 5. 4845 nodes still misclassified out of torch.Size([12708]) \n",
      "\n",
      "Model# 6. 4845 nodes still misclassified out of torch.Size([12708]) \n",
      "\n",
      "Model# 7. 4845 nodes still misclassified out of torch.Size([12708]) \n",
      "\n",
      "Model# 8. 4845 nodes still misclassified out of torch.Size([12708]) \n",
      "\n",
      "Model# 9. 4845 nodes still misclassified out of torch.Size([12708]) \n",
      "\n",
      "Model# 10. 4845 nodes still misclassified out of torch.Size([12708]) \n",
      "\n",
      "Model# 11. 4845 nodes still misclassified out of torch.Size([12708]) \n",
      "\n",
      "Model# 12. 4845 nodes still misclassified out of torch.Size([12708]) \n",
      "\n",
      "Model# 13. 4845 nodes still misclassified out of torch.Size([12708]) \n",
      "\n",
      "Model# 14. 4845 nodes still misclassified out of torch.Size([12708]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 243/299 [02:21<00:32,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4845 nodes still misclassified out of torch.Size([12708]) \n",
      "\n",
      "Model# 16. 4845 nodes still misclassified out of torch.Size([12708]) \n",
      "\n",
      "Model# 17. 4845 nodes still misclassified out of torch.Size([12708]) \n",
      "\n",
      "Model# 18. 4845 nodes still misclassified out of torch.Size([12708]) \n",
      "\n",
      "Model# 19. 4845 nodes still misclassified out of torch.Size([12708]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12487/12487 [00:00<00:00, 4041848.59it/s]\n",
      "100%|██████████| 12487/12487 [00:00<00:00, 4707799.91it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2527196.63it/s]\n",
      "Inferring Phrases: 100%|██████████| 12487/12487 [00:00<00:00, 388178.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4415 nodes still misclassified out of torch.Size([12487]) \n",
      "\n",
      "Model# 1. 4415 nodes still misclassified out of torch.Size([12487]) \n",
      "\n",
      "Model# 2. 4415 nodes still misclassified out of torch.Size([12487]) \n",
      "\n",
      "Model# 3. 4415 nodes still misclassified out of torch.Size([12487]) \n",
      "\n",
      "Model# 4. 4415 nodes still misclassified out of torch.Size([12487]) \n",
      "\n",
      "Model# 5. 4415 nodes still misclassified out of torch.Size([12487]) \n",
      "\n",
      "Model# 6. 4415 nodes still misclassified out of torch.Size([12487]) \n",
      "\n",
      "Model# 7. 4415 nodes still misclassified out of torch.Size([12487]) \n",
      "\n",
      "Model# 8. 4415 nodes still misclassified out of torch.Size([12487]) \n",
      "\n",
      "Model# 9. 4415 nodes still misclassified out of torch.Size([12487]) \n",
      "\n",
      "Model# 10. 4415 nodes still misclassified out of torch.Size([12487]) \n",
      "\n",
      "Model# 11. 4415 nodes still misclassified out of torch.Size([12487]) \n",
      "\n",
      "Model# 12. 4415 nodes still misclassified out of torch.Size([12487]) \n",
      "\n",
      "Model# 13. 4415 nodes still misclassified out of torch.Size([12487]) \n",
      "\n",
      "Model# 14. 4415 nodes still misclassified out of torch.Size([12487]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 244/299 [02:22<00:34,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4415 nodes still misclassified out of torch.Size([12487]) \n",
      "\n",
      "Model# 16. 4415 nodes still misclassified out of torch.Size([12487]) \n",
      "\n",
      "Model# 17. 4415 nodes still misclassified out of torch.Size([12487]) \n",
      "\n",
      "Model# 18. 4415 nodes still misclassified out of torch.Size([12487]) \n",
      "\n",
      "Model# 19. 4415 nodes still misclassified out of torch.Size([12487]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12751/12751 [00:00<00:00, 2632744.43it/s]\n",
      "100%|██████████| 12751/12751 [00:00<00:00, 2915321.36it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1859397.09it/s]\n",
      "Inferring Phrases: 100%|██████████| 12751/12751 [00:00<00:00, 389418.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4553 nodes still misclassified out of torch.Size([12751]) \n",
      "\n",
      "Model# 1. 4553 nodes still misclassified out of torch.Size([12751]) \n",
      "\n",
      "Model# 2. 4553 nodes still misclassified out of torch.Size([12751]) \n",
      "\n",
      "Model# 3. 4553 nodes still misclassified out of torch.Size([12751]) \n",
      "\n",
      "Model# 4. 4553 nodes still misclassified out of torch.Size([12751]) \n",
      "\n",
      "Model# 5. 4553 nodes still misclassified out of torch.Size([12751]) \n",
      "\n",
      "Model# 6. 4553 nodes still misclassified out of torch.Size([12751]) \n",
      "\n",
      "Model# 7. 4553 nodes still misclassified out of torch.Size([12751]) \n",
      "\n",
      "Model# 8. 4553 nodes still misclassified out of torch.Size([12751]) \n",
      "\n",
      "Model# 9. 4553 nodes still misclassified out of torch.Size([12751]) \n",
      "\n",
      "Model# 10. 4553 nodes still misclassified out of torch.Size([12751]) \n",
      "\n",
      "Model# 11. 4553 nodes still misclassified out of torch.Size([12751]) \n",
      "\n",
      "Model# 12. 4553 nodes still misclassified out of torch.Size([12751]) \n",
      "\n",
      "Model# 13. 4553 nodes still misclassified out of torch.Size([12751]) \n",
      "\n",
      "Model# 14. 4553 nodes still misclassified out of torch.Size([12751]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 245/299 [02:23<00:32,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4553 nodes still misclassified out of torch.Size([12751]) \n",
      "\n",
      "Model# 16. 4553 nodes still misclassified out of torch.Size([12751]) \n",
      "\n",
      "Model# 17. 4553 nodes still misclassified out of torch.Size([12751]) \n",
      "\n",
      "Model# 18. 4553 nodes still misclassified out of torch.Size([12751]) \n",
      "\n",
      "Model# 19. 4553 nodes still misclassified out of torch.Size([12751]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12453/12453 [00:00<00:00, 2651488.28it/s]\n",
      "100%|██████████| 12453/12453 [00:00<00:00, 2971084.63it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1938039.00it/s]\n",
      "Inferring Phrases: 100%|██████████| 12453/12453 [00:00<00:00, 370660.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4484 nodes still misclassified out of torch.Size([12453]) \n",
      "\n",
      "Model# 1. 4484 nodes still misclassified out of torch.Size([12453]) \n",
      "\n",
      "Model# 2. 4484 nodes still misclassified out of torch.Size([12453]) \n",
      "\n",
      "Model# 3. 4484 nodes still misclassified out of torch.Size([12453]) \n",
      "\n",
      "Model# 4. 4484 nodes still misclassified out of torch.Size([12453]) \n",
      "\n",
      "Model# 5. 4484 nodes still misclassified out of torch.Size([12453]) \n",
      "\n",
      "Model# 6. 4484 nodes still misclassified out of torch.Size([12453]) \n",
      "\n",
      "Model# 7. 4484 nodes still misclassified out of torch.Size([12453]) \n",
      "\n",
      "Model# 8. 4484 nodes still misclassified out of torch.Size([12453]) \n",
      "\n",
      "Model# 9. 4484 nodes still misclassified out of torch.Size([12453]) \n",
      "\n",
      "Model# 10. 4484 nodes still misclassified out of torch.Size([12453]) \n",
      "\n",
      "Model# 11. 4484 nodes still misclassified out of torch.Size([12453]) \n",
      "\n",
      "Model# 12. 4484 nodes still misclassified out of torch.Size([12453]) \n",
      "\n",
      "Model# 13. 4484 nodes still misclassified out of torch.Size([12453]) \n",
      "\n",
      "Model# 14. 4484 nodes still misclassified out of torch.Size([12453]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 246/299 [02:23<00:30,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4484 nodes still misclassified out of torch.Size([12453]) \n",
      "\n",
      "Model# 16. 4484 nodes still misclassified out of torch.Size([12453]) \n",
      "\n",
      "Model# 17. 4484 nodes still misclassified out of torch.Size([12453]) \n",
      "\n",
      "Model# 18. 4484 nodes still misclassified out of torch.Size([12453]) \n",
      "\n",
      "Model# 19. 4484 nodes still misclassified out of torch.Size([12453]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12527/12527 [00:00<00:00, 4420498.59it/s]\n",
      "100%|██████████| 12527/12527 [00:00<00:00, 5237444.80it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2834499.91it/s]\n",
      "Inferring Phrases: 100%|██████████| 12527/12527 [00:00<00:00, 415119.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4377 nodes still misclassified out of torch.Size([12527]) \n",
      "\n",
      "Model# 1. 4377 nodes still misclassified out of torch.Size([12527]) \n",
      "\n",
      "Model# 2. 4377 nodes still misclassified out of torch.Size([12527]) \n",
      "\n",
      "Model# 3. 4377 nodes still misclassified out of torch.Size([12527]) \n",
      "\n",
      "Model# 4. 4377 nodes still misclassified out of torch.Size([12527]) \n",
      "\n",
      "Model# 5. 4377 nodes still misclassified out of torch.Size([12527]) \n",
      "\n",
      "Model# 6. 4377 nodes still misclassified out of torch.Size([12527]) \n",
      "\n",
      "Model# 7. 4377 nodes still misclassified out of torch.Size([12527]) \n",
      "\n",
      "Model# 8. 4377 nodes still misclassified out of torch.Size([12527]) \n",
      "\n",
      "Model# 9. 4377 nodes still misclassified out of torch.Size([12527]) \n",
      "\n",
      "Model# 10. 4377 nodes still misclassified out of torch.Size([12527]) \n",
      "\n",
      "Model# 11. 4377 nodes still misclassified out of torch.Size([12527]) \n",
      "\n",
      "Model# 12. 4377 nodes still misclassified out of torch.Size([12527]) \n",
      "\n",
      "Model# 13. 4377 nodes still misclassified out of torch.Size([12527]) \n",
      "\n",
      "Model# 14. 4377 nodes still misclassified out of torch.Size([12527]) \n",
      "\n",
      "Model# 15. 4377 nodes still misclassified out of torch.Size([12527]) \n",
      "\n",
      "Model# 16. 4377 nodes still misclassified out of torch.Size([12527]) \n",
      "\n",
      "Model# 17. 4377 nodes still misclassified out of torch.Size([12527]) \n",
      "\n",
      "Model# 18. 4377 nodes still misclassified out of torch.Size([12527]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 247/299 [02:24<00:30,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4377 nodes still misclassified out of torch.Size([12527]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14747/14747 [00:00<00:00, 2525865.77it/s]\n",
      "100%|██████████| 14747/14747 [00:00<00:00, 2819335.48it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1841141.30it/s]\n",
      "Inferring Phrases: 100%|██████████| 14747/14747 [00:00<00:00, 298334.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6083 nodes still misclassified out of torch.Size([14747]) \n",
      "\n",
      "Model# 1. 6083 nodes still misclassified out of torch.Size([14747]) \n",
      "\n",
      "Model# 2. 6083 nodes still misclassified out of torch.Size([14747]) \n",
      "\n",
      "Model# 3. 6083 nodes still misclassified out of torch.Size([14747]) \n",
      "\n",
      "Model# 4. 6083 nodes still misclassified out of torch.Size([14747]) \n",
      "\n",
      "Model# 5. 6083 nodes still misclassified out of torch.Size([14747]) \n",
      "\n",
      "Model# 6. 6083 nodes still misclassified out of torch.Size([14747]) \n",
      "\n",
      "Model# 7. 6083 nodes still misclassified out of torch.Size([14747]) \n",
      "\n",
      "Model# 8. 6083 nodes still misclassified out of torch.Size([14747]) \n",
      "\n",
      "Model# 9. 6083 nodes still misclassified out of torch.Size([14747]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 248/299 [02:24<00:31,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 6083 nodes still misclassified out of torch.Size([14747]) \n",
      "\n",
      "Model# 11. 6083 nodes still misclassified out of torch.Size([14747]) \n",
      "\n",
      "Model# 12. 6083 nodes still misclassified out of torch.Size([14747]) \n",
      "\n",
      "Model# 13. 6083 nodes still misclassified out of torch.Size([14747]) \n",
      "\n",
      "Model# 14. 6083 nodes still misclassified out of torch.Size([14747]) \n",
      "\n",
      "Model# 15. 6083 nodes still misclassified out of torch.Size([14747]) \n",
      "\n",
      "Model# 16. 6083 nodes still misclassified out of torch.Size([14747]) \n",
      "\n",
      "Model# 17. 6083 nodes still misclassified out of torch.Size([14747]) \n",
      "\n",
      "Model# 18. 6083 nodes still misclassified out of torch.Size([14747]) \n",
      "\n",
      "Model# 19. 6083 nodes still misclassified out of torch.Size([14747]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13598/13598 [00:00<00:00, 2649300.71it/s]\n",
      "100%|██████████| 13598/13598 [00:00<00:00, 2974711.61it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1881416.27it/s]\n",
      "Inferring Phrases: 100%|██████████| 13598/13598 [00:00<00:00, 377287.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5036 nodes still misclassified out of torch.Size([13598]) \n",
      "\n",
      "Model# 1. 5036 nodes still misclassified out of torch.Size([13598]) \n",
      "\n",
      "Model# 2. 5036 nodes still misclassified out of torch.Size([13598]) \n",
      "\n",
      "Model# 3. 5036 nodes still misclassified out of torch.Size([13598]) \n",
      "\n",
      "Model# 4. 5036 nodes still misclassified out of torch.Size([13598]) \n",
      "\n",
      "Model# 5. 5036 nodes still misclassified out of torch.Size([13598]) \n",
      "\n",
      "Model# 6. 5036 nodes still misclassified out of torch.Size([13598]) \n",
      "\n",
      "Model# 7. 5036 nodes still misclassified out of torch.Size([13598]) \n",
      "\n",
      "Model# 8. 5036 nodes still misclassified out of torch.Size([13598]) \n",
      "\n",
      "Model# 9. 5036 nodes still misclassified out of torch.Size([13598]) \n",
      "\n",
      "Model# 10. 5036 nodes still misclassified out of torch.Size([13598]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 249/299 [02:25<00:31,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 5036 nodes still misclassified out of torch.Size([13598]) \n",
      "\n",
      "Model# 12. 5036 nodes still misclassified out of torch.Size([13598]) \n",
      "\n",
      "Model# 13. 5036 nodes still misclassified out of torch.Size([13598]) \n",
      "\n",
      "Model# 14. 5036 nodes still misclassified out of torch.Size([13598]) \n",
      "\n",
      "Model# 15. 5036 nodes still misclassified out of torch.Size([13598]) \n",
      "\n",
      "Model# 16. 5036 nodes still misclassified out of torch.Size([13598]) \n",
      "\n",
      "Model# 17. 5036 nodes still misclassified out of torch.Size([13598]) \n",
      "\n",
      "Model# 18. 5036 nodes still misclassified out of torch.Size([13598]) \n",
      "\n",
      "Model# 19. 5036 nodes still misclassified out of torch.Size([13598]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12968/12968 [00:00<00:00, 4385369.21it/s]\n",
      "100%|██████████| 12968/12968 [00:00<00:00, 5079067.54it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2727943.46it/s]\n",
      "Inferring Phrases: 100%|██████████| 12968/12968 [00:00<00:00, 410345.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4704 nodes still misclassified out of torch.Size([12968]) \n",
      "\n",
      "Model# 1. 4704 nodes still misclassified out of torch.Size([12968]) \n",
      "\n",
      "Model# 2. 4704 nodes still misclassified out of torch.Size([12968]) \n",
      "\n",
      "Model# 3. 4704 nodes still misclassified out of torch.Size([12968]) \n",
      "\n",
      "Model# 4. 4704 nodes still misclassified out of torch.Size([12968]) \n",
      "\n",
      "Model# 5. 4704 nodes still misclassified out of torch.Size([12968]) \n",
      "\n",
      "Model# 6. 4704 nodes still misclassified out of torch.Size([12968]) \n",
      "\n",
      "Model# 7. 4704 nodes still misclassified out of torch.Size([12968]) \n",
      "\n",
      "Model# 8. 4704 nodes still misclassified out of torch.Size([12968]) \n",
      "\n",
      "Model# 9. 4704 nodes still misclassified out of torch.Size([12968]) \n",
      "\n",
      "Model# 10. 4704 nodes still misclassified out of torch.Size([12968]) \n",
      "\n",
      "Model# 11. 4704 nodes still misclassified out of torch.Size([12968]) \n",
      "\n",
      "Model# 12. 4704 nodes still misclassified out of torch.Size([12968]) \n",
      "\n",
      "Model# 13. 4704 nodes still misclassified out of torch.Size([12968]) \n",
      "\n",
      "Model# 14. 4704 nodes still misclassified out of torch.Size([12968]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 250/299 [02:26<00:30,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4704 nodes still misclassified out of torch.Size([12968]) \n",
      "\n",
      "Model# 16. 4704 nodes still misclassified out of torch.Size([12968]) \n",
      "\n",
      "Model# 17. 4704 nodes still misclassified out of torch.Size([12968]) \n",
      "\n",
      "Model# 18. 4704 nodes still misclassified out of torch.Size([12968]) \n",
      "\n",
      "Model# 19. 4704 nodes still misclassified out of torch.Size([12968]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12212/12212 [00:00<00:00, 2657371.75it/s]\n",
      "100%|██████████| 12212/12212 [00:00<00:00, 2967603.73it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1926673.51it/s]\n",
      "Inferring Phrases: 100%|██████████| 12212/12212 [00:00<00:00, 338529.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4150 nodes still misclassified out of torch.Size([12212]) \n",
      "\n",
      "Model# 1. 4150 nodes still misclassified out of torch.Size([12212]) \n",
      "\n",
      "Model# 2. 4150 nodes still misclassified out of torch.Size([12212]) \n",
      "\n",
      "Model# 3. 4150 nodes still misclassified out of torch.Size([12212]) \n",
      "\n",
      "Model# 4. 4150 nodes still misclassified out of torch.Size([12212]) \n",
      "\n",
      "Model# 5. 4150 nodes still misclassified out of torch.Size([12212]) \n",
      "\n",
      "Model# 6. 4150 nodes still misclassified out of torch.Size([12212]) \n",
      "\n",
      "Model# 7. 4150 nodes still misclassified out of torch.Size([12212]) \n",
      "\n",
      "Model# 8. 4150 nodes still misclassified out of torch.Size([12212]) \n",
      "\n",
      "Model# 9. 4150 nodes still misclassified out of torch.Size([12212]) \n",
      "\n",
      "Model# 10. 4150 nodes still misclassified out of torch.Size([12212]) \n",
      "\n",
      "Model# 11. 4150 nodes still misclassified out of torch.Size([12212]) \n",
      "\n",
      "Model# 12. 4150 nodes still misclassified out of torch.Size([12212]) \n",
      "\n",
      "Model# 13. 4150 nodes still misclassified out of torch.Size([12212]) \n",
      "\n",
      "Model# 14. 4150 nodes still misclassified out of torch.Size([12212]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 251/299 [02:26<00:28,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4150 nodes still misclassified out of torch.Size([12212]) \n",
      "\n",
      "Model# 16. 4150 nodes still misclassified out of torch.Size([12212]) \n",
      "\n",
      "Model# 17. 4150 nodes still misclassified out of torch.Size([12212]) \n",
      "\n",
      "Model# 18. 4150 nodes still misclassified out of torch.Size([12212]) \n",
      "\n",
      "Model# 19. 4150 nodes still misclassified out of torch.Size([12212]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12607/12607 [00:00<00:00, 3972473.18it/s]\n",
      "100%|██████████| 12607/12607 [00:00<00:00, 5042684.58it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2827175.95it/s]\n",
      "Inferring Phrases: 100%|██████████| 12607/12607 [00:00<00:00, 361828.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4586 nodes still misclassified out of torch.Size([12607]) \n",
      "\n",
      "Model# 1. 4586 nodes still misclassified out of torch.Size([12607]) \n",
      "\n",
      "Model# 2. 4586 nodes still misclassified out of torch.Size([12607]) \n",
      "\n",
      "Model# 3. 4586 nodes still misclassified out of torch.Size([12607]) \n",
      "\n",
      "Model# 4. 4586 nodes still misclassified out of torch.Size([12607]) \n",
      "\n",
      "Model# 5. 4586 nodes still misclassified out of torch.Size([12607]) \n",
      "\n",
      "Model# 6. 4586 nodes still misclassified out of torch.Size([12607]) \n",
      "\n",
      "Model# 7. 4586 nodes still misclassified out of torch.Size([12607]) \n",
      "\n",
      "Model# 8. 4586 nodes still misclassified out of torch.Size([12607]) \n",
      "\n",
      "Model# 9. 4586 nodes still misclassified out of torch.Size([12607]) \n",
      "\n",
      "Model# 10. 4586 nodes still misclassified out of torch.Size([12607]) \n",
      "\n",
      "Model# 11. 4586 nodes still misclassified out of torch.Size([12607]) \n",
      "\n",
      "Model# 12. 4586 nodes still misclassified out of torch.Size([12607]) \n",
      "\n",
      "Model# 13. 4586 nodes still misclassified out of torch.Size([12607]) \n",
      "\n",
      "Model# 14. 4586 nodes still misclassified out of torch.Size([12607]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 252/299 [02:27<00:29,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4586 nodes still misclassified out of torch.Size([12607]) \n",
      "\n",
      "Model# 16. 4586 nodes still misclassified out of torch.Size([12607]) \n",
      "\n",
      "Model# 17. 4586 nodes still misclassified out of torch.Size([12607]) \n",
      "\n",
      "Model# 18. 4586 nodes still misclassified out of torch.Size([12607]) \n",
      "\n",
      "Model# 19. 4586 nodes still misclassified out of torch.Size([12607]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12547/12547 [00:00<00:00, 2548101.11it/s]\n",
      "100%|██████████| 12547/12547 [00:00<00:00, 2981470.30it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1904020.82it/s]\n",
      "Inferring Phrases: 100%|██████████| 12547/12547 [00:00<00:00, 351725.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4469 nodes still misclassified out of torch.Size([12547]) \n",
      "\n",
      "Model# 1. 4469 nodes still misclassified out of torch.Size([12547]) \n",
      "\n",
      "Model# 2. 4469 nodes still misclassified out of torch.Size([12547]) \n",
      "\n",
      "Model# 3. 4469 nodes still misclassified out of torch.Size([12547]) \n",
      "\n",
      "Model# 4. 4469 nodes still misclassified out of torch.Size([12547]) \n",
      "\n",
      "Model# 5. 4469 nodes still misclassified out of torch.Size([12547]) \n",
      "\n",
      "Model# 6. 4469 nodes still misclassified out of torch.Size([12547]) \n",
      "\n",
      "Model# 7. 4469 nodes still misclassified out of torch.Size([12547]) \n",
      "\n",
      "Model# 8. 4469 nodes still misclassified out of torch.Size([12547]) \n",
      "\n",
      "Model# 9. 4469 nodes still misclassified out of torch.Size([12547]) \n",
      "\n",
      "Model# 10. 4469 nodes still misclassified out of torch.Size([12547]) \n",
      "\n",
      "Model# 11. 4469 nodes still misclassified out of torch.Size([12547]) \n",
      "\n",
      "Model# 12. 4469 nodes still misclassified out of torch.Size([12547]) \n",
      "\n",
      "Model# 13. 4469 nodes still misclassified out of torch.Size([12547]) \n",
      "\n",
      "Model# 14. 4469 nodes still misclassified out of torch.Size([12547]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 253/299 [02:27<00:27,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4469 nodes still misclassified out of torch.Size([12547]) \n",
      "\n",
      "Model# 16. 4469 nodes still misclassified out of torch.Size([12547]) \n",
      "\n",
      "Model# 17. 4469 nodes still misclassified out of torch.Size([12547]) \n",
      "\n",
      "Model# 18. 4469 nodes still misclassified out of torch.Size([12547]) \n",
      "\n",
      "Model# 19. 4469 nodes still misclassified out of torch.Size([12547]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12786/12786 [00:00<00:00, 2595507.26it/s]\n",
      "100%|██████████| 12786/12786 [00:00<00:00, 2900241.79it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1921260.59it/s]\n",
      "Inferring Phrases: 100%|██████████| 12786/12786 [00:00<00:00, 365642.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4620 nodes still misclassified out of torch.Size([12786]) \n",
      "\n",
      "Model# 1. 4620 nodes still misclassified out of torch.Size([12786]) \n",
      "\n",
      "Model# 2. 4620 nodes still misclassified out of torch.Size([12786]) \n",
      "\n",
      "Model# 3. 4620 nodes still misclassified out of torch.Size([12786]) \n",
      "\n",
      "Model# 4. 4620 nodes still misclassified out of torch.Size([12786]) \n",
      "\n",
      "Model# 5. 4620 nodes still misclassified out of torch.Size([12786]) \n",
      "\n",
      "Model# 6. 4620 nodes still misclassified out of torch.Size([12786]) \n",
      "\n",
      "Model# 7. 4620 nodes still misclassified out of torch.Size([12786]) \n",
      "\n",
      "Model# 8. 4620 nodes still misclassified out of torch.Size([12786]) \n",
      "\n",
      "Model# 9. 4620 nodes still misclassified out of torch.Size([12786]) \n",
      "\n",
      "Model# 10. 4620 nodes still misclassified out of torch.Size([12786]) \n",
      "\n",
      "Model# 11. 4620 nodes still misclassified out of torch.Size([12786]) \n",
      "\n",
      "Model# 12. 4620 nodes still misclassified out of torch.Size([12786]) \n",
      "\n",
      "Model# 13. 4620 nodes still misclassified out of torch.Size([12786]) \n",
      "\n",
      "Model# 14. 4620 nodes still misclassified out of torch.Size([12786]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 254/299 [02:28<00:26,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4620 nodes still misclassified out of torch.Size([12786]) \n",
      "\n",
      "Model# 16. 4620 nodes still misclassified out of torch.Size([12786]) \n",
      "\n",
      "Model# 17. 4620 nodes still misclassified out of torch.Size([12786]) \n",
      "\n",
      "Model# 18. 4620 nodes still misclassified out of torch.Size([12786]) \n",
      "\n",
      "Model# 19. 4620 nodes still misclassified out of torch.Size([12786]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12850/12850 [00:00<00:00, 4381854.18it/s]\n",
      "100%|██████████| 12850/12850 [00:00<00:00, 5256686.47it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 3152584.87it/s]\n",
      "Inferring Phrases: 100%|██████████| 12850/12850 [00:00<00:00, 421793.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 3215 nodes still misclassified out of torch.Size([12850]) \n",
      "\n",
      "Model# 1. 3215 nodes still misclassified out of torch.Size([12850]) \n",
      "\n",
      "Model# 2. 3215 nodes still misclassified out of torch.Size([12850]) \n",
      "\n",
      "Model# 3. 3215 nodes still misclassified out of torch.Size([12850]) \n",
      "\n",
      "Model# 4. 3215 nodes still misclassified out of torch.Size([12850]) \n",
      "\n",
      "Model# 5. 3215 nodes still misclassified out of torch.Size([12850]) \n",
      "\n",
      "Model# 6. 3215 nodes still misclassified out of torch.Size([12850]) \n",
      "\n",
      "Model# 7. 3215 nodes still misclassified out of torch.Size([12850]) \n",
      "\n",
      "Model# 8. 3215 nodes still misclassified out of torch.Size([12850]) \n",
      "\n",
      "Model# 9. 3215 nodes still misclassified out of torch.Size([12850]) \n",
      "\n",
      "Model# 10. 3215 nodes still misclassified out of torch.Size([12850]) \n",
      "\n",
      "Model# 11. 3215 nodes still misclassified out of torch.Size([12850]) \n",
      "\n",
      "Model# 12. 3215 nodes still misclassified out of torch.Size([12850]) \n",
      "\n",
      "Model# 13. 3215 nodes still misclassified out of torch.Size([12850]) \n",
      "\n",
      "Model# 14. 3215 nodes still misclassified out of torch.Size([12850]) \n",
      "\n",
      "Model# 15. 3215 nodes still misclassified out of torch.Size([12850]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 255/299 [02:29<00:26,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 16. 3215 nodes still misclassified out of torch.Size([12850]) \n",
      "\n",
      "Model# 17. 3215 nodes still misclassified out of torch.Size([12850]) \n",
      "\n",
      "Model# 18. 3215 nodes still misclassified out of torch.Size([12850]) \n",
      "\n",
      "Model# 19. 3215 nodes still misclassified out of torch.Size([12850]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12516/12516 [00:00<00:00, 2624795.44it/s]\n",
      "100%|██████████| 12516/12516 [00:00<00:00, 2990708.65it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1945199.50it/s]\n",
      "Inferring Phrases: 100%|██████████| 12516/12516 [00:00<00:00, 363676.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4207 nodes still misclassified out of torch.Size([12516]) \n",
      "\n",
      "Model# 1. 4207 nodes still misclassified out of torch.Size([12516]) \n",
      "\n",
      "Model# 2. 4207 nodes still misclassified out of torch.Size([12516]) \n",
      "\n",
      "Model# 3. 4207 nodes still misclassified out of torch.Size([12516]) \n",
      "\n",
      "Model# 4. 4207 nodes still misclassified out of torch.Size([12516]) \n",
      "\n",
      "Model# 5. 4207 nodes still misclassified out of torch.Size([12516]) \n",
      "\n",
      "Model# 6. 4207 nodes still misclassified out of torch.Size([12516]) \n",
      "\n",
      "Model# 7. 4207 nodes still misclassified out of torch.Size([12516]) \n",
      "\n",
      "Model# 8. 4207 nodes still misclassified out of torch.Size([12516]) \n",
      "\n",
      "Model# 9. 4207 nodes still misclassified out of torch.Size([12516]) \n",
      "\n",
      "Model# 10. 4207 nodes still misclassified out of torch.Size([12516]) \n",
      "\n",
      "Model# 11. 4207 nodes still misclassified out of torch.Size([12516]) \n",
      "\n",
      "Model# 12. 4207 nodes still misclassified out of torch.Size([12516]) \n",
      "\n",
      "Model# 13. 4207 nodes still misclassified out of torch.Size([12516]) \n",
      "\n",
      "Model# 14. 4207 nodes still misclassified out of torch.Size([12516]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 256/299 [02:29<00:24,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4207 nodes still misclassified out of torch.Size([12516]) \n",
      "\n",
      "Model# 16. 4207 nodes still misclassified out of torch.Size([12516]) \n",
      "\n",
      "Model# 17. 4207 nodes still misclassified out of torch.Size([12516]) \n",
      "\n",
      "Model# 18. 4207 nodes still misclassified out of torch.Size([12516]) \n",
      "\n",
      "Model# 19. 4207 nodes still misclassified out of torch.Size([12516]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12548/12548 [00:00<00:00, 2630585.62it/s]\n",
      "100%|██████████| 12548/12548 [00:00<00:00, 2959908.14it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1932265.36it/s]\n",
      "Inferring Phrases: 100%|██████████| 12548/12548 [00:00<00:00, 373987.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4382 nodes still misclassified out of torch.Size([12548]) \n",
      "\n",
      "Model# 1. 4382 nodes still misclassified out of torch.Size([12548]) \n",
      "\n",
      "Model# 2. 4382 nodes still misclassified out of torch.Size([12548]) \n",
      "\n",
      "Model# 3. 4382 nodes still misclassified out of torch.Size([12548]) \n",
      "\n",
      "Model# 4. 4382 nodes still misclassified out of torch.Size([12548]) \n",
      "\n",
      "Model# 5. 4382 nodes still misclassified out of torch.Size([12548]) \n",
      "\n",
      "Model# 6. 4382 nodes still misclassified out of torch.Size([12548]) \n",
      "\n",
      "Model# 7. 4382 nodes still misclassified out of torch.Size([12548]) \n",
      "\n",
      "Model# 8. 4382 nodes still misclassified out of torch.Size([12548]) \n",
      "\n",
      "Model# 9. 4382 nodes still misclassified out of torch.Size([12548]) \n",
      "\n",
      "Model# 10. 4382 nodes still misclassified out of torch.Size([12548]) \n",
      "\n",
      "Model# 11. 4382 nodes still misclassified out of torch.Size([12548]) \n",
      "\n",
      "Model# 12. 4382 nodes still misclassified out of torch.Size([12548]) \n",
      "\n",
      "Model# 13. 4382 nodes still misclassified out of torch.Size([12548]) \n",
      "\n",
      "Model# 14. 4382 nodes still misclassified out of torch.Size([12548]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 257/299 [02:30<00:23,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4382 nodes still misclassified out of torch.Size([12548]) \n",
      "\n",
      "Model# 16. 4382 nodes still misclassified out of torch.Size([12548]) \n",
      "\n",
      "Model# 17. 4382 nodes still misclassified out of torch.Size([12548]) \n",
      "\n",
      "Model# 18. 4382 nodes still misclassified out of torch.Size([12548]) \n",
      "\n",
      "Model# 19. 4382 nodes still misclassified out of torch.Size([12548]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12841/12841 [00:00<00:00, 3962847.30it/s]\n",
      "100%|██████████| 12841/12841 [00:00<00:00, 4886504.96it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2673461.10it/s]\n",
      "Inferring Phrases: 100%|██████████| 12841/12841 [00:00<00:00, 409051.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4546 nodes still misclassified out of torch.Size([12841]) \n",
      "\n",
      "Model# 1. 4546 nodes still misclassified out of torch.Size([12841]) \n",
      "\n",
      "Model# 2. 4546 nodes still misclassified out of torch.Size([12841]) \n",
      "\n",
      "Model# 3. 4546 nodes still misclassified out of torch.Size([12841]) \n",
      "\n",
      "Model# 4. 4546 nodes still misclassified out of torch.Size([12841]) \n",
      "\n",
      "Model# 5. 4546 nodes still misclassified out of torch.Size([12841]) \n",
      "\n",
      "Model# 6. 4546 nodes still misclassified out of torch.Size([12841]) \n",
      "\n",
      "Model# 7. 4546 nodes still misclassified out of torch.Size([12841]) \n",
      "\n",
      "Model# 8. 4546 nodes still misclassified out of torch.Size([12841]) \n",
      "\n",
      "Model# 9. 4546 nodes still misclassified out of torch.Size([12841]) \n",
      "\n",
      "Model# 10. 4546 nodes still misclassified out of torch.Size([12841]) \n",
      "\n",
      "Model# 11. 4546 nodes still misclassified out of torch.Size([12841]) \n",
      "\n",
      "Model# 12. 4546 nodes still misclassified out of torch.Size([12841]) \n",
      "\n",
      "Model# 13. 4546 nodes still misclassified out of torch.Size([12841]) \n",
      "\n",
      "Model# 14. 4546 nodes still misclassified out of torch.Size([12841]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 258/299 [02:30<00:24,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4546 nodes still misclassified out of torch.Size([12841]) \n",
      "\n",
      "Model# 16. 4546 nodes still misclassified out of torch.Size([12841]) \n",
      "\n",
      "Model# 17. 4546 nodes still misclassified out of torch.Size([12841]) \n",
      "\n",
      "Model# 18. 4546 nodes still misclassified out of torch.Size([12841]) \n",
      "\n",
      "Model# 19. 4546 nodes still misclassified out of torch.Size([12841]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12775/12775 [00:00<00:00, 2587763.62it/s]\n",
      "100%|██████████| 12775/12775 [00:00<00:00, 2929912.16it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1928622.53it/s]\n",
      "Inferring Phrases: 100%|██████████| 12775/12775 [00:00<00:00, 362073.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4335 nodes still misclassified out of torch.Size([12775]) \n",
      "\n",
      "Model# 1. 4335 nodes still misclassified out of torch.Size([12775]) \n",
      "\n",
      "Model# 2. 4335 nodes still misclassified out of torch.Size([12775]) \n",
      "\n",
      "Model# 3. 4335 nodes still misclassified out of torch.Size([12775]) \n",
      "\n",
      "Model# 4. 4335 nodes still misclassified out of torch.Size([12775]) \n",
      "\n",
      "Model# 5. 4335 nodes still misclassified out of torch.Size([12775]) \n",
      "\n",
      "Model# 6. 4335 nodes still misclassified out of torch.Size([12775]) \n",
      "\n",
      "Model# 7. 4335 nodes still misclassified out of torch.Size([12775]) \n",
      "\n",
      "Model# 8. 4335 nodes still misclassified out of torch.Size([12775]) \n",
      "\n",
      "Model# 9. 4335 nodes still misclassified out of torch.Size([12775]) \n",
      "\n",
      "Model# 10. 4335 nodes still misclassified out of torch.Size([12775]) \n",
      "\n",
      "Model# 11. 4335 nodes still misclassified out of torch.Size([12775]) \n",
      "\n",
      "Model# 12. 4335 nodes still misclassified out of torch.Size([12775]) \n",
      "\n",
      "Model# 13. 4335 nodes still misclassified out of torch.Size([12775]) \n",
      "\n",
      "Model# 14. 4335 nodes still misclassified out of torch.Size([12775]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 259/299 [02:31<00:23,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4335 nodes still misclassified out of torch.Size([12775]) \n",
      "\n",
      "Model# 16. 4335 nodes still misclassified out of torch.Size([12775]) \n",
      "\n",
      "Model# 17. 4335 nodes still misclassified out of torch.Size([12775]) \n",
      "\n",
      "Model# 18. 4335 nodes still misclassified out of torch.Size([12775]) \n",
      "\n",
      "Model# 19. 4335 nodes still misclassified out of torch.Size([12775]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15611/15611 [00:00<00:00, 3483019.30it/s]\n",
      "100%|██████████| 15611/15611 [00:00<00:00, 4553674.09it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2664403.51it/s]\n",
      "Inferring Phrases: 100%|██████████| 15611/15611 [00:00<00:00, 469082.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 7236 nodes still misclassified out of torch.Size([15611]) \n",
      "\n",
      "Model# 1. 7236 nodes still misclassified out of torch.Size([15611]) \n",
      "\n",
      "Model# 2. 7236 nodes still misclassified out of torch.Size([15611]) \n",
      "\n",
      "Model# 3. 7236 nodes still misclassified out of torch.Size([15611]) \n",
      "\n",
      "Model# 4. 7236 nodes still misclassified out of torch.Size([15611]) \n",
      "\n",
      "Model# 5. 7236 nodes still misclassified out of torch.Size([15611]) \n",
      "\n",
      "Model# 6. 7236 nodes still misclassified out of torch.Size([15611]) \n",
      "\n",
      "Model# 7. 7236 nodes still misclassified out of torch.Size([15611]) \n",
      "\n",
      "Model# 8. 7236 nodes still misclassified out of torch.Size([15611]) \n",
      "\n",
      "Model# 9. 7236 nodes still misclassified out of torch.Size([15611]) \n",
      "\n",
      "Model# 10. 7236 nodes still misclassified out of torch.Size([15611]) \n",
      "\n",
      "Model# 11. 7236 nodes still misclassified out of torch.Size([15611]) \n",
      "\n",
      "Model# 12. 7236 nodes still misclassified out of torch.Size([15611]) \n",
      "\n",
      "Model# 13. 7236 nodes still misclassified out of torch.Size([15611]) \n",
      "\n",
      "Model# 14. 7236 nodes still misclassified out of torch.Size([15611]) \n",
      "\n",
      "Model# 15. 7236 nodes still misclassified out of torch.Size([15611]) \n",
      "\n",
      "Model# 16. 7236 nodes still misclassified out of torch.Size([15611]) \n",
      "\n",
      "Model# 17. 7236 nodes still misclassified out of torch.Size([15611]) \n",
      "\n",
      "Model# 18. 7236 nodes still misclassified out of torch.Size([15611]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 260/299 [02:32<00:25,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 7236 nodes still misclassified out of torch.Size([15611]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14690/14690 [00:00<00:00, 2419094.06it/s]\n",
      "100%|██████████| 14690/14690 [00:00<00:00, 2843431.90it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1825515.32it/s]\n",
      "Inferring Phrases: 100%|██████████| 14690/14690 [00:00<00:00, 432272.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6466 nodes still misclassified out of torch.Size([14690]) \n",
      "\n",
      "Model# 1. 6466 nodes still misclassified out of torch.Size([14690]) \n",
      "\n",
      "Model# 2. 6466 nodes still misclassified out of torch.Size([14690]) \n",
      "\n",
      "Model# 3. 6466 nodes still misclassified out of torch.Size([14690]) \n",
      "\n",
      "Model# 4. 6466 nodes still misclassified out of torch.Size([14690]) \n",
      "\n",
      "Model# 5. 6466 nodes still misclassified out of torch.Size([14690]) \n",
      "\n",
      "Model# 6. 6466 nodes still misclassified out of torch.Size([14690]) \n",
      "\n",
      "Model# 7. 6466 nodes still misclassified out of torch.Size([14690]) \n",
      "\n",
      "Model# 8. 6466 nodes still misclassified out of torch.Size([14690]) \n",
      "\n",
      "Model# 9. 6466 nodes still misclassified out of torch.Size([14690]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 261/299 [02:32<00:25,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 6466 nodes still misclassified out of torch.Size([14690]) \n",
      "\n",
      "Model# 11. 6466 nodes still misclassified out of torch.Size([14690]) \n",
      "\n",
      "Model# 12. 6466 nodes still misclassified out of torch.Size([14690]) \n",
      "\n",
      "Model# 13. 6466 nodes still misclassified out of torch.Size([14690]) \n",
      "\n",
      "Model# 14. 6466 nodes still misclassified out of torch.Size([14690]) \n",
      "\n",
      "Model# 15. 6466 nodes still misclassified out of torch.Size([14690]) \n",
      "\n",
      "Model# 16. 6466 nodes still misclassified out of torch.Size([14690]) \n",
      "\n",
      "Model# 17. 6466 nodes still misclassified out of torch.Size([14690]) \n",
      "\n",
      "Model# 18. 6466 nodes still misclassified out of torch.Size([14690]) \n",
      "\n",
      "Model# 19. 6466 nodes still misclassified out of torch.Size([14690]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13763/13763 [00:00<00:00, 2536523.68it/s]\n",
      "100%|██████████| 13763/13763 [00:00<00:00, 2937720.40it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1834992.71it/s]\n",
      "Inferring Phrases: 100%|██████████| 13763/13763 [00:00<00:00, 415383.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5659 nodes still misclassified out of torch.Size([13763]) \n",
      "\n",
      "Model# 1. 5659 nodes still misclassified out of torch.Size([13763]) \n",
      "\n",
      "Model# 2. 5659 nodes still misclassified out of torch.Size([13763]) \n",
      "\n",
      "Model# 3. 5659 nodes still misclassified out of torch.Size([13763]) \n",
      "\n",
      "Model# 4. 5659 nodes still misclassified out of torch.Size([13763]) \n",
      "\n",
      "Model# 5. 5659 nodes still misclassified out of torch.Size([13763]) \n",
      "\n",
      "Model# 6. 5659 nodes still misclassified out of torch.Size([13763]) \n",
      "\n",
      "Model# 7. 5659 nodes still misclassified out of torch.Size([13763]) \n",
      "\n",
      "Model# 8. 5659 nodes still misclassified out of torch.Size([13763]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 262/299 [02:33<00:24,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 9. 5659 nodes still misclassified out of torch.Size([13763]) \n",
      "\n",
      "Model# 10. 5659 nodes still misclassified out of torch.Size([13763]) \n",
      "\n",
      "Model# 11. 5659 nodes still misclassified out of torch.Size([13763]) \n",
      "\n",
      "Model# 12. 5659 nodes still misclassified out of torch.Size([13763]) \n",
      "\n",
      "Model# 13. 5659 nodes still misclassified out of torch.Size([13763]) \n",
      "\n",
      "Model# 14. 5659 nodes still misclassified out of torch.Size([13763]) \n",
      "\n",
      "Model# 15. 5659 nodes still misclassified out of torch.Size([13763]) \n",
      "\n",
      "Model# 16. 5659 nodes still misclassified out of torch.Size([13763]) \n",
      "\n",
      "Model# 17. 5659 nodes still misclassified out of torch.Size([13763]) \n",
      "\n",
      "Model# 18. 5659 nodes still misclassified out of torch.Size([13763]) \n",
      "\n",
      "Model# 19. 5659 nodes still misclassified out of torch.Size([13763]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13601/13601 [00:00<00:00, 4073893.36it/s]\n",
      "100%|██████████| 13601/13601 [00:00<00:00, 5072172.91it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2757294.18it/s]\n",
      "Inferring Phrases: 100%|██████████| 13601/13601 [00:00<00:00, 424970.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4720 nodes still misclassified out of torch.Size([13601]) \n",
      "\n",
      "Model# 1. 4720 nodes still misclassified out of torch.Size([13601]) \n",
      "\n",
      "Model# 2. 4720 nodes still misclassified out of torch.Size([13601]) \n",
      "\n",
      "Model# 3. 4720 nodes still misclassified out of torch.Size([13601]) \n",
      "\n",
      "Model# 4. 4720 nodes still misclassified out of torch.Size([13601]) \n",
      "\n",
      "Model# 5. 4720 nodes still misclassified out of torch.Size([13601]) \n",
      "\n",
      "Model# 6. 4720 nodes still misclassified out of torch.Size([13601]) \n",
      "\n",
      "Model# 7. 4720 nodes still misclassified out of torch.Size([13601]) \n",
      "\n",
      "Model# 8. 4720 nodes still misclassified out of torch.Size([13601]) \n",
      "\n",
      "Model# 9. 4720 nodes still misclassified out of torch.Size([13601]) \n",
      "\n",
      "Model# 10. 4720 nodes still misclassified out of torch.Size([13601]) \n",
      "\n",
      "Model# 11. 4720 nodes still misclassified out of torch.Size([13601]) \n",
      "\n",
      "Model# 12. 4720 nodes still misclassified out of torch.Size([13601]) \n",
      "\n",
      "Model# 13. 4720 nodes still misclassified out of torch.Size([13601]) \n",
      "\n",
      "Model# 14. 4720 nodes still misclassified out of torch.Size([13601]) \n",
      "\n",
      "Model# 15. 4720 nodes still misclassified out of torch.Size([13601]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 263/299 [02:34<00:24,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 16. 4720 nodes still misclassified out of torch.Size([13601]) \n",
      "\n",
      "Model# 17. 4720 nodes still misclassified out of torch.Size([13601]) \n",
      "\n",
      "Model# 18. 4720 nodes still misclassified out of torch.Size([13601]) \n",
      "\n",
      "Model# 19. 4720 nodes still misclassified out of torch.Size([13601]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13243/13243 [00:00<00:00, 3810989.22it/s]\n",
      "100%|██████████| 13243/13243 [00:00<00:00, 4456448.00it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2617132.64it/s]\n",
      "Inferring Phrases: 100%|██████████| 13243/13243 [00:00<00:00, 384140.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4275 nodes still misclassified out of torch.Size([13243]) \n",
      "\n",
      "Model# 1. 4275 nodes still misclassified out of torch.Size([13243]) \n",
      "\n",
      "Model# 2. 4275 nodes still misclassified out of torch.Size([13243]) \n",
      "\n",
      "Model# 3. 4275 nodes still misclassified out of torch.Size([13243]) \n",
      "\n",
      "Model# 4. 4275 nodes still misclassified out of torch.Size([13243]) \n",
      "\n",
      "Model# 5. 4275 nodes still misclassified out of torch.Size([13243]) \n",
      "\n",
      "Model# 6. 4275 nodes still misclassified out of torch.Size([13243]) \n",
      "\n",
      "Model# 7. 4275 nodes still misclassified out of torch.Size([13243]) \n",
      "\n",
      "Model# 8. 4275 nodes still misclassified out of torch.Size([13243]) \n",
      "\n",
      "Model# 9. 4275 nodes still misclassified out of torch.Size([13243]) \n",
      "\n",
      "Model# 10. 4275 nodes still misclassified out of torch.Size([13243]) \n",
      "\n",
      "Model# 11. 4275 nodes still misclassified out of torch.Size([13243]) \n",
      "\n",
      "Model# 12. 4275 nodes still misclassified out of torch.Size([13243]) \n",
      "\n",
      "Model# 13. 4275 nodes still misclassified out of torch.Size([13243]) \n",
      "\n",
      "Model# 14. 4275 nodes still misclassified out of torch.Size([13243]) \n",
      "\n",
      "Model# 15. 4275 nodes still misclassified out of torch.Size([13243]) \n",
      "\n",
      "Model# 16. 4275 nodes still misclassified out of torch.Size([13243]) \n",
      "\n",
      "Model# 17. 4275 nodes still misclassified out of torch.Size([13243]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 264/299 [02:34<00:21,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 18. 4275 nodes still misclassified out of torch.Size([13243]) \n",
      "\n",
      "Model# 19. 4275 nodes still misclassified out of torch.Size([13243]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12683/12683 [00:00<00:00, 2375898.06it/s]\n",
      "100%|██████████| 12683/12683 [00:00<00:00, 2894409.80it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1912558.25it/s]\n",
      "Inferring Phrases: 100%|██████████| 12683/12683 [00:00<00:00, 357858.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4440 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 1. 4440 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 2. 4440 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 3. 4440 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 4. 4440 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 5. 4440 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 6. 4440 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 7. 4440 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 8. 4440 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 9. 4440 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 10. 4440 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 11. 4440 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 12. 4440 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 13. 4440 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 14. 4440 nodes still misclassified out of torch.Size([12683]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 265/299 [02:35<00:20,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4440 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 16. 4440 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 17. 4440 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 18. 4440 nodes still misclassified out of torch.Size([12683]) \n",
      "\n",
      "Model# 19. 4440 nodes still misclassified out of torch.Size([12683]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12994/12994 [00:00<00:00, 4304619.40it/s]\n",
      "100%|██████████| 12994/12994 [00:00<00:00, 5161548.08it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2798690.39it/s]\n",
      "Inferring Phrases: 100%|██████████| 12994/12994 [00:00<00:00, 424771.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4646 nodes still misclassified out of torch.Size([12994]) \n",
      "\n",
      "Model# 1. 4646 nodes still misclassified out of torch.Size([12994]) \n",
      "\n",
      "Model# 2. 4646 nodes still misclassified out of torch.Size([12994]) \n",
      "\n",
      "Model# 3. 4646 nodes still misclassified out of torch.Size([12994]) \n",
      "\n",
      "Model# 4. 4646 nodes still misclassified out of torch.Size([12994]) \n",
      "\n",
      "Model# 5. 4646 nodes still misclassified out of torch.Size([12994]) \n",
      "\n",
      "Model# 6. 4646 nodes still misclassified out of torch.Size([12994]) \n",
      "\n",
      "Model# 7. 4646 nodes still misclassified out of torch.Size([12994]) \n",
      "\n",
      "Model# 8. 4646 nodes still misclassified out of torch.Size([12994]) \n",
      "\n",
      "Model# 9. 4646 nodes still misclassified out of torch.Size([12994]) \n",
      "\n",
      "Model# 10. 4646 nodes still misclassified out of torch.Size([12994]) \n",
      "\n",
      "Model# 11. 4646 nodes still misclassified out of torch.Size([12994]) \n",
      "\n",
      "Model# 12. 4646 nodes still misclassified out of torch.Size([12994]) \n",
      "\n",
      "Model# 13. 4646 nodes still misclassified out of torch.Size([12994]) \n",
      "\n",
      "Model# 14. 4646 nodes still misclassified out of torch.Size([12994]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 266/299 [02:35<00:20,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4646 nodes still misclassified out of torch.Size([12994]) \n",
      "\n",
      "Model# 16. 4646 nodes still misclassified out of torch.Size([12994]) \n",
      "\n",
      "Model# 17. 4646 nodes still misclassified out of torch.Size([12994]) \n",
      "\n",
      "Model# 18. 4646 nodes still misclassified out of torch.Size([12994]) \n",
      "\n",
      "Model# 19. 4646 nodes still misclassified out of torch.Size([12994]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12676/12676 [00:00<00:00, 2630336.79it/s]\n",
      "100%|██████████| 12676/12676 [00:00<00:00, 2953722.08it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1938636.18it/s]\n",
      "Inferring Phrases: 100%|██████████| 12676/12676 [00:00<00:00, 377437.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4470 nodes still misclassified out of torch.Size([12676]) \n",
      "\n",
      "Model# 1. 4470 nodes still misclassified out of torch.Size([12676]) \n",
      "\n",
      "Model# 2. 4470 nodes still misclassified out of torch.Size([12676]) \n",
      "\n",
      "Model# 3. 4470 nodes still misclassified out of torch.Size([12676]) \n",
      "\n",
      "Model# 4. 4470 nodes still misclassified out of torch.Size([12676]) \n",
      "\n",
      "Model# 5. 4470 nodes still misclassified out of torch.Size([12676]) \n",
      "\n",
      "Model# 6. 4470 nodes still misclassified out of torch.Size([12676]) \n",
      "\n",
      "Model# 7. 4470 nodes still misclassified out of torch.Size([12676]) \n",
      "\n",
      "Model# 8. 4470 nodes still misclassified out of torch.Size([12676]) \n",
      "\n",
      "Model# 9. 4470 nodes still misclassified out of torch.Size([12676]) \n",
      "\n",
      "Model# 10. 4470 nodes still misclassified out of torch.Size([12676]) \n",
      "\n",
      "Model# 11. 4470 nodes still misclassified out of torch.Size([12676]) \n",
      "\n",
      "Model# 12. 4470 nodes still misclassified out of torch.Size([12676]) \n",
      "\n",
      "Model# 13. 4470 nodes still misclassified out of torch.Size([12676]) \n",
      "\n",
      "Model# 14. 4470 nodes still misclassified out of torch.Size([12676]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 267/299 [02:36<00:18,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4470 nodes still misclassified out of torch.Size([12676]) \n",
      "\n",
      "Model# 16. 4470 nodes still misclassified out of torch.Size([12676]) \n",
      "\n",
      "Model# 17. 4470 nodes still misclassified out of torch.Size([12676]) \n",
      "\n",
      "Model# 18. 4470 nodes still misclassified out of torch.Size([12676]) \n",
      "\n",
      "Model# 19. 4470 nodes still misclassified out of torch.Size([12676]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12428/12428 [00:00<00:00, 2502607.43it/s]\n",
      "100%|██████████| 12428/12428 [00:00<00:00, 2885513.98it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1886606.69it/s]\n",
      "Inferring Phrases: 100%|██████████| 12428/12428 [00:00<00:00, 367116.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4765 nodes still misclassified out of torch.Size([12428]) \n",
      "\n",
      "Model# 1. 4765 nodes still misclassified out of torch.Size([12428]) \n",
      "\n",
      "Model# 2. 4765 nodes still misclassified out of torch.Size([12428]) \n",
      "\n",
      "Model# 3. 4765 nodes still misclassified out of torch.Size([12428]) \n",
      "\n",
      "Model# 4. 4765 nodes still misclassified out of torch.Size([12428]) \n",
      "\n",
      "Model# 5. 4765 nodes still misclassified out of torch.Size([12428]) \n",
      "\n",
      "Model# 6. 4765 nodes still misclassified out of torch.Size([12428]) \n",
      "\n",
      "Model# 7. 4765 nodes still misclassified out of torch.Size([12428]) \n",
      "\n",
      "Model# 8. 4765 nodes still misclassified out of torch.Size([12428]) \n",
      "\n",
      "Model# 9. 4765 nodes still misclassified out of torch.Size([12428]) \n",
      "\n",
      "Model# 10. 4765 nodes still misclassified out of torch.Size([12428]) \n",
      "\n",
      "Model# 11. 4765 nodes still misclassified out of torch.Size([12428]) \n",
      "\n",
      "Model# 12. 4765 nodes still misclassified out of torch.Size([12428]) \n",
      "\n",
      "Model# 13. 4765 nodes still misclassified out of torch.Size([12428]) \n",
      "\n",
      "Model# 14. 4765 nodes still misclassified out of torch.Size([12428]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 268/299 [02:36<00:17,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4765 nodes still misclassified out of torch.Size([12428]) \n",
      "\n",
      "Model# 16. 4765 nodes still misclassified out of torch.Size([12428]) \n",
      "\n",
      "Model# 17. 4765 nodes still misclassified out of torch.Size([12428]) \n",
      "\n",
      "Model# 18. 4765 nodes still misclassified out of torch.Size([12428]) \n",
      "\n",
      "Model# 19. 4765 nodes still misclassified out of torch.Size([12428]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12480/12480 [00:00<00:00, 4250500.52it/s]\n",
      "100%|██████████| 12480/12480 [00:00<00:00, 5131854.31it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2861703.89it/s]\n",
      "Inferring Phrases: 100%|██████████| 12480/12480 [00:00<00:00, 415429.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4707 nodes still misclassified out of torch.Size([12480]) \n",
      "\n",
      "Model# 1. 4707 nodes still misclassified out of torch.Size([12480]) \n",
      "\n",
      "Model# 2. 4707 nodes still misclassified out of torch.Size([12480]) \n",
      "\n",
      "Model# 3. 4707 nodes still misclassified out of torch.Size([12480]) \n",
      "\n",
      "Model# 4. 4707 nodes still misclassified out of torch.Size([12480]) \n",
      "\n",
      "Model# 5. 4707 nodes still misclassified out of torch.Size([12480]) \n",
      "\n",
      "Model# 6. 4707 nodes still misclassified out of torch.Size([12480]) \n",
      "\n",
      "Model# 7. 4707 nodes still misclassified out of torch.Size([12480]) \n",
      "\n",
      "Model# 8. 4707 nodes still misclassified out of torch.Size([12480]) \n",
      "\n",
      "Model# 9. 4707 nodes still misclassified out of torch.Size([12480]) \n",
      "\n",
      "Model# 10. 4707 nodes still misclassified out of torch.Size([12480]) \n",
      "\n",
      "Model# 11. 4707 nodes still misclassified out of torch.Size([12480]) \n",
      "\n",
      "Model# 12. 4707 nodes still misclassified out of torch.Size([12480]) \n",
      "\n",
      "Model# 13. 4707 nodes still misclassified out of torch.Size([12480]) \n",
      "\n",
      "Model# 14. 4707 nodes still misclassified out of torch.Size([12480]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 269/299 [02:37<00:17,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4707 nodes still misclassified out of torch.Size([12480]) \n",
      "\n",
      "Model# 16. 4707 nodes still misclassified out of torch.Size([12480]) \n",
      "\n",
      "Model# 17. 4707 nodes still misclassified out of torch.Size([12480]) \n",
      "\n",
      "Model# 18. 4707 nodes still misclassified out of torch.Size([12480]) \n",
      "\n",
      "Model# 19. 4707 nodes still misclassified out of torch.Size([12480]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12551/12551 [00:00<00:00, 2567185.68it/s]\n",
      "100%|██████████| 12551/12551 [00:00<00:00, 2940440.68it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1894332.17it/s]\n",
      "Inferring Phrases: 100%|██████████| 12551/12551 [00:00<00:00, 367786.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4320 nodes still misclassified out of torch.Size([12551]) \n",
      "\n",
      "Model# 1. 4320 nodes still misclassified out of torch.Size([12551]) \n",
      "\n",
      "Model# 2. 4320 nodes still misclassified out of torch.Size([12551]) \n",
      "\n",
      "Model# 3. 4320 nodes still misclassified out of torch.Size([12551]) \n",
      "\n",
      "Model# 4. 4320 nodes still misclassified out of torch.Size([12551]) \n",
      "\n",
      "Model# 5. 4320 nodes still misclassified out of torch.Size([12551]) \n",
      "\n",
      "Model# 6. 4320 nodes still misclassified out of torch.Size([12551]) \n",
      "\n",
      "Model# 7. 4320 nodes still misclassified out of torch.Size([12551]) \n",
      "\n",
      "Model# 8. 4320 nodes still misclassified out of torch.Size([12551]) \n",
      "\n",
      "Model# 9. 4320 nodes still misclassified out of torch.Size([12551]) \n",
      "\n",
      "Model# 10. 4320 nodes still misclassified out of torch.Size([12551]) \n",
      "\n",
      "Model# 11. 4320 nodes still misclassified out of torch.Size([12551]) \n",
      "\n",
      "Model# 12. 4320 nodes still misclassified out of torch.Size([12551]) \n",
      "\n",
      "Model# 13. 4320 nodes still misclassified out of torch.Size([12551]) \n",
      "\n",
      "Model# 14. 4320 nodes still misclassified out of torch.Size([12551]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 270/299 [02:38<00:16,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4320 nodes still misclassified out of torch.Size([12551]) \n",
      "\n",
      "Model# 16. 4320 nodes still misclassified out of torch.Size([12551]) \n",
      "\n",
      "Model# 17. 4320 nodes still misclassified out of torch.Size([12551]) \n",
      "\n",
      "Model# 18. 4320 nodes still misclassified out of torch.Size([12551]) \n",
      "\n",
      "Model# 19. 4320 nodes still misclassified out of torch.Size([12551]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13837/13837 [00:00<00:00, 3979469.59it/s]\n",
      "100%|██████████| 13837/13837 [00:00<00:00, 4652604.17it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2560364.64it/s]\n",
      "Inferring Phrases: 100%|██████████| 13837/13837 [00:00<00:00, 422047.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5469 nodes still misclassified out of torch.Size([13837]) \n",
      "\n",
      "Model# 1. 5469 nodes still misclassified out of torch.Size([13837]) \n",
      "\n",
      "Model# 2. 5469 nodes still misclassified out of torch.Size([13837]) \n",
      "\n",
      "Model# 3. 5469 nodes still misclassified out of torch.Size([13837]) \n",
      "\n",
      "Model# 4. 5469 nodes still misclassified out of torch.Size([13837]) \n",
      "\n",
      "Model# 5. 5469 nodes still misclassified out of torch.Size([13837]) \n",
      "\n",
      "Model# 6. 5469 nodes still misclassified out of torch.Size([13837]) \n",
      "\n",
      "Model# 7. 5469 nodes still misclassified out of torch.Size([13837]) \n",
      "\n",
      "Model# 8. 5469 nodes still misclassified out of torch.Size([13837]) \n",
      "\n",
      "Model# 9. 5469 nodes still misclassified out of torch.Size([13837]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 271/299 [02:38<00:17,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 5469 nodes still misclassified out of torch.Size([13837]) \n",
      "\n",
      "Model# 11. 5469 nodes still misclassified out of torch.Size([13837]) \n",
      "\n",
      "Model# 12. 5469 nodes still misclassified out of torch.Size([13837]) \n",
      "\n",
      "Model# 13. 5469 nodes still misclassified out of torch.Size([13837]) \n",
      "\n",
      "Model# 14. 5469 nodes still misclassified out of torch.Size([13837]) \n",
      "\n",
      "Model# 15. 5469 nodes still misclassified out of torch.Size([13837]) \n",
      "\n",
      "Model# 16. 5469 nodes still misclassified out of torch.Size([13837]) \n",
      "\n",
      "Model# 17. 5469 nodes still misclassified out of torch.Size([13837]) \n",
      "\n",
      "Model# 18. 5469 nodes still misclassified out of torch.Size([13837]) \n",
      "\n",
      "Model# 19. 5469 nodes still misclassified out of torch.Size([13837]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14908/14908 [00:00<00:00, 2500147.30it/s]\n",
      "100%|██████████| 14908/14908 [00:00<00:00, 2853627.42it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1808409.31it/s]\n",
      "Inferring Phrases: 100%|██████████| 14908/14908 [00:00<00:00, 454707.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6161 nodes still misclassified out of torch.Size([14908]) \n",
      "\n",
      "Model# 1. 6161 nodes still misclassified out of torch.Size([14908]) \n",
      "\n",
      "Model# 2. 6161 nodes still misclassified out of torch.Size([14908]) \n",
      "\n",
      "Model# 3. 6161 nodes still misclassified out of torch.Size([14908]) \n",
      "\n",
      "Model# 4. 6161 nodes still misclassified out of torch.Size([14908]) \n",
      "\n",
      "Model# 5. 6161 nodes still misclassified out of torch.Size([14908]) \n",
      "\n",
      "Model# 6. 6161 nodes still misclassified out of torch.Size([14908]) \n",
      "\n",
      "Model# 7. 6161 nodes still misclassified out of torch.Size([14908]) \n",
      "\n",
      "Model# 8. 6161 nodes still misclassified out of torch.Size([14908]) \n",
      "\n",
      "Model# 9. 6161 nodes still misclassified out of torch.Size([14908]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 272/299 [02:39<00:17,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 6161 nodes still misclassified out of torch.Size([14908]) \n",
      "\n",
      "Model# 11. 6161 nodes still misclassified out of torch.Size([14908]) \n",
      "\n",
      "Model# 12. 6161 nodes still misclassified out of torch.Size([14908]) \n",
      "\n",
      "Model# 13. 6161 nodes still misclassified out of torch.Size([14908]) \n",
      "\n",
      "Model# 14. 6161 nodes still misclassified out of torch.Size([14908]) \n",
      "\n",
      "Model# 15. 6161 nodes still misclassified out of torch.Size([14908]) \n",
      "\n",
      "Model# 16. 6161 nodes still misclassified out of torch.Size([14908]) \n",
      "\n",
      "Model# 17. 6161 nodes still misclassified out of torch.Size([14908]) \n",
      "\n",
      "Model# 18. 6161 nodes still misclassified out of torch.Size([14908]) \n",
      "\n",
      "Model# 19. 6161 nodes still misclassified out of torch.Size([14908]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14327/14327 [00:00<00:00, 2539805.30it/s]\n",
      "100%|██████████| 14327/14327 [00:00<00:00, 2862195.45it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1808123.46it/s]\n",
      "Inferring Phrases: 100%|██████████| 14327/14327 [00:00<00:00, 438389.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6396 nodes still misclassified out of torch.Size([14327]) \n",
      "\n",
      "Model# 1. 6396 nodes still misclassified out of torch.Size([14327]) \n",
      "\n",
      "Model# 2. 6396 nodes still misclassified out of torch.Size([14327]) \n",
      "\n",
      "Model# 3. 6396 nodes still misclassified out of torch.Size([14327]) \n",
      "\n",
      "Model# 4. 6396 nodes still misclassified out of torch.Size([14327]) \n",
      "\n",
      "Model# 5. 6396 nodes still misclassified out of torch.Size([14327]) \n",
      "\n",
      "Model# 6. 6396 nodes still misclassified out of torch.Size([14327]) \n",
      "\n",
      "Model# 7. 6396 nodes still misclassified out of torch.Size([14327]) \n",
      "\n",
      "Model# 8. 6396 nodes still misclassified out of torch.Size([14327]) \n",
      "\n",
      "Model# 9. 6396 nodes still misclassified out of torch.Size([14327]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 273/299 [02:40<00:17,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 6396 nodes still misclassified out of torch.Size([14327]) \n",
      "\n",
      "Model# 11. 6396 nodes still misclassified out of torch.Size([14327]) \n",
      "\n",
      "Model# 12. 6396 nodes still misclassified out of torch.Size([14327]) \n",
      "\n",
      "Model# 13. 6396 nodes still misclassified out of torch.Size([14327]) \n",
      "\n",
      "Model# 14. 6396 nodes still misclassified out of torch.Size([14327]) \n",
      "\n",
      "Model# 15. 6396 nodes still misclassified out of torch.Size([14327]) \n",
      "\n",
      "Model# 16. 6396 nodes still misclassified out of torch.Size([14327]) \n",
      "\n",
      "Model# 17. 6396 nodes still misclassified out of torch.Size([14327]) \n",
      "\n",
      "Model# 18. 6396 nodes still misclassified out of torch.Size([14327]) \n",
      "\n",
      "Model# 19. 6396 nodes still misclassified out of torch.Size([14327]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13890/13890 [00:00<00:00, 4119564.60it/s]\n",
      "100%|██████████| 13890/13890 [00:00<00:00, 4997759.51it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2645914.71it/s]\n",
      "Inferring Phrases: 100%|██████████| 13890/13890 [00:00<00:00, 438508.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5610 nodes still misclassified out of torch.Size([13890]) \n",
      "\n",
      "Model# 1. 5610 nodes still misclassified out of torch.Size([13890]) \n",
      "\n",
      "Model# 2. 5610 nodes still misclassified out of torch.Size([13890]) \n",
      "\n",
      "Model# 3. 5610 nodes still misclassified out of torch.Size([13890]) \n",
      "\n",
      "Model# 4. 5610 nodes still misclassified out of torch.Size([13890]) \n",
      "\n",
      "Model# 5. 5610 nodes still misclassified out of torch.Size([13890]) \n",
      "\n",
      "Model# 6. 5610 nodes still misclassified out of torch.Size([13890]) \n",
      "\n",
      "Model# 7. 5610 nodes still misclassified out of torch.Size([13890]) \n",
      "\n",
      "Model# 8. 5610 nodes still misclassified out of torch.Size([13890]) \n",
      "\n",
      "Model# 9. 5610 nodes still misclassified out of torch.Size([13890]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 274/299 [02:41<00:17,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 5610 nodes still misclassified out of torch.Size([13890]) \n",
      "\n",
      "Model# 11. 5610 nodes still misclassified out of torch.Size([13890]) \n",
      "\n",
      "Model# 12. 5610 nodes still misclassified out of torch.Size([13890]) \n",
      "\n",
      "Model# 13. 5610 nodes still misclassified out of torch.Size([13890]) \n",
      "\n",
      "Model# 14. 5610 nodes still misclassified out of torch.Size([13890]) \n",
      "\n",
      "Model# 15. 5610 nodes still misclassified out of torch.Size([13890]) \n",
      "\n",
      "Model# 16. 5610 nodes still misclassified out of torch.Size([13890]) \n",
      "\n",
      "Model# 17. 5610 nodes still misclassified out of torch.Size([13890]) \n",
      "\n",
      "Model# 18. 5610 nodes still misclassified out of torch.Size([13890]) \n",
      "\n",
      "Model# 19. 5610 nodes still misclassified out of torch.Size([13890]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12589/12589 [00:00<00:00, 2639444.79it/s]\n",
      "100%|██████████| 12589/12589 [00:00<00:00, 2968077.18it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1902006.17it/s]\n",
      "Inferring Phrases: 100%|██████████| 12589/12589 [00:00<00:00, 403275.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4568 nodes still misclassified out of torch.Size([12589]) \n",
      "\n",
      "Model# 1. 4568 nodes still misclassified out of torch.Size([12589]) \n",
      "\n",
      "Model# 2. 4568 nodes still misclassified out of torch.Size([12589]) \n",
      "\n",
      "Model# 3. 4568 nodes still misclassified out of torch.Size([12589]) \n",
      "\n",
      "Model# 4. 4568 nodes still misclassified out of torch.Size([12589]) \n",
      "\n",
      "Model# 5. 4568 nodes still misclassified out of torch.Size([12589]) \n",
      "\n",
      "Model# 6. 4568 nodes still misclassified out of torch.Size([12589]) \n",
      "\n",
      "Model# 7. 4568 nodes still misclassified out of torch.Size([12589]) \n",
      "\n",
      "Model# 8. 4568 nodes still misclassified out of torch.Size([12589]) \n",
      "\n",
      "Model# 9. 4568 nodes still misclassified out of torch.Size([12589]) \n",
      "\n",
      "Model# 10. 4568 nodes still misclassified out of torch.Size([12589]) \n",
      "\n",
      "Model# 11. 4568 nodes still misclassified out of torch.Size([12589]) \n",
      "\n",
      "Model# 12. 4568 nodes still misclassified out of torch.Size([12589]) \n",
      "\n",
      "Model# 13. 4568 nodes still misclassified out of torch.Size([12589]) \n",
      "\n",
      "Model# 14. 4568 nodes still misclassified out of torch.Size([12589]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 275/299 [02:41<00:15,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4568 nodes still misclassified out of torch.Size([12589]) \n",
      "\n",
      "Model# 16. 4568 nodes still misclassified out of torch.Size([12589]) \n",
      "\n",
      "Model# 17. 4568 nodes still misclassified out of torch.Size([12589]) \n",
      "\n",
      "Model# 18. 4568 nodes still misclassified out of torch.Size([12589]) \n",
      "\n",
      "Model# 19. 4568 nodes still misclassified out of torch.Size([12589]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12695/12695 [00:00<00:00, 2528933.24it/s]\n",
      "100%|██████████| 12695/12695 [00:00<00:00, 2941318.53it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1901517.54it/s]\n",
      "Inferring Phrases: 100%|██████████| 12695/12695 [00:00<00:00, 381962.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4561 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 1. 4561 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 2. 4561 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 3. 4561 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 4. 4561 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 5. 4561 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 6. 4561 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 7. 4561 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 8. 4561 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 9. 4561 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 10. 4561 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 11. 4561 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 12. 4561 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 13. 4561 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 14. 4561 nodes still misclassified out of torch.Size([12695]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 276/299 [02:42<00:14,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4561 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 16. 4561 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 17. 4561 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 18. 4561 nodes still misclassified out of torch.Size([12695]) \n",
      "\n",
      "Model# 19. 4561 nodes still misclassified out of torch.Size([12695]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12429/12429 [00:00<00:00, 3927005.98it/s]\n",
      "100%|██████████| 12429/12429 [00:00<00:00, 4986704.08it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2770407.10it/s]\n",
      "Inferring Phrases: 100%|██████████| 12429/12429 [00:00<00:00, 404354.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4356 nodes still misclassified out of torch.Size([12429]) \n",
      "\n",
      "Model# 1. 4356 nodes still misclassified out of torch.Size([12429]) \n",
      "\n",
      "Model# 2. 4356 nodes still misclassified out of torch.Size([12429]) \n",
      "\n",
      "Model# 3. 4356 nodes still misclassified out of torch.Size([12429]) \n",
      "\n",
      "Model# 4. 4356 nodes still misclassified out of torch.Size([12429]) \n",
      "\n",
      "Model# 5. 4356 nodes still misclassified out of torch.Size([12429]) \n",
      "\n",
      "Model# 6. 4356 nodes still misclassified out of torch.Size([12429]) \n",
      "\n",
      "Model# 7. 4356 nodes still misclassified out of torch.Size([12429]) \n",
      "\n",
      "Model# 8. 4356 nodes still misclassified out of torch.Size([12429]) \n",
      "\n",
      "Model# 9. 4356 nodes still misclassified out of torch.Size([12429]) \n",
      "\n",
      "Model# 10. 4356 nodes still misclassified out of torch.Size([12429]) \n",
      "\n",
      "Model# 11. 4356 nodes still misclassified out of torch.Size([12429]) \n",
      "\n",
      "Model# 12. 4356 nodes still misclassified out of torch.Size([12429]) \n",
      "\n",
      "Model# 13. 4356 nodes still misclassified out of torch.Size([12429]) \n",
      "\n",
      "Model# 14. 4356 nodes still misclassified out of torch.Size([12429]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 277/299 [02:42<00:13,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4356 nodes still misclassified out of torch.Size([12429]) \n",
      "\n",
      "Model# 16. 4356 nodes still misclassified out of torch.Size([12429]) \n",
      "\n",
      "Model# 17. 4356 nodes still misclassified out of torch.Size([12429]) \n",
      "\n",
      "Model# 18. 4356 nodes still misclassified out of torch.Size([12429]) \n",
      "\n",
      "Model# 19. 4356 nodes still misclassified out of torch.Size([12429]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12360/12360 [00:00<00:00, 2615488.49it/s]\n",
      "100%|██████████| 12360/12360 [00:00<00:00, 2971887.04it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1948784.54it/s]\n",
      "Inferring Phrases: 100%|██████████| 12360/12360 [00:00<00:00, 362090.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4256 nodes still misclassified out of torch.Size([12360]) \n",
      "\n",
      "Model# 1. 4256 nodes still misclassified out of torch.Size([12360]) \n",
      "\n",
      "Model# 2. 4256 nodes still misclassified out of torch.Size([12360]) \n",
      "\n",
      "Model# 3. 4256 nodes still misclassified out of torch.Size([12360]) \n",
      "\n",
      "Model# 4. 4256 nodes still misclassified out of torch.Size([12360]) \n",
      "\n",
      "Model# 5. 4256 nodes still misclassified out of torch.Size([12360]) \n",
      "\n",
      "Model# 6. 4256 nodes still misclassified out of torch.Size([12360]) \n",
      "\n",
      "Model# 7. 4256 nodes still misclassified out of torch.Size([12360]) \n",
      "\n",
      "Model# 8. 4256 nodes still misclassified out of torch.Size([12360]) \n",
      "\n",
      "Model# 9. 4256 nodes still misclassified out of torch.Size([12360]) \n",
      "\n",
      "Model# 10. 4256 nodes still misclassified out of torch.Size([12360]) \n",
      "\n",
      "Model# 11. 4256 nodes still misclassified out of torch.Size([12360]) \n",
      "\n",
      "Model# 12. 4256 nodes still misclassified out of torch.Size([12360]) \n",
      "\n",
      "Model# 13. 4256 nodes still misclassified out of torch.Size([12360]) \n",
      "\n",
      "Model# 14. 4256 nodes still misclassified out of torch.Size([12360]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 278/299 [02:43<00:12,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4256 nodes still misclassified out of torch.Size([12360]) \n",
      "\n",
      "Model# 16. 4256 nodes still misclassified out of torch.Size([12360]) \n",
      "\n",
      "Model# 17. 4256 nodes still misclassified out of torch.Size([12360]) \n",
      "\n",
      "Model# 18. 4256 nodes still misclassified out of torch.Size([12360]) \n",
      "\n",
      "Model# 19. 4256 nodes still misclassified out of torch.Size([12360]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12736/12736 [00:00<00:00, 4089936.13it/s]\n",
      "100%|██████████| 12736/12736 [00:00<00:00, 4799519.83it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2655407.08it/s]\n",
      "Inferring Phrases: 100%|██████████| 12736/12736 [00:00<00:00, 412489.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4504 nodes still misclassified out of torch.Size([12736]) \n",
      "\n",
      "Model# 1. 4504 nodes still misclassified out of torch.Size([12736]) \n",
      "\n",
      "Model# 2. 4504 nodes still misclassified out of torch.Size([12736]) \n",
      "\n",
      "Model# 3. 4504 nodes still misclassified out of torch.Size([12736]) \n",
      "\n",
      "Model# 4. 4504 nodes still misclassified out of torch.Size([12736]) \n",
      "\n",
      "Model# 5. 4504 nodes still misclassified out of torch.Size([12736]) \n",
      "\n",
      "Model# 6. 4504 nodes still misclassified out of torch.Size([12736]) \n",
      "\n",
      "Model# 7. 4504 nodes still misclassified out of torch.Size([12736]) \n",
      "\n",
      "Model# 8. 4504 nodes still misclassified out of torch.Size([12736]) \n",
      "\n",
      "Model# 9. 4504 nodes still misclassified out of torch.Size([12736]) \n",
      "\n",
      "Model# 10. 4504 nodes still misclassified out of torch.Size([12736]) \n",
      "\n",
      "Model# 11. 4504 nodes still misclassified out of torch.Size([12736]) \n",
      "\n",
      "Model# 12. 4504 nodes still misclassified out of torch.Size([12736]) \n",
      "\n",
      "Model# 13. 4504 nodes still misclassified out of torch.Size([12736]) \n",
      "\n",
      "Model# 14. 4504 nodes still misclassified out of torch.Size([12736]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 279/299 [02:44<00:12,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4504 nodes still misclassified out of torch.Size([12736]) \n",
      "\n",
      "Model# 16. 4504 nodes still misclassified out of torch.Size([12736]) \n",
      "\n",
      "Model# 17. 4504 nodes still misclassified out of torch.Size([12736]) \n",
      "\n",
      "Model# 18. 4504 nodes still misclassified out of torch.Size([12736]) \n",
      "\n",
      "Model# 19. 4504 nodes still misclassified out of torch.Size([12736]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12670/12670 [00:00<00:00, 2539148.15it/s]\n",
      "100%|██████████| 12670/12670 [00:00<00:00, 2916675.72it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1883274.76it/s]\n",
      "Inferring Phrases: 100%|██████████| 12670/12670 [00:00<00:00, 376724.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4643 nodes still misclassified out of torch.Size([12670]) \n",
      "\n",
      "Model# 1. 4643 nodes still misclassified out of torch.Size([12670]) \n",
      "\n",
      "Model# 2. 4643 nodes still misclassified out of torch.Size([12670]) \n",
      "\n",
      "Model# 3. 4643 nodes still misclassified out of torch.Size([12670]) \n",
      "\n",
      "Model# 4. 4643 nodes still misclassified out of torch.Size([12670]) \n",
      "\n",
      "Model# 5. 4643 nodes still misclassified out of torch.Size([12670]) \n",
      "\n",
      "Model# 6. 4643 nodes still misclassified out of torch.Size([12670]) \n",
      "\n",
      "Model# 7. 4643 nodes still misclassified out of torch.Size([12670]) \n",
      "\n",
      "Model# 8. 4643 nodes still misclassified out of torch.Size([12670]) \n",
      "\n",
      "Model# 9. 4643 nodes still misclassified out of torch.Size([12670]) \n",
      "\n",
      "Model# 10. 4643 nodes still misclassified out of torch.Size([12670]) \n",
      "\n",
      "Model# 11. 4643 nodes still misclassified out of torch.Size([12670]) \n",
      "\n",
      "Model# 12. 4643 nodes still misclassified out of torch.Size([12670]) \n",
      "\n",
      "Model# 13. 4643 nodes still misclassified out of torch.Size([12670]) \n",
      "\n",
      "Model# 14. 4643 nodes still misclassified out of torch.Size([12670]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 280/299 [02:44<00:11,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4643 nodes still misclassified out of torch.Size([12670]) \n",
      "\n",
      "Model# 16. 4643 nodes still misclassified out of torch.Size([12670]) \n",
      "\n",
      "Model# 17. 4643 nodes still misclassified out of torch.Size([12670]) \n",
      "\n",
      "Model# 18. 4643 nodes still misclassified out of torch.Size([12670]) \n",
      "\n",
      "Model# 19. 4643 nodes still misclassified out of torch.Size([12670]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12322/12322 [00:00<00:00, 2618411.89it/s]\n",
      "100%|██████████| 12322/12322 [00:00<00:00, 2959526.65it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1939861.56it/s]\n",
      "Inferring Phrases: 100%|██████████| 12322/12322 [00:00<00:00, 367121.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4236 nodes still misclassified out of torch.Size([12322]) \n",
      "\n",
      "Model# 1. 4236 nodes still misclassified out of torch.Size([12322]) \n",
      "\n",
      "Model# 2. 4236 nodes still misclassified out of torch.Size([12322]) \n",
      "\n",
      "Model# 3. 4236 nodes still misclassified out of torch.Size([12322]) \n",
      "\n",
      "Model# 4. 4236 nodes still misclassified out of torch.Size([12322]) \n",
      "\n",
      "Model# 5. 4236 nodes still misclassified out of torch.Size([12322]) \n",
      "\n",
      "Model# 6. 4236 nodes still misclassified out of torch.Size([12322]) \n",
      "\n",
      "Model# 7. 4236 nodes still misclassified out of torch.Size([12322]) \n",
      "\n",
      "Model# 8. 4236 nodes still misclassified out of torch.Size([12322]) \n",
      "\n",
      "Model# 9. 4236 nodes still misclassified out of torch.Size([12322]) \n",
      "\n",
      "Model# 10. 4236 nodes still misclassified out of torch.Size([12322]) \n",
      "\n",
      "Model# 11. 4236 nodes still misclassified out of torch.Size([12322]) \n",
      "\n",
      "Model# 12. 4236 nodes still misclassified out of torch.Size([12322]) \n",
      "\n",
      "Model# 13. 4236 nodes still misclassified out of torch.Size([12322]) \n",
      "\n",
      "Model# 14. 4236 nodes still misclassified out of torch.Size([12322]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 281/299 [02:45<00:10,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4236 nodes still misclassified out of torch.Size([12322]) \n",
      "\n",
      "Model# 16. 4236 nodes still misclassified out of torch.Size([12322]) \n",
      "\n",
      "Model# 17. 4236 nodes still misclassified out of torch.Size([12322]) \n",
      "\n",
      "Model# 18. 4236 nodes still misclassified out of torch.Size([12322]) \n",
      "\n",
      "Model# 19. 4236 nodes still misclassified out of torch.Size([12322]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13004/13004 [00:00<00:00, 4104351.66it/s]\n",
      "100%|██████████| 13004/13004 [00:00<00:00, 4845227.79it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2754819.16it/s]\n",
      "Inferring Phrases: 100%|██████████| 13004/13004 [00:00<00:00, 426364.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4436 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 1. 4436 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 2. 4436 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 3. 4436 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 4. 4436 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 5. 4436 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 6. 4436 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 7. 4436 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 8. 4436 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 9. 4436 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 10. 4436 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 11. 4436 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 12. 4436 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 13. 4436 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 14. 4436 nodes still misclassified out of torch.Size([13004]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 282/299 [02:45<00:10,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4436 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 16. 4436 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 17. 4436 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 18. 4436 nodes still misclassified out of torch.Size([13004]) \n",
      "\n",
      "Model# 19. 4436 nodes still misclassified out of torch.Size([13004]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14023/14023 [00:00<00:00, 2511925.05it/s]\n",
      "100%|██████████| 14023/14023 [00:00<00:00, 2991695.07it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1919238.58it/s]\n",
      "Inferring Phrases: 100%|██████████| 14023/14023 [00:00<00:00, 412416.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5294 nodes still misclassified out of torch.Size([14023]) \n",
      "\n",
      "Model# 1. 5294 nodes still misclassified out of torch.Size([14023]) \n",
      "\n",
      "Model# 2. 5294 nodes still misclassified out of torch.Size([14023]) \n",
      "\n",
      "Model# 3. 5294 nodes still misclassified out of torch.Size([14023]) \n",
      "\n",
      "Model# 4. 5294 nodes still misclassified out of torch.Size([14023]) \n",
      "\n",
      "Model# 5. 5294 nodes still misclassified out of torch.Size([14023]) \n",
      "\n",
      "Model# 6. 5294 nodes still misclassified out of torch.Size([14023]) \n",
      "\n",
      "Model# 7. 5294 nodes still misclassified out of torch.Size([14023]) \n",
      "\n",
      "Model# 8. 5294 nodes still misclassified out of torch.Size([14023]) \n",
      "\n",
      "Model# 9. 5294 nodes still misclassified out of torch.Size([14023]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 283/299 [02:46<00:09,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 5294 nodes still misclassified out of torch.Size([14023]) \n",
      "\n",
      "Model# 11. 5294 nodes still misclassified out of torch.Size([14023]) \n",
      "\n",
      "Model# 12. 5294 nodes still misclassified out of torch.Size([14023]) \n",
      "\n",
      "Model# 13. 5294 nodes still misclassified out of torch.Size([14023]) \n",
      "\n",
      "Model# 14. 5294 nodes still misclassified out of torch.Size([14023]) \n",
      "\n",
      "Model# 15. 5294 nodes still misclassified out of torch.Size([14023]) \n",
      "\n",
      "Model# 16. 5294 nodes still misclassified out of torch.Size([14023]) \n",
      "\n",
      "Model# 17. 5294 nodes still misclassified out of torch.Size([14023]) \n",
      "\n",
      "Model# 18. 5294 nodes still misclassified out of torch.Size([14023]) \n",
      "\n",
      "Model# 19. 5294 nodes still misclassified out of torch.Size([14023]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14900/14900 [00:00<00:00, 2456183.37it/s]\n",
      "100%|██████████| 14900/14900 [00:00<00:00, 2825277.11it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1857311.21it/s]\n",
      "Inferring Phrases: 100%|██████████| 14900/14900 [00:00<00:00, 457109.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6410 nodes still misclassified out of torch.Size([14900]) \n",
      "\n",
      "Model# 1. 6410 nodes still misclassified out of torch.Size([14900]) \n",
      "\n",
      "Model# 2. 6410 nodes still misclassified out of torch.Size([14900]) \n",
      "\n",
      "Model# 3. 6410 nodes still misclassified out of torch.Size([14900]) \n",
      "\n",
      "Model# 4. 6410 nodes still misclassified out of torch.Size([14900]) \n",
      "\n",
      "Model# 5. 6410 nodes still misclassified out of torch.Size([14900]) \n",
      "\n",
      "Model# 6. 6410 nodes still misclassified out of torch.Size([14900]) \n",
      "\n",
      "Model# 7. 6410 nodes still misclassified out of torch.Size([14900]) \n",
      "\n",
      "Model# 8. 6410 nodes still misclassified out of torch.Size([14900]) \n",
      "\n",
      "Model# 9. 6410 nodes still misclassified out of torch.Size([14900]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 284/299 [02:47<00:09,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 6410 nodes still misclassified out of torch.Size([14900]) \n",
      "\n",
      "Model# 11. 6410 nodes still misclassified out of torch.Size([14900]) \n",
      "\n",
      "Model# 12. 6410 nodes still misclassified out of torch.Size([14900]) \n",
      "\n",
      "Model# 13. 6410 nodes still misclassified out of torch.Size([14900]) \n",
      "\n",
      "Model# 14. 6410 nodes still misclassified out of torch.Size([14900]) \n",
      "\n",
      "Model# 15. 6410 nodes still misclassified out of torch.Size([14900]) \n",
      "\n",
      "Model# 16. 6410 nodes still misclassified out of torch.Size([14900]) \n",
      "\n",
      "Model# 17. 6410 nodes still misclassified out of torch.Size([14900]) \n",
      "\n",
      "Model# 18. 6410 nodes still misclassified out of torch.Size([14900]) \n",
      "\n",
      "Model# 19. 6410 nodes still misclassified out of torch.Size([14900]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14706/14706 [00:00<00:00, 4176695.19it/s]\n",
      "100%|██████████| 14706/14706 [00:00<00:00, 4813597.21it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2385747.98it/s]\n",
      "Inferring Phrases: 100%|██████████| 14706/14706 [00:00<00:00, 438430.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6130 nodes still misclassified out of torch.Size([14706]) \n",
      "\n",
      "Model# 1. 6130 nodes still misclassified out of torch.Size([14706]) \n",
      "\n",
      "Model# 2. 6130 nodes still misclassified out of torch.Size([14706]) \n",
      "\n",
      "Model# 3. 6130 nodes still misclassified out of torch.Size([14706]) \n",
      "\n",
      "Model# 4. 6130 nodes still misclassified out of torch.Size([14706]) \n",
      "\n",
      "Model# 5. 6130 nodes still misclassified out of torch.Size([14706]) \n",
      "\n",
      "Model# 6. 6130 nodes still misclassified out of torch.Size([14706]) \n",
      "\n",
      "Model# 7. 6130 nodes still misclassified out of torch.Size([14706]) \n",
      "\n",
      "Model# 8. 6130 nodes still misclassified out of torch.Size([14706]) \n",
      "\n",
      "Model# 9. 6130 nodes still misclassified out of torch.Size([14706]) \n",
      "\n",
      "Model# 10. 6130 nodes still misclassified out of torch.Size([14706]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 285/299 [02:47<00:09,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 11. 6130 nodes still misclassified out of torch.Size([14706]) \n",
      "\n",
      "Model# 12. 6130 nodes still misclassified out of torch.Size([14706]) \n",
      "\n",
      "Model# 13. 6130 nodes still misclassified out of torch.Size([14706]) \n",
      "\n",
      "Model# 14. 6130 nodes still misclassified out of torch.Size([14706]) \n",
      "\n",
      "Model# 15. 6130 nodes still misclassified out of torch.Size([14706]) \n",
      "\n",
      "Model# 16. 6130 nodes still misclassified out of torch.Size([14706]) \n",
      "\n",
      "Model# 17. 6130 nodes still misclassified out of torch.Size([14706]) \n",
      "\n",
      "Model# 18. 6130 nodes still misclassified out of torch.Size([14706]) \n",
      "\n",
      "Model# 19. 6130 nodes still misclassified out of torch.Size([14706]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14751/14751 [00:00<00:00, 2568293.00it/s]\n",
      "100%|██████████| 14751/14751 [00:00<00:00, 2963982.86it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1873628.16it/s]\n",
      "Inferring Phrases: 100%|██████████| 14751/14751 [00:00<00:00, 443749.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 6337 nodes still misclassified out of torch.Size([14751]) \n",
      "\n",
      "Model# 1. 6337 nodes still misclassified out of torch.Size([14751]) \n",
      "\n",
      "Model# 2. 6337 nodes still misclassified out of torch.Size([14751]) \n",
      "\n",
      "Model# 3. 6337 nodes still misclassified out of torch.Size([14751]) \n",
      "\n",
      "Model# 4. 6337 nodes still misclassified out of torch.Size([14751]) \n",
      "\n",
      "Model# 5. 6337 nodes still misclassified out of torch.Size([14751]) \n",
      "\n",
      "Model# 6. 6337 nodes still misclassified out of torch.Size([14751]) \n",
      "\n",
      "Model# 7. 6337 nodes still misclassified out of torch.Size([14751]) \n",
      "\n",
      "Model# 8. 6337 nodes still misclassified out of torch.Size([14751]) \n",
      "\n",
      "Model# 9. 6337 nodes still misclassified out of torch.Size([14751]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 286/299 [02:48<00:08,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 6337 nodes still misclassified out of torch.Size([14751]) \n",
      "\n",
      "Model# 11. 6337 nodes still misclassified out of torch.Size([14751]) \n",
      "\n",
      "Model# 12. 6337 nodes still misclassified out of torch.Size([14751]) \n",
      "\n",
      "Model# 13. 6337 nodes still misclassified out of torch.Size([14751]) \n",
      "\n",
      "Model# 14. 6337 nodes still misclassified out of torch.Size([14751]) \n",
      "\n",
      "Model# 15. 6337 nodes still misclassified out of torch.Size([14751]) \n",
      "\n",
      "Model# 16. 6337 nodes still misclassified out of torch.Size([14751]) \n",
      "\n",
      "Model# 17. 6337 nodes still misclassified out of torch.Size([14751]) \n",
      "\n",
      "Model# 18. 6337 nodes still misclassified out of torch.Size([14751]) \n",
      "\n",
      "Model# 19. 6337 nodes still misclassified out of torch.Size([14751]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13940/13940 [00:00<00:00, 4320126.92it/s]\n",
      "100%|██████████| 13940/13940 [00:00<00:00, 5129274.30it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2658268.09it/s]\n",
      "Inferring Phrases: 100%|██████████| 13940/13940 [00:00<00:00, 433196.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5784 nodes still misclassified out of torch.Size([13940]) \n",
      "\n",
      "Model# 1. 5784 nodes still misclassified out of torch.Size([13940]) \n",
      "\n",
      "Model# 2. 5784 nodes still misclassified out of torch.Size([13940]) \n",
      "\n",
      "Model# 3. 5784 nodes still misclassified out of torch.Size([13940]) \n",
      "\n",
      "Model# 4. 5784 nodes still misclassified out of torch.Size([13940]) \n",
      "\n",
      "Model# 5. 5784 nodes still misclassified out of torch.Size([13940]) \n",
      "\n",
      "Model# 6. 5784 nodes still misclassified out of torch.Size([13940]) \n",
      "\n",
      "Model# 7. 5784 nodes still misclassified out of torch.Size([13940]) \n",
      "\n",
      "Model# 8. 5784 nodes still misclassified out of torch.Size([13940]) \n",
      "\n",
      "Model# 9. 5784 nodes still misclassified out of torch.Size([13940]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 287/299 [02:49<00:08,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 5784 nodes still misclassified out of torch.Size([13940]) \n",
      "\n",
      "Model# 11. 5784 nodes still misclassified out of torch.Size([13940]) \n",
      "\n",
      "Model# 12. 5784 nodes still misclassified out of torch.Size([13940]) \n",
      "\n",
      "Model# 13. 5784 nodes still misclassified out of torch.Size([13940]) \n",
      "\n",
      "Model# 14. 5784 nodes still misclassified out of torch.Size([13940]) \n",
      "\n",
      "Model# 15. 5784 nodes still misclassified out of torch.Size([13940]) \n",
      "\n",
      "Model# 16. 5784 nodes still misclassified out of torch.Size([13940]) \n",
      "\n",
      "Model# 17. 5784 nodes still misclassified out of torch.Size([13940]) \n",
      "\n",
      "Model# 18. 5784 nodes still misclassified out of torch.Size([13940]) \n",
      "\n",
      "Model# 19. 5784 nodes still misclassified out of torch.Size([13940]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13207/13207 [00:00<00:00, 2421920.82it/s]\n",
      "100%|██████████| 13207/13207 [00:00<00:00, 2942741.87it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1866319.40it/s]\n",
      "Inferring Phrases: 100%|██████████| 13207/13207 [00:00<00:00, 376931.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4978 nodes still misclassified out of torch.Size([13207]) \n",
      "\n",
      "Model# 1. 4978 nodes still misclassified out of torch.Size([13207]) \n",
      "\n",
      "Model# 2. 4978 nodes still misclassified out of torch.Size([13207]) \n",
      "\n",
      "Model# 3. 4978 nodes still misclassified out of torch.Size([13207]) \n",
      "\n",
      "Model# 4. 4978 nodes still misclassified out of torch.Size([13207]) \n",
      "\n",
      "Model# 5. 4978 nodes still misclassified out of torch.Size([13207]) \n",
      "\n",
      "Model# 6. 4978 nodes still misclassified out of torch.Size([13207]) \n",
      "\n",
      "Model# 7. 4978 nodes still misclassified out of torch.Size([13207]) \n",
      "\n",
      "Model# 8. 4978 nodes still misclassified out of torch.Size([13207]) \n",
      "\n",
      "Model# 9. 4978 nodes still misclassified out of torch.Size([13207]) \n",
      "\n",
      "Model# 10. 4978 nodes still misclassified out of torch.Size([13207]) \n",
      "\n",
      "Model# 11. 4978 nodes still misclassified out of torch.Size([13207]) \n",
      "\n",
      "Model# 12. 4978 nodes still misclassified out of torch.Size([13207]) \n",
      "\n",
      "Model# 13. 4978 nodes still misclassified out of torch.Size([13207]) \n",
      "\n",
      "Model# 14. 4978 nodes still misclassified out of torch.Size([13207]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 288/299 [02:49<00:07,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4978 nodes still misclassified out of torch.Size([13207]) \n",
      "\n",
      "Model# 16. 4978 nodes still misclassified out of torch.Size([13207]) \n",
      "\n",
      "Model# 17. 4978 nodes still misclassified out of torch.Size([13207]) \n",
      "\n",
      "Model# 18. 4978 nodes still misclassified out of torch.Size([13207]) \n",
      "\n",
      "Model# 19. 4978 nodes still misclassified out of torch.Size([13207]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13684/13684 [00:00<00:00, 2595760.30it/s]\n",
      "100%|██████████| 13684/13684 [00:00<00:00, 2874917.65it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1928711.22it/s]\n",
      "Inferring Phrases: 100%|██████████| 13684/13684 [00:00<00:00, 395259.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5085 nodes still misclassified out of torch.Size([13684]) \n",
      "\n",
      "Model# 1. 5085 nodes still misclassified out of torch.Size([13684]) \n",
      "\n",
      "Model# 2. 5085 nodes still misclassified out of torch.Size([13684]) \n",
      "\n",
      "Model# 3. 5085 nodes still misclassified out of torch.Size([13684]) \n",
      "\n",
      "Model# 4. 5085 nodes still misclassified out of torch.Size([13684]) \n",
      "\n",
      "Model# 5. 5085 nodes still misclassified out of torch.Size([13684]) \n",
      "\n",
      "Model# 6. 5085 nodes still misclassified out of torch.Size([13684]) \n",
      "\n",
      "Model# 7. 5085 nodes still misclassified out of torch.Size([13684]) \n",
      "\n",
      "Model# 8. 5085 nodes still misclassified out of torch.Size([13684]) \n",
      "\n",
      "Model# 9. 5085 nodes still misclassified out of torch.Size([13684]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 289/299 [02:50<00:06,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 5085 nodes still misclassified out of torch.Size([13684]) \n",
      "\n",
      "Model# 11. 5085 nodes still misclassified out of torch.Size([13684]) \n",
      "\n",
      "Model# 12. 5085 nodes still misclassified out of torch.Size([13684]) \n",
      "\n",
      "Model# 13. 5085 nodes still misclassified out of torch.Size([13684]) \n",
      "\n",
      "Model# 14. 5085 nodes still misclassified out of torch.Size([13684]) \n",
      "\n",
      "Model# 15. 5085 nodes still misclassified out of torch.Size([13684]) \n",
      "\n",
      "Model# 16. 5085 nodes still misclassified out of torch.Size([13684]) \n",
      "\n",
      "Model# 17. 5085 nodes still misclassified out of torch.Size([13684]) \n",
      "\n",
      "Model# 18. 5085 nodes still misclassified out of torch.Size([13684]) \n",
      "\n",
      "Model# 19. 5085 nodes still misclassified out of torch.Size([13684]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13546/13546 [00:00<00:00, 4161128.02it/s]\n",
      "100%|██████████| 13546/13546 [00:00<00:00, 5176388.66it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2830228.30it/s]\n",
      "Inferring Phrases: 100%|██████████| 13546/13546 [00:00<00:00, 435866.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4864 nodes still misclassified out of torch.Size([13546]) \n",
      "\n",
      "Model# 1. 4864 nodes still misclassified out of torch.Size([13546]) \n",
      "\n",
      "Model# 2. 4864 nodes still misclassified out of torch.Size([13546]) \n",
      "\n",
      "Model# 3. 4864 nodes still misclassified out of torch.Size([13546]) \n",
      "\n",
      "Model# 4. 4864 nodes still misclassified out of torch.Size([13546]) \n",
      "\n",
      "Model# 5. 4864 nodes still misclassified out of torch.Size([13546]) \n",
      "\n",
      "Model# 6. 4864 nodes still misclassified out of torch.Size([13546]) \n",
      "\n",
      "Model# 7. 4864 nodes still misclassified out of torch.Size([13546]) \n",
      "\n",
      "Model# 8. 4864 nodes still misclassified out of torch.Size([13546]) \n",
      "\n",
      "Model# 9. 4864 nodes still misclassified out of torch.Size([13546]) \n",
      "\n",
      "Model# 10. 4864 nodes still misclassified out of torch.Size([13546]) \n",
      "\n",
      "Model# 11. 4864 nodes still misclassified out of torch.Size([13546]) \n",
      "\n",
      "Model# 12. 4864 nodes still misclassified out of torch.Size([13546]) \n",
      "\n",
      "Model# 13. 4864 nodes still misclassified out of torch.Size([13546]) \n",
      "\n",
      "Model# 14. 4864 nodes still misclassified out of torch.Size([13546]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 290/299 [02:51<00:05,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4864 nodes still misclassified out of torch.Size([13546]) \n",
      "\n",
      "Model# 16. 4864 nodes still misclassified out of torch.Size([13546]) \n",
      "\n",
      "Model# 17. 4864 nodes still misclassified out of torch.Size([13546]) \n",
      "\n",
      "Model# 18. 4864 nodes still misclassified out of torch.Size([13546]) \n",
      "\n",
      "Model# 19. 4864 nodes still misclassified out of torch.Size([13546]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13348/13348 [00:00<00:00, 2550711.64it/s]\n",
      "100%|██████████| 13348/13348 [00:00<00:00, 2962669.72it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1927411.31it/s]\n",
      "Inferring Phrases: 100%|██████████| 13348/13348 [00:00<00:00, 387760.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4621 nodes still misclassified out of torch.Size([13348]) \n",
      "\n",
      "Model# 1. 4621 nodes still misclassified out of torch.Size([13348]) \n",
      "\n",
      "Model# 2. 4621 nodes still misclassified out of torch.Size([13348]) \n",
      "\n",
      "Model# 3. 4621 nodes still misclassified out of torch.Size([13348]) \n",
      "\n",
      "Model# 4. 4621 nodes still misclassified out of torch.Size([13348]) \n",
      "\n",
      "Model# 5. 4621 nodes still misclassified out of torch.Size([13348]) \n",
      "\n",
      "Model# 6. 4621 nodes still misclassified out of torch.Size([13348]) \n",
      "\n",
      "Model# 7. 4621 nodes still misclassified out of torch.Size([13348]) \n",
      "\n",
      "Model# 8. 4621 nodes still misclassified out of torch.Size([13348]) \n",
      "\n",
      "Model# 9. 4621 nodes still misclassified out of torch.Size([13348]) \n",
      "\n",
      "Model# 10. 4621 nodes still misclassified out of torch.Size([13348]) \n",
      "\n",
      "Model# 11. 4621 nodes still misclassified out of torch.Size([13348]) \n",
      "\n",
      "Model# 12. 4621 nodes still misclassified out of torch.Size([13348]) \n",
      "\n",
      "Model# 13. 4621 nodes still misclassified out of torch.Size([13348]) \n",
      "\n",
      "Model# 14. 4621 nodes still misclassified out of torch.Size([13348]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 291/299 [02:51<00:04,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4621 nodes still misclassified out of torch.Size([13348]) \n",
      "\n",
      "Model# 16. 4621 nodes still misclassified out of torch.Size([13348]) \n",
      "\n",
      "Model# 17. 4621 nodes still misclassified out of torch.Size([13348]) \n",
      "\n",
      "Model# 18. 4621 nodes still misclassified out of torch.Size([13348]) \n",
      "\n",
      "Model# 19. 4621 nodes still misclassified out of torch.Size([13348]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13404/13404 [00:00<00:00, 4016607.19it/s]\n",
      "100%|██████████| 13404/13404 [00:00<00:00, 4894267.50it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2746641.05it/s]\n",
      "Inferring Phrases: 100%|██████████| 13404/13404 [00:00<00:00, 428499.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4045 nodes still misclassified out of torch.Size([13404]) \n",
      "\n",
      "Model# 1. 4045 nodes still misclassified out of torch.Size([13404]) \n",
      "\n",
      "Model# 2. 4045 nodes still misclassified out of torch.Size([13404]) \n",
      "\n",
      "Model# 3. 4045 nodes still misclassified out of torch.Size([13404]) \n",
      "\n",
      "Model# 4. 4045 nodes still misclassified out of torch.Size([13404]) \n",
      "\n",
      "Model# 5. 4045 nodes still misclassified out of torch.Size([13404]) \n",
      "\n",
      "Model# 6. 4045 nodes still misclassified out of torch.Size([13404]) \n",
      "\n",
      "Model# 7. 4045 nodes still misclassified out of torch.Size([13404]) \n",
      "\n",
      "Model# 8. 4045 nodes still misclassified out of torch.Size([13404]) \n",
      "\n",
      "Model# 9. 4045 nodes still misclassified out of torch.Size([13404]) \n",
      "\n",
      "Model# 10. 4045 nodes still misclassified out of torch.Size([13404]) \n",
      "\n",
      "Model# 11. 4045 nodes still misclassified out of torch.Size([13404]) \n",
      "\n",
      "Model# 12. 4045 nodes still misclassified out of torch.Size([13404]) \n",
      "\n",
      "Model# 13. 4045 nodes still misclassified out of torch.Size([13404]) \n",
      "\n",
      "Model# 14. 4045 nodes still misclassified out of torch.Size([13404]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 292/299 [02:52<00:04,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 15. 4045 nodes still misclassified out of torch.Size([13404]) \n",
      "\n",
      "Model# 16. 4045 nodes still misclassified out of torch.Size([13404]) \n",
      "\n",
      "Model# 17. 4045 nodes still misclassified out of torch.Size([13404]) \n",
      "\n",
      "Model# 18. 4045 nodes still misclassified out of torch.Size([13404]) \n",
      "\n",
      "Model# 19. 4045 nodes still misclassified out of torch.Size([13404]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13256/13256 [00:00<00:00, 2420429.84it/s]\n",
      "100%|██████████| 13256/13256 [00:00<00:00, 2932009.38it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1885052.21it/s]\n",
      "Inferring Phrases: 100%|██████████| 13256/13256 [00:00<00:00, 400542.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5264 nodes still misclassified out of torch.Size([13256]) \n",
      "\n",
      "Model# 1. 5264 nodes still misclassified out of torch.Size([13256]) \n",
      "\n",
      "Model# 2. 5264 nodes still misclassified out of torch.Size([13256]) \n",
      "\n",
      "Model# 3. 5264 nodes still misclassified out of torch.Size([13256]) \n",
      "\n",
      "Model# 4. 5264 nodes still misclassified out of torch.Size([13256]) \n",
      "\n",
      "Model# 5. 5264 nodes still misclassified out of torch.Size([13256]) \n",
      "\n",
      "Model# 6. 5264 nodes still misclassified out of torch.Size([13256]) \n",
      "\n",
      "Model# 7. 5264 nodes still misclassified out of torch.Size([13256]) \n",
      "\n",
      "Model# 8. 5264 nodes still misclassified out of torch.Size([13256]) \n",
      "\n",
      "Model# 9. 5264 nodes still misclassified out of torch.Size([13256]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 293/299 [02:53<00:03,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 5264 nodes still misclassified out of torch.Size([13256]) \n",
      "\n",
      "Model# 11. 5264 nodes still misclassified out of torch.Size([13256]) \n",
      "\n",
      "Model# 12. 5264 nodes still misclassified out of torch.Size([13256]) \n",
      "\n",
      "Model# 13. 5264 nodes still misclassified out of torch.Size([13256]) \n",
      "\n",
      "Model# 14. 5264 nodes still misclassified out of torch.Size([13256]) \n",
      "\n",
      "Model# 15. 5264 nodes still misclassified out of torch.Size([13256]) \n",
      "\n",
      "Model# 16. 5264 nodes still misclassified out of torch.Size([13256]) \n",
      "\n",
      "Model# 17. 5264 nodes still misclassified out of torch.Size([13256]) \n",
      "\n",
      "Model# 18. 5264 nodes still misclassified out of torch.Size([13256]) \n",
      "\n",
      "Model# 19. 5264 nodes still misclassified out of torch.Size([13256]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13569/13569 [00:00<00:00, 2357797.29it/s]\n",
      "100%|██████████| 13569/13569 [00:00<00:00, 2888813.31it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1893647.97it/s]\n",
      "Inferring Phrases: 100%|██████████| 13569/13569 [00:00<00:00, 423941.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5403 nodes still misclassified out of torch.Size([13569]) \n",
      "\n",
      "Model# 1. 5403 nodes still misclassified out of torch.Size([13569]) \n",
      "\n",
      "Model# 2. 5403 nodes still misclassified out of torch.Size([13569]) \n",
      "\n",
      "Model# 3. 5403 nodes still misclassified out of torch.Size([13569]) \n",
      "\n",
      "Model# 4. 5403 nodes still misclassified out of torch.Size([13569]) \n",
      "\n",
      "Model# 5. 5403 nodes still misclassified out of torch.Size([13569]) \n",
      "\n",
      "Model# 6. 5403 nodes still misclassified out of torch.Size([13569]) \n",
      "\n",
      "Model# 7. 5403 nodes still misclassified out of torch.Size([13569]) \n",
      "\n",
      "Model# 8. 5403 nodes still misclassified out of torch.Size([13569]) \n",
      "\n",
      "Model# 9. 5403 nodes still misclassified out of torch.Size([13569]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 294/299 [02:53<00:03,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 5403 nodes still misclassified out of torch.Size([13569]) \n",
      "\n",
      "Model# 11. 5403 nodes still misclassified out of torch.Size([13569]) \n",
      "\n",
      "Model# 12. 5403 nodes still misclassified out of torch.Size([13569]) \n",
      "\n",
      "Model# 13. 5403 nodes still misclassified out of torch.Size([13569]) \n",
      "\n",
      "Model# 14. 5403 nodes still misclassified out of torch.Size([13569]) \n",
      "\n",
      "Model# 15. 5403 nodes still misclassified out of torch.Size([13569]) \n",
      "\n",
      "Model# 16. 5403 nodes still misclassified out of torch.Size([13569]) \n",
      "\n",
      "Model# 17. 5403 nodes still misclassified out of torch.Size([13569]) \n",
      "\n",
      "Model# 18. 5403 nodes still misclassified out of torch.Size([13569]) \n",
      "\n",
      "Model# 19. 5403 nodes still misclassified out of torch.Size([13569]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13326/13326 [00:00<00:00, 4205349.12it/s]\n",
      "100%|██████████| 13326/13326 [00:00<00:00, 4965203.44it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2638701.51it/s]\n",
      "Inferring Phrases: 100%|██████████| 13326/13326 [00:00<00:00, 426539.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4981 nodes still misclassified out of torch.Size([13326]) \n",
      "\n",
      "Model# 1. 4981 nodes still misclassified out of torch.Size([13326]) \n",
      "\n",
      "Model# 2. 4981 nodes still misclassified out of torch.Size([13326]) \n",
      "\n",
      "Model# 3. 4981 nodes still misclassified out of torch.Size([13326]) \n",
      "\n",
      "Model# 4. 4981 nodes still misclassified out of torch.Size([13326]) \n",
      "\n",
      "Model# 5. 4981 nodes still misclassified out of torch.Size([13326]) \n",
      "\n",
      "Model# 6. 4981 nodes still misclassified out of torch.Size([13326]) \n",
      "\n",
      "Model# 7. 4981 nodes still misclassified out of torch.Size([13326]) \n",
      "\n",
      "Model# 8. 4981 nodes still misclassified out of torch.Size([13326]) \n",
      "\n",
      "Model# 9. 4981 nodes still misclassified out of torch.Size([13326]) \n",
      "\n",
      "Model# 10. 4981 nodes still misclassified out of torch.Size([13326]) \n",
      "\n",
      "Model# 11. 4981 nodes still misclassified out of torch.Size([13326]) \n",
      "\n",
      "Model# 12. 4981 nodes still misclassified out of torch.Size([13326]) \n",
      "\n",
      "Model# 13. 4981 nodes still misclassified out of torch.Size([13326]) \n",
      "\n",
      "Model# 14. 4981 nodes still misclassified out of torch.Size([13326]) \n",
      "\n",
      "Model# 15. 4981 nodes still misclassified out of torch.Size([13326]) \n",
      "\n",
      "Model# 16. 4981 nodes still misclassified out of torch.Size([13326]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 295/299 [02:54<00:02,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 17. 4981 nodes still misclassified out of torch.Size([13326]) \n",
      "\n",
      "Model# 18. 4981 nodes still misclassified out of torch.Size([13326]) \n",
      "\n",
      "Model# 19. 4981 nodes still misclassified out of torch.Size([13326]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13679/13679 [00:00<00:00, 3874781.15it/s]\n",
      "100%|██████████| 13679/13679 [00:00<00:00, 4524040.72it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2594682.34it/s]\n",
      "Inferring Phrases: 100%|██████████| 13679/13679 [00:00<00:00, 386426.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5092 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 1. 5092 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 2. 5092 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 3. 5092 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 4. 5092 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 5. 5092 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 6. 5092 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 7. 5092 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 8. 5092 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 9. 5092 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 10. 5092 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 11. 5092 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 12. 5092 nodes still misclassified out of torch.Size([13679]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 296/299 [02:54<00:01,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 13. 5092 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 14. 5092 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 15. 5092 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 16. 5092 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 17. 5092 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 18. 5092 nodes still misclassified out of torch.Size([13679]) \n",
      "\n",
      "Model# 19. 5092 nodes still misclassified out of torch.Size([13679]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14076/14076 [00:00<00:00, 3798920.48it/s]\n",
      "100%|██████████| 14076/14076 [00:00<00:00, 4587693.15it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2641526.61it/s]\n",
      "Inferring Phrases: 100%|██████████| 14076/14076 [00:00<00:00, 408786.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5587 nodes still misclassified out of torch.Size([14076]) \n",
      "\n",
      "Model# 1. 5587 nodes still misclassified out of torch.Size([14076]) \n",
      "\n",
      "Model# 2. 5587 nodes still misclassified out of torch.Size([14076]) \n",
      "\n",
      "Model# 3. 5587 nodes still misclassified out of torch.Size([14076]) \n",
      "\n",
      "Model# 4. 5587 nodes still misclassified out of torch.Size([14076]) \n",
      "\n",
      "Model# 5. 5587 nodes still misclassified out of torch.Size([14076]) \n",
      "\n",
      "Model# 6. 5587 nodes still misclassified out of torch.Size([14076]) \n",
      "\n",
      "Model# 7. 5587 nodes still misclassified out of torch.Size([14076]) \n",
      "\n",
      "Model# 8. 5587 nodes still misclassified out of torch.Size([14076]) \n",
      "\n",
      "Model# 9. 5587 nodes still misclassified out of torch.Size([14076]) \n",
      "\n",
      "Model# 10. 5587 nodes still misclassified out of torch.Size([14076]) \n",
      "\n",
      "Model# 11. 5587 nodes still misclassified out of torch.Size([14076]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 297/299 [02:55<00:01,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 12. 5587 nodes still misclassified out of torch.Size([14076]) \n",
      "\n",
      "Model# 13. 5587 nodes still misclassified out of torch.Size([14076]) \n",
      "\n",
      "Model# 14. 5587 nodes still misclassified out of torch.Size([14076]) \n",
      "\n",
      "Model# 15. 5587 nodes still misclassified out of torch.Size([14076]) \n",
      "\n",
      "Model# 16. 5587 nodes still misclassified out of torch.Size([14076]) \n",
      "\n",
      "Model# 17. 5587 nodes still misclassified out of torch.Size([14076]) \n",
      "\n",
      "Model# 18. 5587 nodes still misclassified out of torch.Size([14076]) \n",
      "\n",
      "Model# 19. 5587 nodes still misclassified out of torch.Size([14076]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13483/13483 [00:00<00:00, 4210856.35it/s]\n",
      "100%|██████████| 13483/13483 [00:00<00:00, 5128484.70it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2768334.76it/s]\n",
      "Inferring Phrases: 100%|██████████| 13483/13483 [00:00<00:00, 438002.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 4182 nodes still misclassified out of torch.Size([13483]) \n",
      "\n",
      "Model# 1. 4182 nodes still misclassified out of torch.Size([13483]) \n",
      "\n",
      "Model# 2. 4182 nodes still misclassified out of torch.Size([13483]) \n",
      "\n",
      "Model# 3. 4182 nodes still misclassified out of torch.Size([13483]) \n",
      "\n",
      "Model# 4. 4182 nodes still misclassified out of torch.Size([13483]) \n",
      "\n",
      "Model# 5. 4182 nodes still misclassified out of torch.Size([13483]) \n",
      "\n",
      "Model# 6. 4182 nodes still misclassified out of torch.Size([13483]) \n",
      "\n",
      "Model# 7. 4182 nodes still misclassified out of torch.Size([13483]) \n",
      "\n",
      "Model# 8. 4182 nodes still misclassified out of torch.Size([13483]) \n",
      "\n",
      "Model# 9. 4182 nodes still misclassified out of torch.Size([13483]) \n",
      "\n",
      "Model# 10. 4182 nodes still misclassified out of torch.Size([13483]) \n",
      "\n",
      "Model# 11. 4182 nodes still misclassified out of torch.Size([13483]) \n",
      "\n",
      "Model# 12. 4182 nodes still misclassified out of torch.Size([13483]) \n",
      "\n",
      "Model# 13. 4182 nodes still misclassified out of torch.Size([13483]) \n",
      "\n",
      "Model# 14. 4182 nodes still misclassified out of torch.Size([13483]) \n",
      "\n",
      "Model# 15. 4182 nodes still misclassified out of torch.Size([13483]) \n",
      "\n",
      "Model# 16. 4182 nodes still misclassified out of torch.Size([13483]) \n",
      "\n",
      "Model# 17. 4182 nodes still misclassified out of torch.Size([13483]) \n",
      "\n",
      "Model# 18. 4182 nodes still misclassified out of torch.Size([13483]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 298/299 [02:55<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 19. 4182 nodes still misclassified out of torch.Size([13483]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13422/13422 [00:00<00:00, 4011397.20it/s]\n",
      "100%|██████████| 13422/13422 [00:00<00:00, 4526853.35it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2700079.82it/s]\n",
      "Inferring Phrases: 100%|██████████| 13422/13422 [00:00<00:00, 391803.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 0. 5056 nodes still misclassified out of torch.Size([13422]) \n",
      "\n",
      "Model# 1. 5056 nodes still misclassified out of torch.Size([13422]) \n",
      "\n",
      "Model# 2. 5056 nodes still misclassified out of torch.Size([13422]) \n",
      "\n",
      "Model# 3. 5056 nodes still misclassified out of torch.Size([13422]) \n",
      "\n",
      "Model# 4. 5056 nodes still misclassified out of torch.Size([13422]) \n",
      "\n",
      "Model# 5. 5056 nodes still misclassified out of torch.Size([13422]) \n",
      "\n",
      "Model# 6. 5056 nodes still misclassified out of torch.Size([13422]) \n",
      "\n",
      "Model# 7. 5056 nodes still misclassified out of torch.Size([13422]) \n",
      "\n",
      "Model# 8. 5056 nodes still misclassified out of torch.Size([13422]) \n",
      "\n",
      "Model# 9. 5056 nodes still misclassified out of torch.Size([13422]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [02:56<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model# 10. 5056 nodes still misclassified out of torch.Size([13422]) \n",
      "\n",
      "Model# 11. 5056 nodes still misclassified out of torch.Size([13422]) \n",
      "\n",
      "Model# 12. 5056 nodes still misclassified out of torch.Size([13422]) \n",
      "\n",
      "Model# 13. 5056 nodes still misclassified out of torch.Size([13422]) \n",
      "\n",
      "Model# 14. 5056 nodes still misclassified out of torch.Size([13422]) \n",
      "\n",
      "Model# 15. 5056 nodes still misclassified out of torch.Size([13422]) \n",
      "\n",
      "Model# 16. 5056 nodes still misclassified out of torch.Size([13422]) \n",
      "\n",
      "Model# 17. 5056 nodes still misclassified out of torch.Size([13422]) \n",
      "\n",
      "Model# 18. 5056 nodes still misclassified out of torch.Size([13422]) \n",
      "\n",
      "Model# 19. 5056 nodes still misclassified out of torch.Size([13422]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric import utils\n",
    "\n",
    "################################## Training Main Model #####################################\n",
    "if Train_Gnn:\n",
    "    for i in trange(299):\n",
    "        f = open(f\"5gcamflow/{i}.txt\")\n",
    "        data = f.read().split('\\n')\n",
    "\n",
    "        data = [line.split('\\t') for line in data]\n",
    "        df = pd.DataFrame (data, columns = ['actorID', 'actor_type','objectID','object','action','timestamp'])\n",
    "        df.sort_values(by='timestamp', ascending=True,inplace=True)\n",
    "        df = df.dropna()\n",
    "        phrases,labels,edges,mapp = prepare_graph(df)\n",
    "\n",
    "        criterion = CrossEntropyLoss()\n",
    "\n",
    "        nodes = [infer(x) for x in tqdm(phrases, desc='Inferring Phrases')]\n",
    "        nodes = np.array(nodes)  \n",
    "\n",
    "        graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "        graph.n_id = torch.arange(graph.num_nodes)\n",
    "        mask = torch.tensor([True]*graph.num_nodes, dtype=torch.bool)\n",
    "\n",
    "        for m_n in range(20):\n",
    "            loader = NeighborLoader(graph, num_neighbors=[-1,-1], batch_size=5000,input_nodes=mask)\n",
    "            total_loss = 0\n",
    "            for subg in loader:\n",
    "                subg.to(device)\n",
    "                model.train()\n",
    "                optimizer.zero_grad() \n",
    "                out = model(subg.x, subg.edge_index) \n",
    "                loss = criterion(out, subg.y) \n",
    "                loss.backward() \n",
    "                optimizer.step()      \n",
    "                total_loss += loss.item() * subg.batch_size\n",
    "\n",
    "            loader = NeighborLoader(graph, num_neighbors=[-1,-1], batch_size=5000,input_nodes=mask)\n",
    "            for subg in loader:\n",
    "                subg.to(device)\n",
    "                model.eval()\n",
    "                out = model(subg.x, subg.edge_index)\n",
    "                sorted, indices = out.sort(dim=1,descending=True)\n",
    "                conf = (sorted[:,0] - sorted[:,1]) / sorted[:,0]\n",
    "                conf = (conf - conf.min()) / conf.max()\n",
    "                pred = indices[:,0]\n",
    "                cond = (pred == subg.y)\n",
    "                mask[subg.n_id[cond]] = False\n",
    "\n",
    "            print(f'Model# {m_n}. {mask.sum().item()} nodes still misclassified out of {mask.size()} \\n')\n",
    "            torch.save(model.state_dict(), f'trained_weights/5gcamflow/5gcamflow{m_n}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class PhraseDataset(Dataset):\n",
    "    def __init__(self, phrases):\n",
    "        self.phrases = phrases\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.phrases)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.phrases[idx]\n",
    "\n",
    "def batch_infer(phrases):\n",
    "    return [infer(phrase) for phrase in phrases] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph #: 300\n",
      "Preparing Graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12516/12516 [00:00<00:00, 3861128.92it/s]\n",
      "100%|██████████| 12516/12516 [00:00<00:00, 4802480.00it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2706410.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Inferring words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12516/12516 [00:00<00:00, 375195.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 186.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "4334 34.6276765739853\n",
      "Graph #: 301\n",
      "Preparing Graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12602/12602 [00:00<00:00, 4024104.99it/s]\n",
      "100%|██████████| 12602/12602 [00:00<00:00, 5019621.94it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2841669.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Inferring words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12602/12602 [00:00<00:00, 408212.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 265.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "4577 36.31963180447548\n",
      "Graph #: 302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12744/12744 [00:00<00:00, 4305800.72it/s]\n",
      "100%|██████████| 12744/12744 [00:00<00:00, 5214341.06it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 3026120.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Inferring words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12744/12744 [00:00<00:00, 403458.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 264.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4627 36.307281858129315\n",
      "Graph #: 303\n",
      "Preparing Graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12629/12629 [00:00<00:00, 4297757.83it/s]\n",
      "100%|██████████| 12629/12629 [00:00<00:00, 5209979.86it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 3043099.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Inferring words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12629/12629 [00:00<00:00, 429740.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 270.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "4588 36.32908385462032\n",
      "Graph #: 304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12541/12541 [00:00<00:00, 4317554.50it/s]\n",
      "100%|██████████| 12541/12541 [00:00<00:00, 5279081.34it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 3119137.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Inferring words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12541/12541 [00:00<00:00, 423186.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 264.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "4635 36.9587752172873\n",
      "Graph #: 305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13659/13659 [00:00<00:00, 3958952.27it/s]\n",
      "100%|██████████| 13659/13659 [00:00<00:00, 5106060.46it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 3005951.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Inferring words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13659/13659 [00:00<00:00, 435516.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 262.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "5200 38.07013690606926\n",
      "Graph #: 306\n",
      "Preparing Graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14229/14229 [00:00<00:00, 4274819.25it/s]\n",
      "100%|██████████| 14229/14229 [00:00<00:00, 5021941.40it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2950756.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Inferring words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14229/14229 [00:00<00:00, 444139.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 262.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "5940 41.745730550284634\n",
      "Graph #: 307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12543/12543 [00:00<00:00, 4104318.54it/s]\n",
      "100%|██████████| 12543/12543 [00:00<00:00, 5203160.43it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 3055884.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Inferring words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12543/12543 [00:00<00:00, 387641.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 262.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "4265 34.00302957825082\n",
      "Graph #: 308\n",
      "Preparing Graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12667/12667 [00:00<00:00, 4090011.45it/s]\n",
      "100%|██████████| 12667/12667 [00:00<00:00, 4718824.83it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2821850.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Inferring words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12667/12667 [00:00<00:00, 409123.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 265.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "4841 38.217415331175495\n",
      "Graph #: 309\n",
      "Preparing Graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12672/12672 [00:00<00:00, 4171589.38it/s]\n",
      "100%|██████████| 12672/12672 [00:00<00:00, 5019854.58it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2982298.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Inferring words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12672/12672 [00:00<00:00, 396078.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 259.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "3737 29.490214646464647\n",
      "Graph #: 310\n",
      "Preparing Graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12927/12927 [00:00<00:00, 4370447.19it/s]\n",
      "100%|██████████| 12927/12927 [00:00<00:00, 5438837.18it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2985411.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Inferring words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12927/12927 [00:00<00:00, 423562.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 258.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "4030 31.17505995203837\n",
      "Graph #: 311\n",
      "Preparing Graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12507/12507 [00:00<00:00, 4214183.81it/s]\n",
      "100%|██████████| 12507/12507 [00:00<00:00, 5130884.21it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2946196.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Inferring words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12507/12507 [00:00<00:00, 410406.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 263.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "4321 34.54865275445751\n",
      "Graph #: 312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:00<00:00, 4295330.17it/s]\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 5346604.12it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 3057518.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Inferring words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:00<00:00, 404384.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 258.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "4532 36.256\n",
      "Graph #: 313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12534/12534 [00:00<00:00, 4146664.01it/s]\n",
      "100%|██████████| 12534/12534 [00:00<00:00, 5043304.52it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2847199.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Inferring words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12534/12534 [00:00<00:00, 410569.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 264.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "4488 35.806606031594065\n",
      "Graph #: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12485/12485 [00:00<00:00, 4306050.94it/s]\n",
      "100%|██████████| 12485/12485 [00:00<00:00, 5034697.19it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2935406.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Inferring words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12485/12485 [00:00<00:00, 402994.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 264.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "4431 35.49058870644774\n",
      "Graph #: 315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12628/12628 [00:00<00:00, 3893961.98it/s]\n",
      "100%|██████████| 12628/12628 [00:00<00:00, 4749858.39it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2827239.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Inferring words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12628/12628 [00:00<00:00, 390231.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 263.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "4598 36.41114982578397\n",
      "Graph #: 316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12430/12430 [00:00<00:00, 4214988.98it/s]\n",
      "100%|██████████| 12430/12430 [00:00<00:00, 5231306.31it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2987041.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Inferring words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12430/12430 [00:00<00:00, 413063.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 263.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "4257 34.24778761061947\n",
      "Graph #: 317\n",
      "Preparing Graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13959/13959 [00:00<00:00, 4199719.50it/s]\n",
      "100%|██████████| 13959/13959 [00:00<00:00, 5026035.67it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 3005520.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Inferring words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13959/13959 [00:00<00:00, 449696.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 261.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "5439 38.964109176875134\n",
      "Graph #: 318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14744/14744 [00:00<00:00, 4296589.88it/s]\n",
      "100%|██████████| 14744/14744 [00:00<00:00, 5157699.60it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2951795.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Inferring words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14744/14744 [00:00<00:00, 468391.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 258.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "5805 39.37194791101465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in range(300, 319):\n",
    "    print(f\"Graph #: {i}\")\n",
    "    f = open(f\"5gcamflow/{i}.txt\")\n",
    "    data = f.read().split('\\n')\n",
    "\n",
    "    data = [line.split('\\t') for line in data]\n",
    "    df = pd.DataFrame (data, columns = ['actorID', 'actor_type','objectID','object','action','timestamp'])\n",
    "    df.sort_values(by='timestamp', ascending=True,inplace=True)\n",
    "    df = df.dropna()\n",
    "\n",
    "    print(\"Preparing Graph\")\n",
    "    phrases,labels,edges,mapp = prepare_graph(df)\n",
    "    print(\"Done\")\n",
    "    print(\"Inferring words\")\n",
    "    # dataset = PhraseDataset(phrases)\n",
    "    # loader = DataLoader(dataset, batch_size=10, num_workers=4)\n",
    "    # nodes = []\n",
    "    # for batch in tqdm(loader):\n",
    "    #     batch_embeddings = batch_infer(batch)\n",
    "    #     nodes.extend(batch_embeddings)\n",
    "    nodes = [infer(x) for x in tqdm(phrases)]\n",
    "    nodes = np.array(nodes)  \n",
    "    print(\"Done!\")\n",
    "\n",
    "    graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "    graph.n_id = torch.arange(graph.num_nodes).to(device)\n",
    "    flag = torch.tensor([True]*graph.num_nodes, dtype=torch.bool).to(device)\n",
    "    print(\"Evaluating...\")\n",
    "    for m_n in tqdm(range(20)):\n",
    "        model.load_state_dict(torch.load(f'trained_weights/5gcamflow/5gcamflow{m_n}.pth'))\n",
    "        model.eval()\n",
    "        out = model(graph.x, graph.edge_index)\n",
    "\n",
    "        sorted, indices = out.sort(dim=1,descending=True)\n",
    "        conf = (sorted[:,0] - sorted[:,1]) / sorted[:,0]\n",
    "        conf = (conf - conf.min()) / conf.max()\n",
    "\n",
    "        pred = indices[:,0]\n",
    "        cond = (pred == graph.y).to(device)\n",
    "        falses = torch.tensor([False] * len(flag[graph.n_id[cond]]), dtype=torch.bool).to(device)\n",
    "        flag[graph.n_id[cond]] = torch.logical_and(flag[graph.n_id[cond]], falses)\n",
    "    print(\"Done!\")\n",
    "            \n",
    "    print(flag.sum().item(), (flag.sum().item() / len(flag))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "thresh = 5700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph #: 320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13728/13728 [00:00<00:00, 3205980.25it/s]\n",
      "100%|██████████| 13728/13728 [00:00<00:00, 2756710.17it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1552545.07it/s]\n",
      "100%|██████████| 13728/13728 [00:00<00:00, 267481.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5114 37.252331002331005\n",
      "Graph #: 321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13790/13790 [00:00<00:00, 3137480.45it/s]\n",
      "100%|██████████| 13790/13790 [00:00<00:00, 3752153.89it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2112219.16it/s]\n",
      "100%|██████████| 13790/13790 [00:00<00:00, 320683.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5783 41.9361856417694\n",
      "Graph #: 322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13511/13511 [00:00<00:00, 3200928.68it/s]\n",
      "100%|██████████| 13511/13511 [00:00<00:00, 3732659.82it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2272760.64it/s]\n",
      "100%|██████████| 13511/13511 [00:00<00:00, 321743.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4745 35.11953223299534\n",
      "Graph #: 323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13262/13262 [00:00<00:00, 2975386.98it/s]\n",
      "100%|██████████| 13262/13262 [00:00<00:00, 3707335.35it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2200117.50it/s]\n",
      "100%|██████████| 13262/13262 [00:00<00:00, 323244.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3603 27.167847986729\n",
      "Graph #: 324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13668/13668 [00:00<00:00, 3149184.08it/s]\n",
      "100%|██████████| 13668/13668 [00:00<00:00, 3791768.44it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2247630.89it/s]\n",
      "100%|██████████| 13668/13668 [00:00<00:00, 332201.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5038 36.859818554287386\n",
      "Graph #: 325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13071/13071 [00:00<00:00, 3421352.20it/s]\n",
      "100%|██████████| 13071/13071 [00:00<00:00, 3783818.59it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2187913.96it/s]\n",
      "100%|██████████| 13071/13071 [00:00<00:00, 319537.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4623 35.36837273353225\n",
      "Graph #: 326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13269/13269 [00:00<00:00, 3530463.07it/s]\n",
      "100%|██████████| 13269/13269 [00:00<00:00, 3915450.95it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2284728.18it/s]\n",
      "100%|██████████| 13269/13269 [00:00<00:00, 324948.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5241 39.49807822744744\n",
      "Graph #: 327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12921/12921 [00:00<00:00, 3072778.93it/s]\n",
      "100%|██████████| 12921/12921 [00:00<00:00, 3694750.61it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2142282.76it/s]\n",
      "100%|██████████| 12921/12921 [00:00<00:00, 318319.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4275 33.08567448339912\n",
      "Graph #: 328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12982/12982 [00:00<00:00, 3443833.69it/s]\n",
      "100%|██████████| 12982/12982 [00:00<00:00, 3813057.04it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2232081.32it/s]\n",
      "100%|██████████| 12982/12982 [00:00<00:00, 319543.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3606 27.776921891850254\n",
      "Graph #: 329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14090/14090 [00:00<00:00, 3071448.64it/s]\n",
      "100%|██████████| 14090/14090 [00:00<00:00, 3671579.48it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2215652.48it/s]\n",
      "100%|██████████| 14090/14090 [00:00<00:00, 340156.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4810 34.13768630234208\n",
      "Graph #: 330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14303/14303 [00:00<00:00, 3338033.06it/s]\n",
      "100%|██████████| 14303/14303 [00:00<00:00, 3933586.66it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2313035.29it/s]\n",
      "100%|██████████| 14303/14303 [00:00<00:00, 342969.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5731 40.06851709431587\n",
      "Graph #: 331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13107/13107 [00:00<00:00, 4001072.96it/s]\n",
      "100%|██████████| 13107/13107 [00:00<00:00, 4535121.48it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2785000.77it/s]\n",
      "100%|██████████| 13107/13107 [00:00<00:00, 443695.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4162 31.75402456702525\n",
      "Graph #: 332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13274/13274 [00:00<00:00, 3983058.47it/s]\n",
      "100%|██████████| 13274/13274 [00:00<00:00, 4639599.27it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2702225.28it/s]\n",
      "100%|██████████| 13274/13274 [00:00<00:00, 433952.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3658 27.557631459996983\n",
      "Graph #: 333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12972/12972 [00:00<00:00, 4034443.98it/s]\n",
      "100%|██████████| 12972/12972 [00:00<00:00, 4868770.60it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2760560.76it/s]\n",
      "100%|██████████| 12972/12972 [00:00<00:00, 430341.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4570 35.22972556275054\n",
      "Graph #: 334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12868/12868 [00:00<00:00, 3989673.56it/s]\n",
      "100%|██████████| 12868/12868 [00:00<00:00, 4565412.27it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2783152.77it/s]\n",
      "100%|██████████| 12868/12868 [00:00<00:00, 423229.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4869 37.83804787068698\n",
      "Graph #: 335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12707/12707 [00:00<00:00, 3879815.17it/s]\n",
      "100%|██████████| 12707/12707 [00:00<00:00, 4581143.28it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2634668.23it/s]\n",
      "100%|██████████| 12707/12707 [00:00<00:00, 411271.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4366 34.359014716298105\n",
      "Graph #: 336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13013/13013 [00:00<00:00, 4053507.46it/s]\n",
      "100%|██████████| 13013/13013 [00:00<00:00, 4824580.39it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2825144.70it/s]\n",
      "100%|██████████| 13013/13013 [00:00<00:00, 442029.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4676 35.93329747175901\n",
      "Graph #: 337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13046/13046 [00:00<00:00, 3947687.03it/s]\n",
      "100%|██████████| 13046/13046 [00:00<00:00, 4635229.99it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2669830.68it/s]\n",
      "100%|██████████| 13046/13046 [00:00<00:00, 426335.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4196 32.16311513107466\n",
      "Graph #: 338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13070/13070 [00:00<00:00, 3968692.77it/s]\n",
      "100%|██████████| 13070/13070 [00:00<00:00, 4544437.81it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2748380.84it/s]\n",
      "100%|██████████| 13070/13070 [00:00<00:00, 426325.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3573 27.337413925019128\n",
      "Graph #: 339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12908/12908 [00:00<00:00, 4182638.75it/s]\n",
      "100%|██████████| 12908/12908 [00:00<00:00, 5120113.11it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2961591.07it/s]\n",
      "100%|██████████| 12908/12908 [00:00<00:00, 430986.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4601 35.64456151224047\n",
      "Graph #: 340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13418/13418 [00:00<00:00, 3994546.89it/s]\n",
      "100%|██████████| 13418/13418 [00:00<00:00, 4714683.01it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2728535.00it/s]\n",
      "100%|██████████| 13418/13418 [00:00<00:00, 424690.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5071 37.79251751378745\n",
      "Graph #: 341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14665/14665 [00:00<00:00, 3829502.44it/s]\n",
      "100%|██████████| 14665/14665 [00:00<00:00, 4563355.45it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2635385.58it/s]\n",
      "100%|██████████| 14665/14665 [00:00<00:00, 457268.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5899 40.22502557108763\n",
      "Graph #: 342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13525/13525 [00:00<00:00, 4390369.29it/s]\n",
      "100%|██████████| 13525/13525 [00:00<00:00, 4598197.42it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 3080951.01it/s]\n",
      "100%|██████████| 13525/13525 [00:00<00:00, 449761.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4812 35.57855822550832\n",
      "Graph #: 343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13629/13629 [00:00<00:00, 3779199.34it/s]\n",
      "100%|██████████| 13629/13629 [00:00<00:00, 4558182.70it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2679324.57it/s]\n",
      "100%|██████████| 13629/13629 [00:00<00:00, 437503.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4808 35.277716633648836\n",
      "Graph #: 344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13850/13850 [00:00<00:00, 3950701.20it/s]\n",
      "100%|██████████| 13850/13850 [00:00<00:00, 4372684.26it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2644635.66it/s]\n",
      "100%|██████████| 13850/13850 [00:00<00:00, 443850.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5342 38.57039711191336\n",
      "Graph #: 345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13353/13353 [00:00<00:00, 3737756.36it/s]\n",
      "100%|██████████| 13353/13353 [00:00<00:00, 5000584.05it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2794712.15it/s]\n",
      "100%|██████████| 13353/13353 [00:00<00:00, 424510.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4791 35.879577623006064\n",
      "Graph #: 346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13353/13353 [00:00<00:00, 3989354.04it/s]\n",
      "100%|██████████| 13353/13353 [00:00<00:00, 4660609.25it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2752589.42it/s]\n",
      "100%|██████████| 13353/13353 [00:00<00:00, 435272.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4518 33.83509323747472\n",
      "Graph #: 347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13565/13565 [00:00<00:00, 3990722.72it/s]\n",
      "100%|██████████| 13565/13565 [00:00<00:00, 2999089.86it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 1967401.85it/s]\n",
      "100%|██████████| 13565/13565 [00:00<00:00, 453797.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5143 37.913748617766316\n",
      "Graph #: 348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13524/13524 [00:00<00:00, 4018117.68it/s]\n",
      "100%|██████████| 13524/13524 [00:00<00:00, 4960105.57it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2742450.63it/s]\n",
      "100%|██████████| 13524/13524 [00:00<00:00, 445917.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4917 36.357586512866014\n",
      "Graph #: 349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13203/13203 [00:00<00:00, 3965441.87it/s]\n",
      "100%|██████████| 13203/13203 [00:00<00:00, 4684266.26it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2686188.33it/s]\n",
      "100%|██████████| 13203/13203 [00:00<00:00, 428445.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4735 35.863061425433614\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct_benign = 0\n",
    "\n",
    "for i in range(320,350):\n",
    "    print(f\"Graph #: {i}\")\n",
    "    f = open(f\"5gcamflow/{i}.txt\")\n",
    "    data = f.read().split('\\n')\n",
    "\n",
    "    data = [line.split('\\t') for line in data]\n",
    "    df = pd.DataFrame (data, columns = ['actorID', 'actor_type','objectID','object','action','timestamp'])\n",
    "    df.sort_values(by='timestamp', ascending=True,inplace=True)\n",
    "    df = df.dropna()\n",
    "\n",
    "    phrases,labels,edges,mapp = prepare_graph(df)\n",
    "\n",
    "    nodes = [infer(x) for x in tqdm(phrases)]\n",
    "    nodes = np.array(nodes)  \n",
    "\n",
    "    graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "    graph.n_id = torch.arange(graph.num_nodes).to(device)\n",
    "    flag = torch.tensor([True]*graph.num_nodes, dtype=torch.bool).to(device)\n",
    "\n",
    "    for m_n in range(20):\n",
    "        model.load_state_dict(torch.load(f'trained_weights/5gcamflow/5gcamflow{m_n}.pth'))\n",
    "        model.eval()\n",
    "        out = model(graph.x, graph.edge_index)\n",
    "\n",
    "        sorted, indices = out.sort(dim=1,descending=True)\n",
    "        conf = (sorted[:,0] - sorted[:,1]) / sorted[:,0]\n",
    "        conf = (conf - conf.min()) / conf.max()\n",
    "\n",
    "        pred = indices[:,0]\n",
    "        cond = (pred == graph.y).to(device)\n",
    "        falses = torch.tensor([False]*len(flag[graph.n_id[cond]]), dtype=torch.bool).to(device)\n",
    "        flag[graph.n_id[cond]] = torch.logical_and(flag[graph.n_id[cond]], falses)\n",
    "\n",
    "    if flag.sum().item() <= thresh:\n",
    "        correct_benign = correct_benign + 1\n",
    "            \n",
    "    print(flag.sum().item(), (flag.sum().item() / len(flag))*100)\n",
    "print(correct_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph #: 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15797/15797 [00:00<00:00, 3405325.60it/s]\n",
      "100%|██████████| 15797/15797 [00:00<00:00, 4077630.64it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2127612.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15797 100.0\n",
      "Graph #: 401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15815/15815 [00:00<00:00, 3074811.93it/s]\n",
      "100%|██████████| 15815/15815 [00:00<00:00, 3933636.82it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2126857.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15815 100.0\n",
      "Graph #: 402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15444/15444 [00:00<00:00, 3919454.89it/s]\n",
      "100%|██████████| 15444/15444 [00:00<00:00, 4810756.11it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2639864.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15444 100.0\n",
      "Graph #: 403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15829/15829 [00:00<00:00, 4460904.25it/s]\n",
      "100%|██████████| 15829/15829 [00:00<00:00, 5482381.34it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2888572.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15829 100.0\n",
      "Graph #: 404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15870/15870 [00:00<00:00, 3757471.32it/s]\n",
      "100%|██████████| 15870/15870 [00:00<00:00, 4711800.42it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2591689.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15870 100.0\n",
      "Graph #: 405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15294/15294 [00:00<00:00, 3457909.84it/s]\n",
      "100%|██████████| 15294/15294 [00:00<00:00, 4074938.72it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2527856.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15294 100.0\n",
      "Graph #: 406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15205/15205 [00:00<00:00, 3991137.89it/s]\n",
      "100%|██████████| 15205/15205 [00:00<00:00, 4718087.77it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2689288.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15205 100.0\n",
      "Graph #: 407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16002/16002 [00:00<00:00, 3734961.19it/s]\n",
      "100%|██████████| 16002/16002 [00:00<00:00, 4902290.02it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2467334.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16002 100.0\n",
      "Graph #: 408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15711/15711 [00:00<00:00, 3204313.65it/s]\n",
      "100%|██████████| 15711/15711 [00:00<00:00, 4150189.58it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2567312.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15711 100.0\n",
      "Graph #: 409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15881/15881 [00:00<00:00, 3750126.21it/s]\n",
      "100%|██████████| 15881/15881 [00:00<00:00, 4774207.41it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2528110.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15881 100.0\n",
      "Graph #: 410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15518/15518 [00:00<00:00, 3949466.59it/s]\n",
      "100%|██████████| 15518/15518 [00:00<00:00, 4790403.29it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2544366.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15518 100.0\n",
      "Graph #: 411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15181/15181 [00:00<00:00, 3878287.80it/s]\n",
      "100%|██████████| 15181/15181 [00:00<00:00, 4761364.62it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2536366.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15181 100.0\n",
      "Graph #: 412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15577/15577 [00:00<00:00, 4090319.50it/s]\n",
      "100%|██████████| 15577/15577 [00:00<00:00, 5180768.65it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2733217.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15577 100.0\n",
      "Graph #: 413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15359/15359 [00:00<00:00, 2202178.07it/s]\n",
      "100%|██████████| 15359/15359 [00:00<00:00, 2466510.27it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2081402.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15359 100.0\n",
      "Graph #: 414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15411/15411 [00:00<00:00, 4280406.53it/s]\n",
      "100%|██████████| 15411/15411 [00:00<00:00, 5368639.45it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2689173.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15411 100.0\n",
      "Graph #: 415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15371/15371 [00:00<00:00, 3244295.83it/s]\n",
      "100%|██████████| 15371/15371 [00:00<00:00, 4651897.45it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2497253.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15371 100.0\n",
      "Graph #: 416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15743/15743 [00:00<00:00, 3912016.58it/s]\n",
      "100%|██████████| 15743/15743 [00:00<00:00, 4793185.82it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2284271.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15743 100.0\n",
      "Graph #: 417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15962/15962 [00:00<00:00, 4258872.80it/s]\n",
      "100%|██████████| 15962/15962 [00:00<00:00, 5046316.46it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2665871.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15962 100.0\n",
      "Graph #: 418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15316/15316 [00:00<00:00, 2554069.66it/s]\n",
      "100%|██████████| 15316/15316 [00:00<00:00, 2963234.47it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2187039.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15316 100.0\n",
      "Graph #: 419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15282/15282 [00:00<00:00, 3821460.31it/s]\n",
      "100%|██████████| 15282/15282 [00:00<00:00, 5005650.43it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2483110.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15282 100.0\n",
      "Graph #: 420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16293/16293 [00:00<00:00, 3815622.28it/s]\n",
      "100%|██████████| 16293/16293 [00:00<00:00, 4606524.78it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2481689.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16293 100.0\n",
      "Graph #: 421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16624/16624 [00:00<00:00, 3902507.96it/s]\n",
      "100%|██████████| 16624/16624 [00:00<00:00, 4627429.63it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2579046.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16624 100.0\n",
      "Graph #: 422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16489/16489 [00:00<00:00, 3227697.70it/s]\n",
      "100%|██████████| 16489/16489 [00:00<00:00, 4001613.07it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2139659.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16489 100.0\n",
      "Graph #: 423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16204/16204 [00:00<00:00, 4266982.80it/s]\n",
      "100%|██████████| 16204/16204 [00:00<00:00, 5237304.62it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2636103.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16204 100.0\n",
      "Graph #: 424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15530/15530 [00:00<00:00, 4000094.64it/s]\n",
      "100%|██████████| 15530/15530 [00:00<00:00, 4797992.13it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2769431.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15530 100.0\n",
      "Graph #: 425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15791/15791 [00:00<00:00, 3994948.70it/s]\n",
      "100%|██████████| 15791/15791 [00:00<00:00, 4672799.10it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2729541.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15791 100.0\n",
      "Graph #: 426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15400/15400 [00:00<00:00, 3977112.35it/s]\n",
      "100%|██████████| 15400/15400 [00:00<00:00, 4995536.09it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2646916.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15400 100.0\n",
      "Graph #: 427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16528/16528 [00:00<00:00, 4013632.27it/s]\n",
      "100%|██████████| 16528/16528 [00:00<00:00, 4724559.16it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2668415.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16528 100.0\n",
      "Graph #: 428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15680/15680 [00:00<00:00, 3726157.89it/s]\n",
      "100%|██████████| 15680/15680 [00:00<00:00, 4473315.65it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2446419.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15680 100.0\n",
      "Graph #: 429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15036/15036 [00:00<00:00, 3820302.58it/s]\n",
      "100%|██████████| 15036/15036 [00:00<00:00, 4678106.59it/s]\n",
      "100%|██████████| 30000/30000 [00:00<00:00, 2408673.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15036 100.0\n"
     ]
    }
   ],
   "source": [
    "correct_attack = 0\n",
    "\n",
    "for i in range(400,430):\n",
    "    print(f\"Graph #: {i}\")\n",
    "    f = open(f\"5gcamflow/{i}.txt\")\n",
    "    data = f.read().split('\\n')\n",
    "\n",
    "    data = [line.split('\\t') for line in data]\n",
    "    df = pd.DataFrame (data, columns = ['actorID', 'actor_type','objectID','object','action','timestamp'])\n",
    "    df.sort_values(by='timestamp', ascending=True,inplace=True)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    phrases,labels,edges,mapp = prepare_graph(df)\n",
    "\n",
    "    nodes = [infer(x) for x in phrases]\n",
    "    nodes = np.array(nodes)  \n",
    "    \n",
    "    graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "    graph.n_id = torch.arange(graph.num_nodes).to(device)\n",
    "    flag = torch.tensor([True]*graph.num_nodes, dtype=torch.bool).to(device)\n",
    "\n",
    "    for m_n in range(20):\n",
    "        model.load_state_dict(torch.load(f'trained_weights/5gcamflow/5gcamflow{m_n}.pth'))\n",
    "        model.eval()\n",
    "        out = model(graph.x, graph.edge_index)\n",
    "\n",
    "        sorted, indices = out.sort(dim=1,descending=True)\n",
    "        conf = (sorted[:,0] - sorted[:,1]) / sorted[:,0]\n",
    "        conf = (conf - conf.min()) / conf.max()\n",
    "\n",
    "        pred = indices[:,0]\n",
    "        cond = (pred == graph.y).to(device)\n",
    "        falses = torch.tensor([False]*len(flag[graph.n_id[cond]]), dtype=torch.bool).to(device)\n",
    "        flag[graph.n_id[cond]] = torch.logical_and(flag[graph.n_id[cond]], falses)\n",
    "\n",
    "    if  flag.sum().item() > thresh:\n",
    "        correct_attack = correct_attack + 1\n",
    "   \n",
    "    print(flag.sum().item(), (flag.sum().item() / len(flag))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of True Positives (TP): 30\n",
      "Number of False Positives (FP): 2\n",
      "Number of False Negatives (FN): 0\n",
      "Number of True Negatives (TN): 27\n",
      "\n",
      "Precision: 0.9375\n",
      "Recall: 1.0\n",
      "Fscore: 0.967741935483871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TP = correct_attack\n",
    "FP = 29 - correct_benign\n",
    "TN = correct_benign\n",
    "FN = 30 - correct_attack\n",
    "\n",
    "FPR = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "TPR = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "print(f\"Number of True Positives (TP): {TP}\")\n",
    "print(f\"Number of False Positives (FP): {FP}\")\n",
    "print(f\"Number of False Negatives (FN): {FN}\")\n",
    "print(f\"Number of True Negatives (TN): {TN}\\n\")\n",
    "\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TPR  \n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "fscore = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "print(f\"Fscore: {fscore}\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
