{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flash Evaluation on CamFow Dataset:\n",
    "\n",
    "This notebook is dedicated to evaluating Flash on the 5G CamFlow datasets, which are graph-level in nature. We employ Flash in graph-level detection mode to analyze this dataset effectively. Upon completion of the notebook execution, the results will be presented.\n",
    "\n",
    "## Dataset Access: \n",
    "- This dataset will be publically available upon publishing\n",
    "\n",
    "## Data Parsing and Execution:\n",
    "- Utilize the parser included in this notebook to process the downloaded files.\n",
    "- To obtain the evaluation results, execute all cells within this notebook.\n",
    "\n",
    "## Model Training and Execution Flexibility:\n",
    "- By default, the notebook operates using pre-trained model weights.\n",
    "- Additionally, this notebook offers the flexibility to set parameters for training Graph Neural Networks (GNNs) and word2vec models from scratch.\n",
    "- You can then utilize these freshly trained models to conduct the evaluation. \n",
    "\n",
    "Follow these guidelines for a thorough and efficient analysis of the Unicorn datasets using Flash.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "id": "F1op-CbyLuN4",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "warnings.filterwarnings('ignore')\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import multiprocessing\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nM7KaeCbA_mQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import gzip\n",
    "from sklearn.manifold import TSNE\n",
    "import json\n",
    "import copy\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Train_Gnn = True\n",
    "Train_Word2vec = False\n",
    "Parse_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import csv\n",
    "import time\n",
    "\n",
    "def show(str):\n",
    "\tprint (str + ' ' + time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(time.time())))\n",
    "\n",
    "def parse_data():\n",
    "    \n",
    "    show('Start processing.')\n",
    "    f = open('datasets/5gcamflow/preprocessed.txt', 'r')\n",
    "    \n",
    "    file_idx = 0\n",
    "    i = 0 \n",
    "    for i, line in tqdm(enumerate(f)):\n",
    "\n",
    "        # Split the large graph into smaller graph each with 1M edges\n",
    "        if i >= file_idx * 1000000:\n",
    "            if file_idx > 0: fw.close()\n",
    "            fw = open('5gcamflow/'+str(file_idx)+'.txt', 'w')\n",
    "            file_idx += 1\n",
    "\n",
    "        tempp = line.strip('\\n').split('\\t')\n",
    "        temp = []\n",
    "        temp.append(tempp[0])\n",
    "        temp.append(tempp[2].split(':')[0])\n",
    "        temp.append(tempp[1])\n",
    "        temp.append(tempp[2].split(':')[1])\n",
    "        temp.append(tempp[2].split(':')[2])\n",
    "        temp.append(tempp[2].split(':')[3])\n",
    "        fw.write(temp[0]+'\\t'+temp[1]+'\\t'+temp[2]+'\\t'+temp[3]+'\\t'+temp[4]+'\\t'+temp[5]+'\\n')\n",
    "            \n",
    "    f.close()\n",
    "    fw.close()\n",
    "    show('Done.')\n",
    "\n",
    "if Parse_data:\n",
    "    parse_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "def prepare_graph(df):\n",
    "    def process_node(node, action, node_dict, label_dict, dummies, node_type):\n",
    "        node_dict.setdefault(node, []).append(action)\n",
    "        label_dict[node] = dummies.get(getattr(row, node_type), -1)  \n",
    "\n",
    "    nodes = {}\n",
    "    labels = {}\n",
    "    edges = []\n",
    "    dummies = {\n",
    "        \"7998762093665332071\": 0, \"14709879154498484854\": 1, \"10991425273196493354\": 2,\n",
    "        \"14871526952859113360\": 3, \"8771628573506871447\": 4, \"7877121489144997480\": 5,\n",
    "        \"17841021884467483934\": 6, \"7895447931126725167\": 7, \"15125250455093594050\": 8,\n",
    "        \"8664433583651064836\": 9, \"14377490526132269506\": 10, \"15554536683409451879\": 11,\n",
    "        \"8204541918505434145\": 12, \"14356114695140920775\": 13\n",
    "    }\n",
    "\n",
    "    for row in df.itertuples():\n",
    "        process_node(row.actorID, row.action, nodes, labels, dummies, 'actor_type')\n",
    "        process_node(row.objectID, row.action, nodes, labels, dummies, 'object')\n",
    "\n",
    "        edges.append((row.actorID, row.objectID))\n",
    "\n",
    "    features = [nodes[node] for node in tqdm(nodes)]\n",
    "    feat_labels = [labels[node] for node in tqdm(nodes)]\n",
    "    edge_index = [[], []]\n",
    "    node_index_map = {node: i for i, node in enumerate(nodes.keys())}\n",
    "    for src, dst in tqdm(edges):\n",
    "        src_index = node_index_map[src]\n",
    "        dst_index = node_index_map[dst]\n",
    "        edge_index[0].append(src_index)\n",
    "        edge_index[1].append(dst_index)\n",
    "\n",
    "    return features, feat_labels, edge_index, list(nodes.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fmXWs1dKIzD8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import SAGEConv, GATConv\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self,in_channel,out_channel):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channel, 32, normalize=True)\n",
    "        self.conv2 = SAGEConv(32, 20, normalize=True)\n",
    "        self.linear = nn.Linear(in_features=20,out_features=out_channel)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.linear(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3PCP6SXwZaif",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from multiprocessing import Pool\n",
    "from itertools import compress\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class EpochSaver(CallbackAny2Vec):\n",
    "    '''Callback to save model after each epoch.'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        model.save('trained_weights/5gcamflow/5gcamflow.model')\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "P8oBL8LFaeOf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EpochLogger(CallbackAny2Vec):\n",
    "    '''Callback to log information about training'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(\"Epoch #{} start\".format(self.epoch))\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(\"Epoch #{} end\".format(self.epoch))\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Se7Ei4tAapVj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = EpochLogger()\n",
    "saver = EpochSaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Train_Word2vec:\n",
    "    comb_data = []\n",
    "    for i in tqdm(range(12)):\n",
    "        f = open(f\"5gcamflow/{i}.txt\")\n",
    "        data = f.read().split('\\n')\n",
    "        data = [line.split('\\t') for line in data]\n",
    "        comb_data = comb_data + data\n",
    "\n",
    "    df = pd.DataFrame (comb_data, columns = ['actorID', 'actor_type','objectID','object','action','timestamp'])\n",
    "    df.sort_values(by='timestamp', ascending=True,inplace=True)\n",
    "    df = df.dropna()\n",
    "    phrases,labels,edges,mapp = prepare_graph(df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Train_Word2vec:\n",
    "        word2vec = Word2Vec(sentences=phrases, vector_size=30, window=5, min_count=1, workers=32,epochs=300,callbacks=[saver,logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "p3TAi69zI1bO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "model = GCN(30,14).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Vn_pMyt5Jd-6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "class PositionalEncoder:\n",
    "\n",
    "    def __init__(self, d_model, max_len=100000, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.device = device\n",
    "        position = torch.arange(max_len, device=device).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2, device=device) * (-math.log(10000.0) / d_model))\n",
    "        self.pe = torch.zeros(max_len, d_model, device=device)\n",
    "        self.pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "    def embed(self, x):\n",
    "        return x + self.pe[:x.size(0)]\n",
    "\n",
    "def infer(document):\n",
    "    word_embeddings = [w2vmodel.wv[word] for word in document if word in  w2vmodel.wv]\n",
    "    \n",
    "    if not word_embeddings:\n",
    "        return np.zeros(20)\n",
    "\n",
    "    output_embedding = torch.tensor(word_embeddings, dtype=torch.float, device=device)\n",
    "    if len(document) < 100000:\n",
    "        output_embedding = encoder.embed(output_embedding)\n",
    "\n",
    "    output_embedding = output_embedding.detach().cpu().numpy()\n",
    "    return np.mean(output_embedding, axis=0)\n",
    "\n",
    "encoder = PositionalEncoder(30)\n",
    "w2vmodel = Word2Vec.load(\"trained_weights/5gcamflow/5gcamflow.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 486933/486933 [00:00<00:00, 2709852.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 486933/486933 [00:00<00:00, 3002234.43it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000000/1000000 [00:00<00:00, 2427231.17it/s]\n",
      "Inferring Phrases: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 486933/486933 [00:48<00:00, 10014.29it/s]\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "f = open(f\"5gcamflow/{i}.txt\")\n",
    "data = f.read().split('\\n')\n",
    "\n",
    "data = [line.split('\\t') for line in data]\n",
    "df = pd.DataFrame (data, columns = ['actorID', 'actor_type','objectID','object','action','timestamp'])\n",
    "df.sort_values(by='timestamp', ascending=True,inplace=True)\n",
    "df = df.dropna()\n",
    "phrases,labels,edges,mapp = prepare_graph(df)\n",
    "\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "nodes = [infer(x) for x in tqdm(phrases, desc='Inferring Phrases')]\n",
    "nodes = np.array(nodes)  \n",
    "\n",
    "graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "graph.n_id = torch.arange(graph.num_nodes)\n",
    "mask = torch.tensor([True]*graph.num_nodes, dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [10,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [11,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [12,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [13,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [14,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [15,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [16,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [17,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [18,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [19,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [20,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [21,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [22,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [23,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [24,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [25,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [26,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [27,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [28,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [29,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [30,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1711403378171/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [31,0,0] Assertion `t >= 0 && t < n_classes` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m out \u001b[38;5;241m=\u001b[39m model(subg\u001b[38;5;241m.\u001b[39mx, subg\u001b[38;5;241m.\u001b[39medge_index) \n\u001b[1;32m      7\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, subg\u001b[38;5;241m.\u001b[39my) \n\u001b[0;32m----> 8\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \n\u001b[1;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()      \n\u001b[1;32m     10\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m subg\u001b[38;5;241m.\u001b[39mbatch_size\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    267\u001b[0m     tensors,\n\u001b[1;32m    268\u001b[0m     grad_tensors_,\n\u001b[1;32m    269\u001b[0m     retain_graph,\n\u001b[1;32m    270\u001b[0m     create_graph,\n\u001b[1;32m    271\u001b[0m     inputs,\n\u001b[1;32m    272\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    273\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    274\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`"
     ]
    }
   ],
   "source": [
    "loader = NeighborLoader(graph, num_neighbors=[-1,-1], batch_size=5000,input_nodes=mask)\n",
    "total_loss = 0\n",
    "for subg in loader:\n",
    "    model.train()\n",
    "    optimizer.zero_grad() \n",
    "    out = model(subg.x, subg.edge_index) \n",
    "    loss = criterion(out, subg.y) \n",
    "    loss.backward() \n",
    "    optimizer.step()      \n",
    "    total_loss += loss.item() * subg.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21278\n"
     ]
    }
   ],
   "source": [
    "print(max(map(len, phrases)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 689309,
     "status": "ok",
     "timestamp": 1673566932746,
     "user": {
      "displayName": "Mati Ur Rehman",
      "userId": "04281203290774044297"
     },
     "user_tz": 300
    },
    "id": "Gclj6HVL17lD",
    "outputId": "f60fadea-a7db-471f-defe-fee744f6ef25",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric import utils\n",
    "\n",
    "################################## Training Main Model #####################################\n",
    "if Train_Gnn:\n",
    "    for i in tqdm(range(13)):\n",
    "        f = open(f\"5gcamflow/{i}.txt\")\n",
    "        data = f.read().split('\\n')\n",
    "\n",
    "        data = [line.split('\\t') for line in data]\n",
    "        df = pd.DataFrame (data, columns = ['actorID', 'actor_type','objectID','object','action','timestamp'])\n",
    "        df.sort_values(by='timestamp', ascending=True,inplace=True)\n",
    "        df = df.dropna()\n",
    "        phrases,labels,edges,mapp = prepare_graph(df)\n",
    "\n",
    "        criterion = CrossEntropyLoss()\n",
    "\n",
    "        nodes = [infer(x) for x in tqdm(phrases, desc='Inferring Phrases')]\n",
    "        nodes = np.array(nodes)  \n",
    "\n",
    "        graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "        graph.n_id = torch.arange(graph.num_nodes)\n",
    "        mask = torch.tensor([True]*graph.num_nodes, dtype=torch.bool)\n",
    "\n",
    "        for m_n in range(20):\n",
    "            loader = NeighborLoader(graph, num_neighbors=[-1,-1], batch_size=5000,input_nodes=mask)\n",
    "            total_loss = 0\n",
    "            for subg in loader:\n",
    "                model.train()\n",
    "                optimizer.zero_grad() \n",
    "                out = model(subg.x, subg.edge_index) \n",
    "                loss = criterion(out, subg.y) \n",
    "                loss.backward() \n",
    "                optimizer.step()      \n",
    "                total_loss += loss.item() * subg.batch_size\n",
    "\n",
    "            loader = NeighborLoader(graph, num_neighbors=[-1,-1], batch_size=5000,input_nodes=mask)\n",
    "            for subg in loader:\n",
    "              model.eval()\n",
    "              out = model(subg.x, subg.edge_index)\n",
    "              sorted, indices = out.sort(dim=1,descending=True)\n",
    "              conf = (sorted[:,0] - sorted[:,1]) / sorted[:,0]\n",
    "              conf = (conf - conf.min()) / conf.max()\n",
    "              pred = indices[:,0]\n",
    "              cond = (pred == subg.y)w\n",
    "              mask[subg.n_id[cond]] = False\n",
    "\n",
    "            print(f'Model# {m_n}. {mask.sum().item()} nodes still misclassified \\n')\n",
    "            torch.save(model.state_dict(), f'trained_weights/5gcamflow/5gcamflow{m_n}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class PhraseDataset(Dataset):\n",
    "    def __init__(self, phrases):\n",
    "        self.phrases = phrases\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.phrases)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.phrases[idx]\n",
    "\n",
    "def batch_infer(phrases):\n",
    "    return [infer(phrase) for phrase in phrases] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph #: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████                                                                   | 50600/249325 [00:43<02:50, 1167.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 230438/230438 [00:00<00:00, 2330345.30it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 230438/230438 [00:00<00:00, 3058426.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 900266/900266 [00:00<00:00, 2473264.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Inferring words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 230438/230438 [00:26<00:00, 8655.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 52.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "11884 5.157135541881113\n",
      "Graph #: 96\n",
      "Preparing Graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 249325/249325 [00:00<00:00, 2452491.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 249325/249325 [00:00<00:00, 3141006.88it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 950908/950908 [00:00<00:00, 2387755.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Inferring words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 249325/249325 [00:28<00:00, 8743.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 50.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "14759 5.91958287375915\n",
      "Graph #: 97\n",
      "Preparing Graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 245135/245135 [00:00<00:00, 2322132.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 245135/245135 [00:00<00:00, 2947230.15it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 940300/940300 [00:00<00:00, 2427787.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Inferring words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 245135/245135 [00:27<00:00, 8769.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 50.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "13215 5.390907051216677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in range(95,98):\n",
    "    print(f\"Graph #: {i}\")\n",
    "    f = open(f\"datasets/5gcamflow/{i}.txt\")\n",
    "    data = f.read().split('\\n')\n",
    "\n",
    "    data = [line.split('\\t') for line in data]\n",
    "    df = pd.DataFrame (data, columns = ['actorID', 'actor_type','objectID','object','action','timestamp'])\n",
    "    df.sort_values(by='timestamp', ascending=True,inplace=True)\n",
    "    df = df.dropna()\n",
    "\n",
    "    print(\"Preparing Graph\")\n",
    "    phrases,labels,edges,mapp = prepare_graph(df)\n",
    "    print(\"Done\")\n",
    "    print(\"Inferring words\")\n",
    "    # dataset = PhraseDataset(phrases)\n",
    "    # loader = DataLoader(dataset, batch_size=10, num_workers=4)\n",
    "    # nodes = []\n",
    "    # for batch in tqdm(loader):\n",
    "    #     batch_embeddings = batch_infer(batch)\n",
    "    #     nodes.extend(batch_embeddings)\n",
    "    nodes = [infer(x) for x in tqdm(phrases)]\n",
    "    nodes = np.array(nodes)  \n",
    "    print(\"Done!\")\n",
    "\n",
    "    graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "    graph.n_id = torch.arange(graph.num_nodes).to(device)\n",
    "    flag = torch.tensor([True]*graph.num_nodes, dtype=torch.bool).to(device)\n",
    "    print(\"Evaluating...\")\n",
    "    for m_n in tqdm(range(20)):\n",
    "        model.load_state_dict(torch.load(f'trained_weights/5gcamflow/5gcamflow{m_n}.pth'))\n",
    "        model.eval()\n",
    "        out = model(graph.x, graph.edge_index)\n",
    "\n",
    "        sorted, indices = out.sort(dim=1,descending=True)\n",
    "        conf = (sorted[:,0] - sorted[:,1]) / sorted[:,0]\n",
    "        conf = (conf - conf.min()) / conf.max()\n",
    "\n",
    "        pred = indices[:,0]\n",
    "        cond = (pred == graph.y).to(device)\n",
    "        falses = torch.tensor([False] * len(flag[graph.n_id[cond]]), dtype=torch.bool).to(device)\n",
    "        flag[graph.n_id[cond]] = torch.logical_and(flag[graph.n_id[cond]], falses)\n",
    "    print(\"Done!\")\n",
    "            \n",
    "    print(flag.sum().item(), (flag.sum().item() / len(flag))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "thresh = 330"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph #: 100\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/5gcamflow/100.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m125\u001b[39m):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraph #: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets/5gcamflow/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     data \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m     data \u001b[38;5;241m=\u001b[39m [line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m data]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/5gcamflow/100.txt'"
     ]
    }
   ],
   "source": [
    "correct_benign = 0\n",
    "\n",
    "for i in range(100,125):\n",
    "    print(f\"Graph #: {i}\")\n",
    "    f = open(f\"datasets/5gcamflow/{i}.txt\")\n",
    "    data = f.read().split('\\n')\n",
    "\n",
    "    data = [line.split('\\t') for line in data]\n",
    "    df = pd.DataFrame (data, columns = ['actorID', 'actor_type','objectID','object','action','timestamp'])\n",
    "    df.sort_values(by='timestamp', ascending=True,inplace=True)\n",
    "    df = df.dropna()\n",
    "\n",
    "    phrases,labels,edges,mapp = prepare_graph(df)\n",
    "\n",
    "    nodes = [infer(x) for x in tqdm(phrases)]\n",
    "    nodes = np.array(nodes)  \n",
    "\n",
    "    graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "    graph.n_id = torch.arange(graph.num_nodes).to(device)\n",
    "    flag = torch.tensor([True]*graph.num_nodes, dtype=torch.bool).to(device)\n",
    "\n",
    "    for m_n in range(20):\n",
    "        model.load_state_dict(torch.load(f'trained_weights/5gcamflow/5gcamflow{m_n}.pth'))\n",
    "        model.eval()\n",
    "        out = model(graph.x, graph.edge_index)\n",
    "\n",
    "        sorted, indices = out.sort(dim=1,descending=True)\n",
    "        conf = (sorted[:,0] - sorted[:,1]) / sorted[:,0]\n",
    "        conf = (conf - conf.min()) / conf.max()\n",
    "\n",
    "        pred = indices[:,0]\n",
    "        cond = (pred == graph.y).to(device)\n",
    "        falses = torch.tensor([False]*len(flag[graph.n_id[cond]]), dtype=torch.bool).to(device)\n",
    "        flag[graph.n_id[cond]] = torch.logical_and(flag[graph.n_id[cond]], falses)\n",
    "\n",
    "    if flag.sum().item() <= thresh:\n",
    "        correct_benign = correct_benign + 1\n",
    "            \n",
    "    print(flag.sum().item(), (flag.sum().item() / len(flag))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph #: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250904/250904 [00:00<00:00, 2364791.41it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 250904/250904 [00:00<00:00, 3093561.21it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 973950/973950 [00:00<00:00, 2138024.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13218 5.2681503682683415\n",
      "Graph #: 126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 233846/233846 [00:00<00:00, 2458956.55it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 233846/233846 [00:00<00:00, 3216123.60it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 927125/927125 [00:00<00:00, 2344874.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12855 5.497207563952345\n",
      "Graph #: 127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 276042/276042 [00:00<00:00, 2389550.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 276042/276042 [00:00<00:00, 2999865.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1058110/1058110 [00:00<00:00, 2372442.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15369 5.567631012671985\n",
      "Graph #: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 248200/248200 [00:00<00:00, 2379722.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 248200/248200 [00:00<00:00, 2994311.39it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 969084/969084 [00:00<00:00, 2393933.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13046 5.25624496373892\n",
      "Graph #: 129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 255584/255584 [00:00<00:00, 2442368.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 255584/255584 [00:00<00:00, 3161114.04it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 977788/977788 [00:00<00:00, 2386377.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13458 5.265587830224114\n",
      "Graph #: 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 244068/244068 [00:00<00:00, 2454769.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 244068/244068 [00:00<00:00, 3176090.91it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 947473/947473 [00:00<00:00, 2400440.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12878 5.276398380779127\n",
      "Graph #: 131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 255432/255432 [00:00<00:00, 2414842.71it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 255432/255432 [00:00<00:00, 3110366.32it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 990249/990249 [00:00<00:00, 2445917.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14002 5.481693758025619\n",
      "Graph #: 132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 249089/249089 [00:00<00:00, 2342058.87it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 249089/249089 [00:00<00:00, 2848668.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 960122/960122 [00:00<00:00, 2274216.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12885 5.1728498649077235\n",
      "Graph #: 133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 237216/237216 [00:00<00:00, 2416824.80it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 237216/237216 [00:00<00:00, 3087940.42it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 929153/929153 [00:00<00:00, 2402231.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12390 5.223087818696884\n",
      "Graph #: 134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 248175/248175 [00:00<00:00, 2401590.56it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 248175/248175 [00:00<00:00, 2945381.53it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 951876/951876 [00:00<00:00, 2412885.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13146 5.297068600785735\n",
      "Graph #: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 224288/224288 [00:00<00:00, 2333332.64it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 224288/224288 [00:00<00:00, 3094981.66it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 896440/896440 [00:00<00:00, 2418936.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12293 5.480899557711514\n",
      "Graph #: 136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 253091/253091 [00:00<00:00, 2328496.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 253091/253091 [00:00<00:00, 2316570.41it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 953372/953372 [00:00<00:00, 2358927.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13549 5.353410433401424\n",
      "Graph #: 137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 261156/261156 [00:00<00:00, 2263773.71it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 261156/261156 [00:00<00:00, 2912150.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1018644/1018644 [00:00<00:00, 2457999.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14153 5.419366202576239\n",
      "Graph #: 138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 232184/232184 [00:00<00:00, 2434114.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 232184/232184 [00:00<00:00, 3236630.33it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 927643/927643 [00:00<00:00, 2445221.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11909 5.1291217310408985\n",
      "Graph #: 139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 249251/249251 [00:00<00:00, 2227409.11it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 249251/249251 [00:00<00:00, 2408230.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 973399/973399 [00:00<00:00, 1655847.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14038 5.63207369278358\n",
      "Graph #: 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 256627/256627 [00:00<00:00, 2464294.16it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 256627/256627 [00:00<00:00, 3205566.86it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 988930/988930 [00:00<00:00, 2409626.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14226 5.543454118233857\n",
      "Graph #: 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 236217/236217 [00:00<00:00, 2397022.03it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 236217/236217 [00:00<00:00, 3112073.39it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 908925/908925 [00:00<00:00, 2379737.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12013 5.085578091331276\n",
      "Graph #: 142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 226388/226388 [00:00<00:00, 2392879.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 226388/226388 [00:00<00:00, 3071454.29it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 905630/905630 [00:00<00:00, 2377003.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12430 5.490573705320069\n",
      "Graph #: 143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 225121/225121 [00:00<00:00, 2385444.97it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 225121/225121 [00:00<00:00, 3023874.28it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 904585/904585 [00:00<00:00, 2436164.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12202 5.420196250016658\n",
      "Graph #: 144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 227384/227384 [00:00<00:00, 2022838.16it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 227384/227384 [00:00<00:00, 2635758.60it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 889691/889691 [00:00<00:00, 2148834.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12282 5.401435457200155\n",
      "Graph #: 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 249572/249572 [00:00<00:00, 2389103.31it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 249572/249572 [00:00<00:00, 2999079.85it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 962409/962409 [00:00<00:00, 2459782.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12964 5.1944929719680095\n",
      "Graph #: 146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 249389/249389 [00:00<00:00, 2396375.88it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 249389/249389 [00:00<00:00, 3137553.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 973099/973099 [00:00<00:00, 2380639.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12894 5.17023605692312\n",
      "Graph #: 147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 229636/229636 [00:00<00:00, 2383194.26it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 229636/229636 [00:00<00:00, 3155553.20it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 905318/905318 [00:00<00:00, 2432730.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12640 5.504363427337177\n",
      "Graph #: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 247628/247628 [00:00<00:00, 2384233.87it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 247628/247628 [00:00<00:00, 3076137.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 960381/960381 [00:00<00:00, 2347300.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13146 5.3087696060219365\n",
      "Graph #: 149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 224930/224930 [00:00<00:00, 2362590.21it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 224930/224930 [00:00<00:00, 2659579.90it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 893784/893784 [00:00<00:00, 2199442.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12223 5.434135064242208\n"
     ]
    }
   ],
   "source": [
    "correct_attack = 0\n",
    "\n",
    "for i in range(125,150):\n",
    "    print(f\"Graph #: {i}\")\n",
    "    f = open(f\"datasets/5gcamflow/{i}.txt\")\n",
    "    data = f.read().split('\\n')\n",
    "\n",
    "    data = [line.split('\\t') for line in data]\n",
    "    df = pd.DataFrame (data, columns = ['actorID', 'actor_type','objectID','object','action','timestamp'])\n",
    "    df.sort_values(by='timestamp', ascending=True,inplace=True)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    phrases,labels,edges,mapp = prepare_graph(df)\n",
    "\n",
    "    nodes = [infer(x) for x in phrases]\n",
    "    nodes = np.array(nodes)  \n",
    "    \n",
    "    graph = Data(x=torch.tensor(nodes,dtype=torch.float).to(device),y=torch.tensor(labels,dtype=torch.long).to(device), edge_index=torch.tensor(edges,dtype=torch.long).to(device))\n",
    "    graph.n_id = torch.arange(graph.num_nodes).to(device)\n",
    "    flag = torch.tensor([True]*graph.num_nodes, dtype=torch.bool).to(device)\n",
    "\n",
    "    for m_n in range(20):\n",
    "        model.load_state_dict(torch.load(f'trained_weights/5gcamflow/5gcamflw{m_n}.pth'))\n",
    "        model.eval()\n",
    "        out = model(graph.x, graph.edge_index)\n",
    "\n",
    "        sorted, indices = out.sort(dim=1,descending=True)\n",
    "        conf = (sorted[:,0] - sorted[:,1]) / sorted[:,0]\n",
    "        conf = (conf - conf.min()) / conf.max()\n",
    "\n",
    "        pred = indices[:,0]\n",
    "        cond = (pred == graph.y).to(device)\n",
    "        falses = torch.tensor([False]*len(flag[graph.n_id[cond]]), dtype=torch.bool).to(device)\n",
    "        flag[graph.n_id[cond]] = torch.logical_and(flag[graph.n_id[cond]], falses)\n",
    "\n",
    "    if  flag.sum().item() > thresh:\n",
    "        correct_attack = correct_attack + 1\n",
    "   \n",
    "    print(flag.sum().item(), (flag.sum().item() / len(flag))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = correct_attack\n",
    "FP = 25 - correct_benign\n",
    "TN = correct_benign\n",
    "FN = 25 - correct_attack\n",
    "\n",
    "FPR = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "TPR = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "print(f\"Number of True Positives (TP): {TP}\")\n",
    "print(f\"Number of False Positives (FP): {FP}\")\n",
    "print(f\"Number of False Negatives (FN): {FN}\")\n",
    "print(f\"Number of True Negatives (TN): {TN}\\n\")\n",
    "\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TPR  \n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "fscore = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "print(f\"Fscore: {fscore}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
